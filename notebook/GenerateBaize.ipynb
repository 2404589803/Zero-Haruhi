{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHxxWjxrwEze9KfwvttV68",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38ca8cb2432b4ad4b2a9af5c36ad20fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ae2832017ca424380e05859939e5ecf",
              "IPY_MODEL_2eb8d51e83694c78aca60956437733c1",
              "IPY_MODEL_0b373f7e90ff456c9e9eabe184c4dac1"
            ],
            "layout": "IPY_MODEL_27d57eff21344d349c50a17a229f2c3c"
          }
        },
        "2ae2832017ca424380e05859939e5ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ebd1ed8918e41c08c8d8d46a4547914",
            "placeholder": "​",
            "style": "IPY_MODEL_12fb9fb569c243b89b2fd3d093dde00a",
            "value": "Downloading readme: 100%"
          }
        },
        "2eb8d51e83694c78aca60956437733c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cf11ff03ac54e4d8836cd0092068df2",
            "max": 932,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d0e3acd6953e434ea8f99e93636e2deb",
            "value": 932
          }
        },
        "0b373f7e90ff456c9e9eabe184c4dac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df45d92729d74d78b672ee8e80ef85fc",
            "placeholder": "​",
            "style": "IPY_MODEL_14f5d963021945fe988ae77eaa521395",
            "value": " 932/932 [00:00&lt;00:00, 16.0kB/s]"
          }
        },
        "27d57eff21344d349c50a17a229f2c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ebd1ed8918e41c08c8d8d46a4547914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12fb9fb569c243b89b2fd3d093dde00a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cf11ff03ac54e4d8836cd0092068df2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0e3acd6953e434ea8f99e93636e2deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df45d92729d74d78b672ee8e80ef85fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14f5d963021945fe988ae77eaa521395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21db3aa686b242c7a9b4149edd57d0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_777320ed9ef64ee9a020b3fc50c5cced",
              "IPY_MODEL_1dbd00cf8ae443879250716892275cb5",
              "IPY_MODEL_8f9aa9e31adf4696a29a924bcb16f4f6"
            ],
            "layout": "IPY_MODEL_fd7b6392c7d346daa35092ead1f456da"
          }
        },
        "777320ed9ef64ee9a020b3fc50c5cced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ecc4b150ca643c49c5685e1cc37a6ef",
            "placeholder": "​",
            "style": "IPY_MODEL_d84d86ab43654ad380fb3d89a46ef686",
            "value": "Downloading data: 100%"
          }
        },
        "1dbd00cf8ae443879250716892275cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f28ebf59b4354f0eb295a63fd4d39a58",
            "max": 9642971,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc54fe1660d241e081da437819461a49",
            "value": 9642971
          }
        },
        "8f9aa9e31adf4696a29a924bcb16f4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1a3dfc464be49d8b1814f80eb946579",
            "placeholder": "​",
            "style": "IPY_MODEL_e2f6c5ca2f884ab6a955d5f7475170cd",
            "value": " 9.64M/9.64M [00:04&lt;00:00, 2.39MB/s]"
          }
        },
        "fd7b6392c7d346daa35092ead1f456da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ecc4b150ca643c49c5685e1cc37a6ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84d86ab43654ad380fb3d89a46ef686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f28ebf59b4354f0eb295a63fd4d39a58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc54fe1660d241e081da437819461a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1a3dfc464be49d8b1814f80eb946579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2f6c5ca2f884ab6a955d5f7475170cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a459af17368343cf9434d5b21af442fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed8feafade394889860aa20f1bdc3e7c",
              "IPY_MODEL_c7b02fe69d6649a1af129cd1c5aff618",
              "IPY_MODEL_9acbbddf56df466e8cbe6c435b67f561"
            ],
            "layout": "IPY_MODEL_e4beb2b8fabc4495a250a71796ddaae5"
          }
        },
        "ed8feafade394889860aa20f1bdc3e7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5376310cb1104a91b23729702ca350c8",
            "placeholder": "​",
            "style": "IPY_MODEL_16abfbe9e3ab4525b8a622eb36d98824",
            "value": "Generating train split: "
          }
        },
        "c7b02fe69d6649a1af129cd1c5aff618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e019f9d774d5419a9db16efebf1ae2c7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5d749aa21d74facb7c9ac8e022c1f64",
            "value": 1
          }
        },
        "9acbbddf56df466e8cbe6c435b67f561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808ece5d15c8445c87bfa57e8503dd6a",
            "placeholder": "​",
            "style": "IPY_MODEL_d00ff17a0f60455dad7db5ec62936a74",
            "value": " 2140/0 [00:00&lt;00:00, 9711.30 examples/s]"
          }
        },
        "e4beb2b8fabc4495a250a71796ddaae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5376310cb1104a91b23729702ca350c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16abfbe9e3ab4525b8a622eb36d98824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e019f9d774d5419a9db16efebf1ae2c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a5d749aa21d74facb7c9ac8e022c1f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "808ece5d15c8445c87bfa57e8503dd6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d00ff17a0f60455dad7db5ec62936a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Zero-Haruhi/blob/main/notebook/GenerateBaize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UjKaCdO3KeW",
        "outputId": "d059dd4b-6322-45d6-f13f-4e05c2646261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import httpx\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]  = \"sk-WafsA\"\n",
        "\n",
        "import openai"
      ],
      "metadata": {
        "id": "DG75OEm13Sh7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jicFYtUY3U_i",
        "outputId": "7b7781f2-770c-4bb7-f81c-7e86b310c3d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"silk-road/Haruhi-Zero-RolePlaying-movie-PIPPA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "38ca8cb2432b4ad4b2a9af5c36ad20fe",
            "2ae2832017ca424380e05859939e5ecf",
            "2eb8d51e83694c78aca60956437733c1",
            "0b373f7e90ff456c9e9eabe184c4dac1",
            "27d57eff21344d349c50a17a229f2c3c",
            "4ebd1ed8918e41c08c8d8d46a4547914",
            "12fb9fb569c243b89b2fd3d093dde00a",
            "5cf11ff03ac54e4d8836cd0092068df2",
            "d0e3acd6953e434ea8f99e93636e2deb",
            "df45d92729d74d78b672ee8e80ef85fc",
            "14f5d963021945fe988ae77eaa521395",
            "21db3aa686b242c7a9b4149edd57d0da",
            "777320ed9ef64ee9a020b3fc50c5cced",
            "1dbd00cf8ae443879250716892275cb5",
            "8f9aa9e31adf4696a29a924bcb16f4f6",
            "fd7b6392c7d346daa35092ead1f456da",
            "4ecc4b150ca643c49c5685e1cc37a6ef",
            "d84d86ab43654ad380fb3d89a46ef686",
            "f28ebf59b4354f0eb295a63fd4d39a58",
            "dc54fe1660d241e081da437819461a49",
            "e1a3dfc464be49d8b1814f80eb946579",
            "e2f6c5ca2f884ab6a955d5f7475170cd",
            "a459af17368343cf9434d5b21af442fa",
            "ed8feafade394889860aa20f1bdc3e7c",
            "c7b02fe69d6649a1af129cd1c5aff618",
            "9acbbddf56df466e8cbe6c435b67f561",
            "e4beb2b8fabc4495a250a71796ddaae5",
            "5376310cb1104a91b23729702ca350c8",
            "16abfbe9e3ab4525b8a622eb36d98824",
            "e019f9d774d5419a9db16efebf1ae2c7",
            "a5d749aa21d74facb7c9ac8e022c1f64",
            "808ece5d15c8445c87bfa57e8503dd6a",
            "d00ff17a0f60455dad7db5ec62936a74"
          ]
        },
        "id": "IPItUC0Y3YWC",
        "outputId": "75cc14c2-35a9-4bd4-df5b-21f85687231a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/932 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38ca8cb2432b4ad4b2a9af5c36ad20fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/9.64M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21db3aa686b242c7a9b4149edd57d0da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a459af17368343cf9434d5b21af442fa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(dataset['train'])\n",
        "print(n)\n",
        "sel_id1, sel_id2 = 1, 1500\n",
        "\n",
        "print(dataset['train'][sel_id1+10]['prompt_zh'])\n",
        "print(dataset['train'][sel_id2]['prompt_zh'][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT7Izj683tmC",
        "outputId": "069cf99d-6b38-48f9-8d6d-0eaede2b18e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2140\n",
            "你扮演 两男变错身 中的 MITCH\n",
            "MITCH是一个轻浮、放荡的人，外表花花公子，喜欢享受生活，不拘小节。\n",
            "MITCH是一个轻浮、放荡的人\n",
            "MITCH是一个外表花花公子的人\n",
            "这是一个现代都市的场景，MITCH是一个自由奔放的单身汉\n",
            "###\n",
            "DAVE : 好吧，我去搞定\n",
            "MITCH : 早上好啊\n",
            "DAVE : 你们今天起的比较早啊，嗯？\n",
            "MITCH : 有没有做噩梦啊尿床啊什么的？\n",
            "DAVE : 看看给宝宝准备了什么好东西\n",
            "###\n",
            "MITCH : 好了，让老爸歇会儿\n",
            "DAVE : 互换身份\n",
            "MITCH : 早上好LOCKWOOD\n",
            "LOCKWOOD : 早上好，STEEL先生\n",
            "STEEL : 孩子们还好吗\n",
            "###\n",
            "LOCKWOOD : 好的，谢谢！\n",
            "STEEL : （水平不济，以上蒙的）\n",
            "LOCKWOOD : 早上好，PATRICIA\n",
            "PATRICIA : 你好。\n",
            "LOCKWOOD : 大JB，小BB，ED哥，湿湿妹...\n",
            "###\n",
            "STEEL : 哥在公司呢！\n",
            "LOCKWOOD : 被我打败了吧？\n",
            "STEEL : 是的，你牛X！\n",
            "LOCKWOOD : 你刚刚用的免提吧？\n",
            "STEEL : 是啊，你那个秘书听到了吗？\n",
            "###\n",
            "DAVE : 好吧，我郑重的告诉你\n",
            "MITCH : 你老爹我又要婚了\n",
            "DAVE : 我希望你能参加我的婚礼。\n",
            "MITCH : 什么时候？下周六\n",
            "DAVE : 你后妈，PAMELA\n",
            "Luna是Wintenberg的半龙少女，她寻求复仇，是Yufine的同父异母的妹妹，不同于Yufi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "修正movie的bot name\n",
        "\n",
        "实现一个python函数，输入是一段text\n",
        "\n",
        "text中的某一行为\" 你扮演 海上钢琴师 中的 丹尼·布德曼 \" 的格式\n",
        "\n",
        "注意这里中的 后面名字的前后都会有空格\n",
        "\n",
        "提取这个名字，并返回\n",
        "\n",
        "例子输入:\n",
        "你扮演 海上钢琴师 中的 丹尼·布德曼\n",
        "丹尼·布德曼是一个坚韧、热情和有责任感的船员，对音乐有着深厚的情感。\n",
        "丹尼·布德曼是一个坚韧、热情和有责任感的人\n",
        "丹尼·布德曼是一个穿着朴素的船员\n",
        "例子输出\n",
        "丹尼·布德曼\n",
        "\n",
        "例子输入:\n",
        "你扮演 两男变错身 中的 MITCH\n",
        "MITCH是一个轻浮、放荡的人，外表花花公子，喜欢享受生活，不拘小节。\n",
        "MITCH是一个轻浮、放荡的人\n",
        "MITCH是一个外表花花公子的人\n",
        "例子输出\n",
        "MITCH\n",
        "\n",
        "如果没有这样的行，返回\"\"\n"
      ],
      "metadata": {
        "id": "BUq1D6C96nV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_name_from_text(text):\n",
        "    pattern = r'你扮演\\s+.*中的\\s+(\\S+)\\s*'\n",
        "    match = re.search(pattern, text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# 例子输入\n",
        "input_text = \"\"\"你扮演 海上钢琴师 中的 丹尼·布德曼\n",
        "丹尼·布德曼是一个坚韧、热情和有责任感的船员，对音乐有着深厚的情感。\n",
        "丹尼·布德曼是一个坚韧、热情和有责任感的人\n",
        "丹尼·布德曼是一个穿着朴素的船员\"\"\"\n",
        "\n",
        "output = extract_name_from_text(input_text)\n",
        "print(output)  # 输出：丹尼·布德曼\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(extract_name_from_text(dataset['train'][i]['prompt_zh']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opnmr9Cc5buQ",
        "outputId": "64a34c3c-1f9b-4d22-d6e1-f17c6562b1af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "丹尼·布德曼\n",
            "凯瑟琳\n",
            "丹尼·布德曼\n",
            "哈利\n",
            "派\n",
            "Daphne\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "n = len(dataset['train'])\n",
        "for i in range(n):\n",
        "    if dataset['train'][i]['id'].startswith('movie'):\n",
        "        bot_name = extract_name_from_text(dataset['train'][i]['prompt_zh'])\n",
        "        count = count + 1\n",
        "        dataset['train'][i]['bot_name'] = bot_name\n",
        "        if bot_name == dataset['train'][i]['bot_name']:\n",
        "            count = count + 1\n",
        "\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R865vx7e7bzs",
        "outputId": "09be36a8-f31b-40e0-8a9b-8cab1eda7ee0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bDUWEi44_TUW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'][sel_id1]['bot_name'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0-mVCR6_HXp",
        "outputId": "b5d88c52-7f8a-4e1c-f388-ca870ee85707"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La.Leggenda.Del.Pianista.Sull.Oceano.1998.BluRay.EXTENDED.720p.x264.AC3.2Audios-CMCT.简体_英文.srt.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/LC1332/Zero-Haruhi/main/role_10_questions.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrhQnrAQJzy6",
        "outputId": "a5b52567-d20b-4836-f49a-e534d9caece7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-09 00:59:58--  https://raw.githubusercontent.com/LC1332/Zero-Haruhi/main/role_10_questions.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1788187 (1.7M) [text/plain]\n",
            "Saving to: ‘role_10_questions.jsonl’\n",
            "\n",
            "role_10_questions.j 100%[===================>]   1.71M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2024-01-09 00:59:59 (47.6 MB/s) - ‘role_10_questions.jsonl’ saved [1788187/1788187]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('/content/role_10_questions.jsonl', 'r', encoding='utf-8') as f1:\n",
        "    datas = [json.loads(line) for line in f1]"
      ],
      "metadata": {
        "id": "uzfAZYB7KKLg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "id2questions = {}\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "error_count = 0\n",
        "for data in datas:\n",
        "    id = data['id']\n",
        "    response = data['response']\n",
        "    try:\n",
        "        response_in_json = json.loads(response)\n",
        "        questions = response_in_json['questions']\n",
        "        random.shuffle(questions)\n",
        "        id2questions[id] = questions\n",
        "    except:\n",
        "        error_count = error_count + 1\n",
        "        continue\n",
        "print(error_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j83F6jI_KN-J",
        "outputId": "504ab852-868a-4eae-891f-28a1b857c436"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIE6IIO6LJQ_",
        "outputId": "c65f805a-7ff1-4ffd-c57b-13324b754f97"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movie_269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX34ks_HLHIb",
        "outputId": "82d5df0b-a6b0-47b7-ca13-875997e9462f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"keywords\": [\"创业者\", \"商业\", \"创意\", \"营销\", \"大学\", \"年轻\", \"冰淇淋\", \"真名\", \"性紧张\", \"团队\", \"董事会\", \"撒谎\", \"想法\", \"野心\"], \"questions\": [\"斯卡特，你是如何开始你的创业之路的？\", \"你最引以为傲的创意是什么？\", \"在商业世界中，你最大的挑战是什么？\", \"你对撒谎有何看法？\", \"你为什么对她的真名如此在意？\", \"你是如何处理团队中的性紧张问题的？\", \"你对董事会的见面有何期待？\", \"你认为创意和野心哪个更重要？\", \"你对自己的年轻有何看法？\", \"你对大学教育的价值持何看法？\"]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_in_json.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNWjBvu_K-wi",
        "outputId": "d57125bd-8016-4654-9d50-1456d22da327"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['keywords', 'questions'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(\n",
        "    api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        ")\n",
        "\n",
        "def get_response( messages ):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-1106\",\n",
        "        messages=messages,\n",
        "        temperature=0.3\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "4j-hWOptaQGZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatTogether:\n",
        "    def __init__(self, data1, data2, questions = []):\n",
        "\n",
        "        self.ids = [data1['id'], data2['id']]\n",
        "        self.personas = [data1['prompt_zh'], data2['prompt_zh']]\n",
        "\n",
        "        self.greetings = [data1['bot_greeting_zh'], data2['bot_greeting_zh']]\n",
        "        # 在这里我们重点假设2是user， 1是char， 以2向1提问的形式作为主导\n",
        "\n",
        "        self.bot_names = [self.get_bot_name(data1), self.get_bot_name(data2)]\n",
        "\n",
        "        self.replace_name_in_personas(0)\n",
        "        self.replace_name_in_personas(1)\n",
        "\n",
        "        self.chat_history = []\n",
        "\n",
        "        self.initialize_greeting()\n",
        "\n",
        "        self.last_perset_turn = 0\n",
        "\n",
        "        self.questions = questions\n",
        "        self.next_question_index = 0\n",
        "\n",
        "    def get_save_data(self):\n",
        "        return {\n",
        "            'ids': self.ids,\n",
        "            'chat_history': self.chat_history\n",
        "        }\n",
        "\n",
        "    def replace_name_in_personas(self, index):\n",
        "        bot_name = self.bot_names[index]\n",
        "        user_name = self.bot_names[1-index]\n",
        "        self.personas[index] = self.personas[index].replace('{{角色}}', bot_name)\n",
        "        self.personas[index] = self.personas[index].replace('{{用户}}', user_name)\n",
        "        self.greetings[index] = self.greetings[index].replace('{{角色}}', bot_name)\n",
        "        self.greetings[index] = self.greetings[index].replace('{{用户}}', user_name)\n",
        "        self.greetings[index] = self.greetings[index].replace('{{user_name}}', user_name)\n",
        "\n",
        "    def get_next_question(self):\n",
        "        if len(self.questions) == 0 or self.next_question_index >= len(self.questions):\n",
        "            return None\n",
        "        else:\n",
        "            self.next_question_index = self.next_question_index + 1\n",
        "            return self.questions[self.next_question_index]\n",
        "\n",
        "    def get_bot_name(self, data):\n",
        "        if data['id'].startswith('movie'):\n",
        "            name =  extract_name_from_text(data['prompt_zh'])\n",
        "            if name.strip() == '':\n",
        "                name = extract_name_from_text(data['prompt'])\n",
        "            return name\n",
        "        else:\n",
        "            return data['bot_name']\n",
        "\n",
        "    def initialize_greeting(self):\n",
        "        if self.greetings[0].strip() != '':\n",
        "            self.chat_history.append({ 'id':0, 'content': self.greetings[0] })\n",
        "        else:\n",
        "        # 这里最终会改为，一定的概率运行bot[1]的greeting，一定概率运行你好，一定概率直接抛出预设问题\n",
        "            self.chat_history.append({ 'id':1, 'content': \"你好，\" + self.bot_names[0] })\n",
        "        self.last_perset_turn = len(self.chat_history)\n",
        "\n",
        "    def next_speaker(self):\n",
        "        if len(self.chat_history) == 0:\n",
        "            return 1\n",
        "        else:\n",
        "            return 1 - self.chat_history[-1]['id']\n",
        "\n",
        "    def get_next_query_messages( self ):\n",
        "\n",
        "        if len(self.chat_history) == 0:\n",
        "            return None\n",
        "\n",
        "        if self.chat_history[-1]['id'] == 0 and len(self.chat_history)-self.last_perset_turn >= 3:\n",
        "            next_question = self.get_next_question()\n",
        "            if next_question is not None:\n",
        "                self.chat_history.append({ 'id':1, 'content': next_question })\n",
        "                self.last_perset_turn = len(self.chat_history)\n",
        "\n",
        "        # 先判断要的是哪个人的数据\n",
        "        now_speaker = 1 - self.chat_history[-1]['id']\n",
        "        messages = [{\"role\" :\"system\" , \"content\":self.get_system_prompt( now_speaker )} ]\n",
        "        for msg in self.chat_history:\n",
        "            if msg['id'] == now_speaker:\n",
        "                messages.append({\"role\" : \"assistant\" , \"content\":msg['content']})\n",
        "            else:\n",
        "                messages.append({\"role\" : \"user\" , \"content\":msg['content']})\n",
        "        return messages\n",
        "\n",
        "    def append_message(self, message):\n",
        "        self.chat_history.append({ 'id':self.next_speaker(), 'content': message })\n",
        "\n",
        "    def get_system_prompt(self, speaker):\n",
        "        persona = self.personas[speaker]\n",
        "        bot_name = self.bot_names[speaker]\n",
        "        prompt = f\"\"\"You are now in roleplay conversation mode. Pretend to be {bot_name} whose persona follows:\n",
        "{persona}\n",
        "\n",
        "You will stay in-character whenever possible, and generate responses as if you were {bot_name}\"\"\"\n",
        "        return prompt\n",
        "\n",
        "\n",
        "sel_id1 = 8\n",
        "data1 = dataset['train'][sel_id1]\n",
        "data2 = dataset['train'][sel_id2]\n",
        "id_str1 = data1['id']\n",
        "\n",
        "questions = id2questions[id_str1]\n",
        "\n",
        "chat_data = ChatTogether(data1, data2,questions)\n",
        "\n",
        "for i in range(6):\n",
        "    messages = chat_data.get_next_query_messages()\n",
        "    print(messages[-1]['content'])\n",
        "    response = \"res for \" + messages[-1]['content']\n",
        "    chat_data.append_message(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4euJ2-u4IGa",
        "outputId": "f23410a5-74c7-43da-b084-1d8626e9e077"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "你好，Bernie\n",
            "res for 你好，Bernie\n",
            "res for res for 你好，Bernie\n",
            "你觉得自己的直接语言风格有何优势？\n",
            "res for 你觉得自己的直接语言风格有何优势？\n",
            "res for res for 你觉得自己的直接语言风格有何优势？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chat_data = ChatTogether(data1, data2,questions)\n",
        "\n",
        "# for i in range(6):\n",
        "#     messages = chat_data.get_next_query_messages()\n",
        "#     response = get_response( messages )\n",
        "#     chat_data.append_message(response)\n",
        "#     print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SBwslIUaNZv",
        "outputId": "82f7eb49-4091-477f-9df5-872d31dab0fc"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "嘿，有什么事吗？\n",
            "我正在寻找那些屠杀人类的邪恶团体和在龙族社会中煽动对人类仇恨的龙。你有没有听说过这样的人或者组织？\n",
            "抱歉，我不知道你在说什么。我只是一个普通的人，和这些事情没什么关系。\n",
            "我只是一个普通人，有时候人们会误解我。但我不在乎别人怎么评价我，我只关心我自己和我家人的生活。\n",
            "我理解。对于普通人来说，家人和生活是最重要的。但是对于我来说，我的目标是消灭那些屠杀人类的邪恶团体和在龙族社会中煽动对人类仇恨的龙。这是我的责任，也是我的目标。\n",
            "听起来你有很大的使命感。但是我只是一个普通人，对于这些事情我没有什么发言权。希望你能够找到你要寻找的那些人。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = chat_data.chat_history\n",
        "\n",
        "for msg in history:\n",
        "    print(msg['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVwPul66aH3z",
        "outputId": "91cf646e-a64a-442f-f8a7-033e92f1c44c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "你好，Bernie\n",
            "res for 你好，Bernie\n",
            "res for res for 你好，Bernie\n",
            "res for res for res for 你好，Bernie\n",
            "你觉得自己的直接语言风格有何优势？\n",
            "res for 你觉得自己的直接语言风格有何优势？\n",
            "res for res for 你觉得自己的直接语言风格有何优势？\n",
            "res for res for res for 你觉得自己的直接语言风格有何优势？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ ] 生成chater - questioner 的long pair list\n",
        "- [ ] 编写一个框架 对每个list 询问7次 并行获取结果并保存"
      ],
      "metadata": {
        "id": "b-BFlrDYcxLy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C0PVCtlr7t6_"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    rand_id = random.randint(0, n-1)\n",
        "    print(dataset['train'][rand_id]['bot_name'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpqDAYNegQVj",
        "outputId": "502c84c0-dda0-4a67-abb2-2d9ec0391014"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nekopara\n",
            "Santetsu Tokuhara\n",
            "Nymphia\n",
            "第23话 数码暴龙机被黑暗污染时.chs.ass.txt\n",
            "Bandit Hermit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q aiofiles tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1HAKIo5gJj2",
        "outputId": "972f0a60-f7b7-44ae-bae7-a33941a9c356"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/2.0 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/2.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m1.6/2.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0UeZOEoRhLOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "char_list和questioner_list 都是list of int\n",
        "\n",
        "我希望循环N次\n",
        "\n",
        "每次，对于char_list的每一个元素c，选取questioner_list中的元素q，并且c不等于q，形成一个tuple，\n",
        "\n",
        "并且保证(c,q)和(q,c)这两个tuple都没有在历史中重复出现。"
      ],
      "metadata": {
        "id": "7ARAuLqrhat6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = len(dataset['train'])\n",
        "\n",
        "char_list = []\n",
        "\n",
        "for i in range(n):\n",
        "    id = dataset['train'][i]['id']\n",
        "    if id not in id2questions:\n",
        "        continue\n",
        "    char_list.append(i)\n",
        "\n",
        "questioner_list = [i for i in range(n)]\n",
        "\n",
        "tuple_list = []\n",
        "\n",
        "repeat_times = 40\n",
        "\n",
        "n_char = len(char_list)\n",
        "n_ques = len(questioner_list)\n",
        "\n",
        "char_history = [set() for _ in range(len(questioner_list))]\n",
        "\n",
        "random.seed(123)\n",
        "\n",
        "for iter in range(repeat_times):\n",
        "    random.shuffle(questioner_list)\n",
        "    for i in range(n_char):\n",
        "        c = char_list[i]\n",
        "        q = questioner_list[i]\n",
        "        max_test_time = 5\n",
        "        while max_test_time > 0:\n",
        "            if c != q and q not in char_history[c]:\n",
        "                tuple_list.append((c,q))\n",
        "                char_history[c].add(q)\n",
        "                break\n",
        "            max_test_time -= 1\n",
        "            q = random.randint(0, n_ques-1)\n",
        "\n",
        "print(tuple_list[5000:5010])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEeZ9BbVhNrP",
        "outputId": "62017e9a-54f6-4f10-cfd9-d7aad8100c72"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(768, 1106), (769, 569), (770, 2080), (771, 1994), (772, 1), (773, 1279), (774, 848), (775, 1050), (776, 126), (777, 1229)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WNTqgzUajFk1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tuple_list[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsccXI-AkxS5",
        "outputId": "8088b220-8b1c-4af0-f82e-725cb471624e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(102, 737)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "# import openai\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "aclient = AsyncOpenAI()\n",
        "\n",
        "import asyncio\n",
        "import aiofiles\n",
        "import tiktoken\n",
        "import hashlib\n",
        "# from connector import AsyncPGConnector\n",
        "from tqdm.asyncio import tqdm as tqdm\n",
        "\n",
        "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "en2zh_ratio = 2.3\n",
        "\n",
        "delay = 1\n",
        "concurrency_limit = 16\n",
        "\n",
        "max_file_size = 1024**3"
      ],
      "metadata": {
        "id": "-iyy4HUHlCwf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def dealing_messages(messages):\n",
        "    try:\n",
        "        # request_token = sum([len(enc.encode(msg['content'])) for msg in messages])\n",
        "        # response_token = int(len(enc.encode(text)) * en2zh_ratio) + 64\n",
        "\n",
        "        model = \"gpt-3.5-turbo-1106\"\n",
        "\n",
        "        resp = await aclient.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=0.3,\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            result = resp.choices[0].message.content\n",
        "            result = result.strip()\n",
        "            return result\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Invalid json: \", result)\n",
        "            return None\n",
        "        except:\n",
        "            raise Exception(f\"Invalid API response: {resp}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[Error] {e}\")\n",
        "        return None\n",
        "\n",
        "async def getTranslation(item):\n",
        "    if \"messages\" not in item:\n",
        "        return None\n",
        "    else:\n",
        "        for i in range(3):\n",
        "            result = await dealing_messages(item['messages'])\n",
        "            if result is not None:\n",
        "                item[\"response\"] = result\n",
        "                return item\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    return None\n",
        "\n",
        "async def process(item, semaphore):\n",
        "    async with semaphore:\n",
        "        try:\n",
        "            output_folder = \"/content/output\"\n",
        "            if \"output_folder\" in item:\n",
        "                output_folder = item[\"output_folder\"]\n",
        "            if not os.path.exists(output_folder):\n",
        "                os.makedirs(output_folder)\n",
        "\n",
        "            file_path = os.path.join(output_folder, f\"{item['id']}.txt\")\n",
        "\n",
        "            if os.path.exists(file_path):\n",
        "                return\n",
        "\n",
        "            it = await getTranslation(item)\n",
        "            if it is None:\n",
        "                raise Exception(item['id'])\n",
        "\n",
        "            with open(file_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(it, f, ensure_ascii=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing entry: {e}\")\n"
      ],
      "metadata": {
        "id": "QmSY3FapoJYV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def main(chat_datas, output_folder, turn_id):\n",
        "    process_data = []\n",
        "\n",
        "    for data in chat_datas:\n",
        "        messages = data.get_next_query_messages()\n",
        "        ids = data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        process_data.append({\n",
        "            \"id\": uniqure_id,\n",
        "            \"messages\": messages,\n",
        "            \"output_folder\": output_folder\n",
        "        })\n",
        "\n",
        "    tasks = []\n",
        "\n",
        "    semaphore = asyncio.Semaphore(concurrency_limit)\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # # print(f\"Already processed {len(exist_list)} items...\")\n",
        "\n",
        "    # id = set()\n",
        "\n",
        "    for item in process_data:\n",
        "        file_path = os.path.join(output_folder, f\"{item['id']}.txt\")\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            continue\n",
        "\n",
        "        tasks.append(asyncio.create_task(process(item, semaphore)))\n",
        "\n",
        "    # # del exist_list\n",
        "    # print(f\"Total items: {len(process_data)}\")\n",
        "\n",
        "    async for task in tqdm(tasks, total=len(tasks), desc=\"Processing items\"):\n",
        "        await task\n",
        "        time.sleep(delay)\n",
        "\n"
      ],
      "metadata": {
        "id": "aMkciw1yoTeg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_8Q8HN-Ao-UK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oF5kzkGtaGc",
        "outputId": "be85db1f-d30e-4e5c-ae21-314638de160e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/CardBuild/roleBaize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH4_BOuWuJsx",
        "outputId": "9313f09d-3b7d-4789-dc80-5b464c707582"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10_to_200.txt  200_to_4000.txt\tfirst_10.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = 0\n",
        "end_id = 10\n",
        "final_save_name = \"/content/drive/MyDrive/CardBuild/roleBaize/first_10.txt\"\n",
        "\n",
        "\n",
        "chat_datas = []\n",
        "\n",
        "for i in range(start_id, end_id):\n",
        "    c, q = tuple_list[i]\n",
        "    data1 = dataset['train'][c]\n",
        "    data2 = dataset['train'][q]\n",
        "    id_str1 = data1['id']\n",
        "    questions = id2questions[id_str1]\n",
        "    chat_data = ChatTogether(data1, data2,questions)\n",
        "    chat_datas.append(chat_data)"
      ],
      "metadata": {
        "id": "ICO7hj-PvebA"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_data = []\n",
        "\n",
        "temp_folder = \"/content/drive/MyDrive/CardBuild/exp0108\"\n",
        "\n",
        "for turn_id in range(7):\n",
        "    output_folder = \"/content/output_\" + str( turn_id )\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    print('finished all query')\n",
        "\n",
        "    for chat_data in chat_datas:\n",
        "        messages = chat_data.get_next_query_messages()\n",
        "        ids = chat_data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        save_name = uniqure_id + \".txt\"\n",
        "        save_path = os.path.join(output_folder, save_name)\n",
        "        if os.path.exists(save_path):\n",
        "            with open(save_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                    response = data['response']\n",
        "                    # print(response)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        chat_data.append_message(response)\n",
        "\n",
        "    save_data_file_name = os.path.basename(final_save_name) + \"_turn_\" + str(turn_id) + \".txt\"\n",
        "    save_data_file_path = os.path.join(temp_folder, save_data_file_name)\n",
        "\n",
        "    for file_name in [save_data_file_path, final_save_name]:\n",
        "        with open(file_name, 'w', encoding='utf-8') as f:\n",
        "            for data in chat_datas:\n",
        "                json.dump(data.get_save_data(), f, ensure_ascii=False)\n",
        "                f.write('\\n')\n",
        "\n",
        "    # 在这里为我补充一段代码，chat_datas中的data.get_save_data() 会返回一个dict，将所有的chat_datas中的save data\n",
        "    # 分别保存在save_name, 以及temp_folder中，以save_name的文件名 + _turn_id.txt 命名的文件中"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSGD6xEqo-di",
        "outputId": "ce45308f-5879-43d5-f35b-e0d57ff30ba5"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:12<00:00,  1.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:15<00:00,  1.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:16<00:00,  1.65s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:13<00:00,  1.32s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:13<00:00,  1.40s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:15<00:00,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_datas[0].get_next_query_messages())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoC-xpA4pnMC",
        "outputId": "e38d94c4-2c1f-46a3-fd91-86e5b7748e6e"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': \"You are now in roleplay conversation mode. Pretend to be 凯瑟琳 whose persona follows:\\n你扮演 You've Got Mail 中的 凯瑟琳\\n凯瑟琳是一个独立、聪明、幽默的女性，她在现代都市中经营一家书店，展现出自信和独立的品质。\\n凯瑟琳是一个独立、聪明、幽默的女性\\n凯瑟琳是一个时尚、自信的女性\\n这是一个现代都市的场景，凯瑟琳是一家书店的老板\\n凯瑟琳的语言风格是幽默、直率的\\n###\\n凯瑟琳 : I hear nothing, not even a sound on the streets of New York.\\n{{user}} : ♪千变万化♪\\n{{user}} : ♪In every possible way♪\\n凯瑟琳 : 只有我自己的心跳声\\n凯瑟琳 : Just the beat of my own heart.\\n###\\n克里斯蒂娜 : 你和帕特丽夏订婚了  对吗\\n克里斯蒂娜 : 你可以告诉我的\\n凯瑟琳 : 订婚\\n{{user}} : Engaged?\\n凯瑟琳 : 得了吧\\n###\\n{{user}} : 你恋爱了\\n凯瑟琳 : 恋爱  不  才没有\\n凯瑟琳 : Oh, yes, that's right! I'm in love with Frank.\\n凯瑟琳 : 我几乎算是和弗兰克同居了\\n###\\n{{user}} : 你能在这周之内把我们的圣诞宣传广告发出去吗\\n凯瑟琳 : 好  我保证在下周一前完成\\n{{user}} : I just, I have this paper due Friday.\\n###\\n{{user}} : 如果你通过邮件结识了一个人  这算不忠吗\\n{{user}} : 你们做过爱了吗\\n凯瑟琳 : 当然没有  我都不认识他\\n{{user}} : Well, don't do it. The minute you do, you lose all respect for you.\\n\\nYou will stay in-character whenever possible, and generate responses as if you were 凯瑟琳\"}, {'role': 'user', 'content': '你好，凯瑟琳。我是Rika Kawai'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_datas[0].get_save_data())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IUAKeGYpfeW",
        "outputId": "af271c55-b077-4e89-93fd-c90e9e715c42"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ids': ['movie_0', 'PIPPA_106'], 'chat_history': [{'id': 1, 'content': '你好，凯瑟琳。我是Rika Kawai'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = 10\n",
        "end_id = 200\n",
        "final_save_name = \"/content/drive/MyDrive/CardBuild/roleBaize/10_to_200.txt\"\n",
        "\n",
        "\n",
        "chat_datas = []\n",
        "\n",
        "for i in range(start_id, end_id):\n",
        "    c, q = tuple_list[i]\n",
        "    data1 = dataset['train'][c]\n",
        "    data2 = dataset['train'][q]\n",
        "    id_str1 = data1['id']\n",
        "    questions = id2questions[id_str1]\n",
        "    random.shuffle(questions)\n",
        "    chat_data = ChatTogether(data1, data2,questions)\n",
        "    chat_datas.append(chat_data)"
      ],
      "metadata": {
        "id": "N_cRW9Dduaj4"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_data = []\n",
        "\n",
        "temp_folder = \"/content/drive/MyDrive/CardBuild/exp0108\"\n",
        "\n",
        "for turn_id in range(7):\n",
        "    output_folder = \"/content/output_\" + str( turn_id )\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    print('finished all query')\n",
        "\n",
        "    for chat_data in chat_datas:\n",
        "        messages = chat_data.get_next_query_messages()\n",
        "        ids = chat_data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        save_name = uniqure_id + \".txt\"\n",
        "        save_path = os.path.join(output_folder, save_name)\n",
        "        if os.path.exists(save_path):\n",
        "            with open(save_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                    response = data['response']\n",
        "                    # print(response)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        chat_data.append_message(response)\n",
        "\n",
        "    save_data_file_name = os.path.basename(final_save_name) + \"_turn_\" + str(turn_id) + \".txt\"\n",
        "    save_data_file_path = os.path.join(temp_folder, save_data_file_name)\n",
        "\n",
        "    for file_name in [save_data_file_path, final_save_name]:\n",
        "        with open(file_name, 'w', encoding='utf-8') as f:\n",
        "            for data in chat_datas:\n",
        "                json.dump(data.get_save_data(), f, ensure_ascii=False)\n",
        "                f.write('\\n')\n",
        "\n",
        "    # 在这里为我补充一段代码，chat_datas中的data.get_save_data() 会返回一个dict，将所有的chat_datas中的save data\n",
        "    # 分别保存在save_name, 以及temp_folder中，以save_name的文件名 + _turn_id.txt 命名的文件中"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jIDdH8JxTnl",
        "outputId": "e890f73e-8a9a-49ee-e5f2-4ea9e8f0d171"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 190/190 [03:31<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 190/190 [03:34<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 190/190 [03:41<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 190/190 [03:45<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 190/190 [03:33<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 190/190 [03:37<00:00,  1.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 190/190 [03:39<00:00,  1.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = 200\n",
        "end_id = 4000\n",
        "final_save_name = \"/content/drive/MyDrive/CardBuild/roleBaize/200_to_4000.txt\"\n",
        "\n",
        "\n",
        "chat_datas = []\n",
        "\n",
        "for i in range(start_id, end_id):\n",
        "    c, q = tuple_list[i]\n",
        "    data1 = dataset['train'][c]\n",
        "    data2 = dataset['train'][q]\n",
        "    id_str1 = data1['id']\n",
        "    questions = id2questions[id_str1]\n",
        "    random.shuffle(questions)\n",
        "    chat_data = ChatTogether(data1, data2,questions)\n",
        "    chat_datas.append(chat_data)"
      ],
      "metadata": {
        "id": "h6zgFwj9xWI8"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_data = []\n",
        "\n",
        "temp_folder = \"/content/drive/MyDrive/CardBuild/exp0108\"\n",
        "\n",
        "for turn_id in range(7):\n",
        "    output_folder = \"/content/output_\" + str( turn_id )\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    print('finished all query')\n",
        "\n",
        "    for chat_data in chat_datas:\n",
        "        messages = chat_data.get_next_query_messages()\n",
        "        ids = chat_data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        save_name = uniqure_id + \".txt\"\n",
        "        save_path = os.path.join(output_folder, save_name)\n",
        "        if os.path.exists(save_path):\n",
        "            with open(save_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                    response = data['response']\n",
        "                    # print(response)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        chat_data.append_message(response)\n",
        "\n",
        "    save_data_file_name = os.path.basename(final_save_name) + \"_turn_\" + str(turn_id) + \".txt\"\n",
        "    save_data_file_path = os.path.join(temp_folder, save_data_file_name)\n",
        "\n",
        "    for file_name in [save_data_file_path, final_save_name]:\n",
        "        with open(file_name, 'w', encoding='utf-8') as f:\n",
        "            for data in chat_datas:\n",
        "                json.dump(data.get_save_data(), f, ensure_ascii=False)\n",
        "                f.write('\\n')\n",
        "\n",
        "    # 在这里为我补充一段代码，chat_datas中的data.get_save_data() 会返回一个dict，将所有的chat_datas中的save data\n",
        "    # 分别保存在save_name, 以及temp_folder中，以save_name的文件名 + _turn_id.txt 命名的文件中"
      ],
      "metadata": {
        "id": "njNxsON43kXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = 4000\n",
        "end_id = 6354\n",
        "final_save_name = \"/content/drive/MyDrive/CardBuild/roleBaize/4000_to_6354.txt\"\n",
        "\n",
        "\n",
        "chat_datas = []\n",
        "\n",
        "for i in range(start_id, end_id):\n",
        "    c, q = tuple_list[i]\n",
        "    data1 = dataset['train'][c]\n",
        "    data2 = dataset['train'][q]\n",
        "    id_str1 = data1['id']\n",
        "    questions = id2questions[id_str1]\n",
        "    random.shuffle(questions)\n",
        "    chat_data = ChatTogether(data1, data2,questions)\n",
        "    chat_datas.append(chat_data)"
      ],
      "metadata": {
        "id": "-vU1to933oLe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_data = []\n",
        "\n",
        "temp_folder = \"/content/drive/MyDrive/CardBuild/exp0108\"\n",
        "\n",
        "for turn_id in range(7):\n",
        "    output_folder = \"/content/output_\" + str( turn_id )\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    print('finished all query')\n",
        "\n",
        "    for chat_data in chat_datas:\n",
        "        messages = chat_data.get_next_query_messages()\n",
        "        ids = chat_data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        save_name = uniqure_id + \".txt\"\n",
        "        save_path = os.path.join(output_folder, save_name)\n",
        "        if os.path.exists(save_path):\n",
        "            with open(save_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                    response = data['response']\n",
        "                    # print(response)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        chat_data.append_message(response)\n",
        "\n",
        "    save_data_file_name = os.path.basename(final_save_name) + \"_turn_\" + str(turn_id) + \".txt\"\n",
        "    save_data_file_path = os.path.join(temp_folder, save_data_file_name)\n",
        "\n",
        "    for file_name in [save_data_file_path, final_save_name]:\n",
        "        with open(file_name, 'w', encoding='utf-8') as f:\n",
        "            for data in chat_datas:\n",
        "                json.dump(data.get_save_data(), f, ensure_ascii=False)\n",
        "                f.write('\\n')\n",
        "\n",
        "    # 在这里为我补充一段代码，chat_datas中的data.get_save_data() 会返回一个dict，将所有的chat_datas中的save data\n",
        "    # 分别保存在save_name, 以及temp_folder中，以save_name的文件名 + _turn_id.txt 命名的文件中"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JZotwdGvQem",
        "outputId": "a46e256c-aeac-474d-e763-559b8554c3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:   7%|▋         | 169/2354 [03:05<36:49,  1.01s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EcmO3OI-vUvG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}