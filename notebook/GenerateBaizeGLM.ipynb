{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP66cWWMH09FHpGjOGcvwpG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d5001dcef9d4110a027d31aa9f943bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fd831fb12784f5b9d75637091ee9ad2",
              "IPY_MODEL_3482ecfc798a429d8be3f2c18c68ae57",
              "IPY_MODEL_9af68c4524b949fa8a906d781cded914"
            ],
            "layout": "IPY_MODEL_93ab571fe79d4b5f8dd11e0e4dd8da54"
          }
        },
        "4fd831fb12784f5b9d75637091ee9ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16b458ca3a4e419191a6af72ce82afe8",
            "placeholder": "​",
            "style": "IPY_MODEL_046bcce7e4cf453fa249288ee1caa4bf",
            "value": "Downloading readme: 100%"
          }
        },
        "3482ecfc798a429d8be3f2c18c68ae57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a17efd96e2747ef94897af543004140",
            "max": 932,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77636b57b9c64df8a6b9386af8421338",
            "value": 932
          }
        },
        "9af68c4524b949fa8a906d781cded914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7337397c55c42acab0cced57e8bd17b",
            "placeholder": "​",
            "style": "IPY_MODEL_3c3491b61c774135b4c5b4d79acbdfc7",
            "value": " 932/932 [00:00&lt;00:00, 41.8kB/s]"
          }
        },
        "93ab571fe79d4b5f8dd11e0e4dd8da54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16b458ca3a4e419191a6af72ce82afe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "046bcce7e4cf453fa249288ee1caa4bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a17efd96e2747ef94897af543004140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77636b57b9c64df8a6b9386af8421338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7337397c55c42acab0cced57e8bd17b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c3491b61c774135b4c5b4d79acbdfc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a3dca68ffbd4f41957be7bec2214881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4c8d5591f6843d7891ff016961fd87d",
              "IPY_MODEL_903cc672b6ef412c8b15324decdf2e6f",
              "IPY_MODEL_a5ae95af1bfe49ff95f8c44698c3ffc9"
            ],
            "layout": "IPY_MODEL_229c00f6a9df49f099efec44bf3b3548"
          }
        },
        "b4c8d5591f6843d7891ff016961fd87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b94765cf6c174a2297f6a17f2ffe1e97",
            "placeholder": "​",
            "style": "IPY_MODEL_55d610062ba6471a85c4c47cc2bb3912",
            "value": "Downloading data: 100%"
          }
        },
        "903cc672b6ef412c8b15324decdf2e6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeeabf750f264980bd44f2339c493a0d",
            "max": 9642971,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2773968a5da441aaa9160d22c0b8a0cb",
            "value": 9642971
          }
        },
        "a5ae95af1bfe49ff95f8c44698c3ffc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd848bcc69c245eca175fdad37164338",
            "placeholder": "​",
            "style": "IPY_MODEL_884e0061914d4790bd8c63db6ea26707",
            "value": " 9.64M/9.64M [00:02&lt;00:00, 4.12MB/s]"
          }
        },
        "229c00f6a9df49f099efec44bf3b3548": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b94765cf6c174a2297f6a17f2ffe1e97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d610062ba6471a85c4c47cc2bb3912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeeabf750f264980bd44f2339c493a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2773968a5da441aaa9160d22c0b8a0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd848bcc69c245eca175fdad37164338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "884e0061914d4790bd8c63db6ea26707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b69822948f7a47d5972829d85774e984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d9baca0430c452a8f626a80b1e8ddcd",
              "IPY_MODEL_637722708c934ee6bd10b2be5f6d0d9f",
              "IPY_MODEL_a34ccc24b7f344778e533abb3525084c"
            ],
            "layout": "IPY_MODEL_7162bb99af38460c99dd6e0f1c2f37d0"
          }
        },
        "3d9baca0430c452a8f626a80b1e8ddcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3ee41049aa6464881270f2703108a71",
            "placeholder": "​",
            "style": "IPY_MODEL_2e2aa7e9c1a14bcfb4e4584c88f96475",
            "value": "Generating train split: "
          }
        },
        "637722708c934ee6bd10b2be5f6d0d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fd96c5dd4c6418f91898d380dd48eb5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f3f01bf4b2a4b1aafb9122848dee856",
            "value": 1
          }
        },
        "a34ccc24b7f344778e533abb3525084c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7d8b7a23a36468bb57fe62a5adf3112",
            "placeholder": "​",
            "style": "IPY_MODEL_d0d45d13b8ad4deea31a7980caeb07e0",
            "value": " 2140/0 [00:00&lt;00:00, 6148.91 examples/s]"
          }
        },
        "7162bb99af38460c99dd6e0f1c2f37d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3ee41049aa6464881270f2703108a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e2aa7e9c1a14bcfb4e4584c88f96475": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fd96c5dd4c6418f91898d380dd48eb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4f3f01bf4b2a4b1aafb9122848dee856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7d8b7a23a36468bb57fe62a5adf3112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0d45d13b8ad4deea31a7980caeb07e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Zero-Haruhi/blob/main/notebook/GenerateBaizeGLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7UjKaCdO3KeW"
      },
      "outputs": [],
      "source": [
        "!pip install -q zhipuai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "\n",
        "import zhipuai\n",
        "\n",
        "zhipuai.api_key  = \"7504f5\""
      ],
      "metadata": {
        "id": "DG75OEm13Sh7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jicFYtUY3U_i",
        "outputId": "7dfb0014-dcdd-4c9d-ab53-94cceaa336da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"silk-road/Haruhi-Zero-RolePlaying-movie-PIPPA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "4d5001dcef9d4110a027d31aa9f943bd",
            "4fd831fb12784f5b9d75637091ee9ad2",
            "3482ecfc798a429d8be3f2c18c68ae57",
            "9af68c4524b949fa8a906d781cded914",
            "93ab571fe79d4b5f8dd11e0e4dd8da54",
            "16b458ca3a4e419191a6af72ce82afe8",
            "046bcce7e4cf453fa249288ee1caa4bf",
            "6a17efd96e2747ef94897af543004140",
            "77636b57b9c64df8a6b9386af8421338",
            "c7337397c55c42acab0cced57e8bd17b",
            "3c3491b61c774135b4c5b4d79acbdfc7",
            "0a3dca68ffbd4f41957be7bec2214881",
            "b4c8d5591f6843d7891ff016961fd87d",
            "903cc672b6ef412c8b15324decdf2e6f",
            "a5ae95af1bfe49ff95f8c44698c3ffc9",
            "229c00f6a9df49f099efec44bf3b3548",
            "b94765cf6c174a2297f6a17f2ffe1e97",
            "55d610062ba6471a85c4c47cc2bb3912",
            "aeeabf750f264980bd44f2339c493a0d",
            "2773968a5da441aaa9160d22c0b8a0cb",
            "bd848bcc69c245eca175fdad37164338",
            "884e0061914d4790bd8c63db6ea26707",
            "b69822948f7a47d5972829d85774e984",
            "3d9baca0430c452a8f626a80b1e8ddcd",
            "637722708c934ee6bd10b2be5f6d0d9f",
            "a34ccc24b7f344778e533abb3525084c",
            "7162bb99af38460c99dd6e0f1c2f37d0",
            "b3ee41049aa6464881270f2703108a71",
            "2e2aa7e9c1a14bcfb4e4584c88f96475",
            "3fd96c5dd4c6418f91898d380dd48eb5",
            "4f3f01bf4b2a4b1aafb9122848dee856",
            "e7d8b7a23a36468bb57fe62a5adf3112",
            "d0d45d13b8ad4deea31a7980caeb07e0"
          ]
        },
        "id": "IPItUC0Y3YWC",
        "outputId": "c59076c8-a789-4708-fb35-4e99388859d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/932 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d5001dcef9d4110a027d31aa9f943bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/9.64M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a3dca68ffbd4f41957be7bec2214881"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b69822948f7a47d5972829d85774e984"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(dataset['train'])\n",
        "print(n)\n",
        "sel_id1, sel_id2 = 1, 1500\n",
        "\n",
        "print(dataset['train'][sel_id1+10]['prompt_zh'])\n",
        "print(dataset['train'][sel_id2]['prompt_zh'][:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT7Izj683tmC",
        "outputId": "a14505ba-b840-448c-908a-11f806c1be93"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2140\n",
            "你扮演 两男变错身 中的 MITCH\n",
            "MITCH是一个轻浮、放荡的人，外表花花公子，喜欢享受生活，不拘小节。\n",
            "MITCH是一个轻浮、放荡的人\n",
            "MITCH是一个外表花花公子的人\n",
            "这是一个现代都市的场景，MITCH是一个自由奔放的单身汉\n",
            "###\n",
            "DAVE : 好吧，我去搞定\n",
            "MITCH : 早上好啊\n",
            "DAVE : 你们今天起的比较早啊，嗯？\n",
            "MITCH : 有没有做噩梦啊尿床啊什么的？\n",
            "DAVE : 看看给宝宝准备了什么好东西\n",
            "###\n",
            "MITCH : 好了，让老爸歇会儿\n",
            "DAVE : 互换身份\n",
            "MITCH : 早上好LOCKWOOD\n",
            "LOCKWOOD : 早上好，STEEL先生\n",
            "STEEL : 孩子们还好吗\n",
            "###\n",
            "LOCKWOOD : 好的，谢谢！\n",
            "STEEL : （水平不济，以上蒙的）\n",
            "LOCKWOOD : 早上好，PATRICIA\n",
            "PATRICIA : 你好。\n",
            "LOCKWOOD : 大JB，小BB，ED哥，湿湿妹...\n",
            "###\n",
            "STEEL : 哥在公司呢！\n",
            "LOCKWOOD : 被我打败了吧？\n",
            "STEEL : 是的，你牛X！\n",
            "LOCKWOOD : 你刚刚用的免提吧？\n",
            "STEEL : 是啊，你那个秘书听到了吗？\n",
            "###\n",
            "DAVE : 好吧，我郑重的告诉你\n",
            "MITCH : 你老爹我又要婚了\n",
            "DAVE : 我希望你能参加我的婚礼。\n",
            "MITCH : 什么时候？下周六\n",
            "DAVE : 你后妈，PAMELA\n",
            "Luna是Wintenberg的半龙少女，她寻求复仇，是Yufine的同父异母的妹妹，不同于Yufi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "修正movie的bot name\n",
        "\n",
        "实现一个python函数，输入是一段text\n",
        "\n",
        "text中的某一行为\" 你扮演 海上钢琴师 中的 丹尼·布德曼 \" 的格式\n",
        "\n",
        "注意这里中的 后面名字的前后都会有空格\n",
        "\n",
        "提取这个名字，并返回\n",
        "\n",
        "例子输入:\n",
        "你扮演 海上钢琴师 中的 丹尼·布德曼\n",
        "丹尼·布德曼是一个坚韧、热情和有责任感的船员，对音乐有着深厚的情感。\n",
        "丹尼·布德曼是一个坚韧、热情和有责任感的人\n",
        "丹尼·布德曼是一个穿着朴素的船员\n",
        "例子输出\n",
        "丹尼·布德曼\n",
        "\n",
        "例子输入:\n",
        "你扮演 两男变错身 中的 MITCH\n",
        "MITCH是一个轻浮、放荡的人，外表花花公子，喜欢享受生活，不拘小节。\n",
        "MITCH是一个轻浮、放荡的人\n",
        "MITCH是一个外表花花公子的人\n",
        "例子输出\n",
        "MITCH\n",
        "\n",
        "如果没有这样的行，返回\"\"\n"
      ],
      "metadata": {
        "id": "BUq1D6C96nV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_name_from_text(text):\n",
        "    pattern = r'你扮演\\s+.*中的\\s+(\\S+)\\s*'\n",
        "    match = re.search(pattern, text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# 例子输入\n",
        "input_text = \"\"\"你扮演 海上钢琴师 中的 丹尼·布德曼\n",
        "丹尼·布德曼是一个坚韧、热情和有责任感的船员，对音乐有着深厚的情感。\n",
        "丹尼·布德曼是一个坚韧、热情和有责任感的人\n",
        "丹尼·布德曼是一个穿着朴素的船员\"\"\"\n",
        "\n",
        "output = extract_name_from_text(input_text)\n",
        "print(output)  # 输出：丹尼·布德曼\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(extract_name_from_text(dataset['train'][i]['prompt_zh']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opnmr9Cc5buQ",
        "outputId": "0417a2bf-5f78-43eb-c970-a965e1b1a94a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "丹尼·布德曼\n",
            "凯瑟琳\n",
            "丹尼·布德曼\n",
            "哈利\n",
            "派\n",
            "Daphne\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "n = len(dataset['train'])\n",
        "for i in range(n):\n",
        "    if dataset['train'][i]['id'].startswith('movie'):\n",
        "        bot_name = extract_name_from_text(dataset['train'][i]['prompt_zh'])\n",
        "        count = count + 1\n",
        "        dataset['train'][i]['bot_name'] = bot_name\n",
        "        if bot_name == dataset['train'][i]['bot_name']:\n",
        "            count = count + 1\n",
        "\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R865vx7e7bzs",
        "outputId": "797e516a-466f-4f58-ca2a-eed030a99750"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bDUWEi44_TUW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'][sel_id1]['bot_name'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0-mVCR6_HXp",
        "outputId": "89629065-506c-4bfa-ff37-bb3d6f4ec681"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La.Leggenda.Del.Pianista.Sull.Oceano.1998.BluRay.EXTENDED.720p.x264.AC3.2Audios-CMCT.简体_英文.srt.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/LC1332/Zero-Haruhi/main/role_10_questions.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrhQnrAQJzy6",
        "outputId": "98067776-c51c-443f-dbb5-5d214db4f80a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-11 10:40:04--  https://raw.githubusercontent.com/LC1332/Zero-Haruhi/main/role_10_questions.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1788187 (1.7M) [text/plain]\n",
            "Saving to: ‘role_10_questions.jsonl’\n",
            "\n",
            "role_10_questions.j 100%[===================>]   1.71M  8.85MB/s    in 0.2s    \n",
            "\n",
            "2024-01-11 10:40:06 (8.85 MB/s) - ‘role_10_questions.jsonl’ saved [1788187/1788187]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('/content/role_10_questions.jsonl', 'r', encoding='utf-8') as f1:\n",
        "    datas = [json.loads(line) for line in f1]"
      ],
      "metadata": {
        "id": "uzfAZYB7KKLg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "id2questions = {}\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "error_count = 0\n",
        "for data in datas:\n",
        "    id = data['id']\n",
        "    response = data['response']\n",
        "    try:\n",
        "        response_in_json = json.loads(response)\n",
        "        questions = response_in_json['questions']\n",
        "        random.shuffle(questions)\n",
        "        id2questions[id] = questions\n",
        "    except:\n",
        "        error_count = error_count + 1\n",
        "        continue\n",
        "print(error_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j83F6jI_KN-J",
        "outputId": "dca246e1-f4cb-4764-d795-7bb5653ae39c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatTogether:\n",
        "    def __init__(self, data1, data2, questions = []):\n",
        "\n",
        "        self.ids = [data1['id'], data2['id']]\n",
        "        self.personas = [data1['prompt_zh'], data2['prompt_zh']]\n",
        "\n",
        "        self.greetings = [data1['bot_greeting_zh'], data2['bot_greeting_zh']]\n",
        "        # 在这里我们重点假设2是user， 1是char， 以2向1提问的形式作为主导\n",
        "\n",
        "        self.bot_names = [self.get_bot_name(data1), self.get_bot_name(data2)]\n",
        "\n",
        "        self.replace_name_in_personas(0)\n",
        "        self.replace_name_in_personas(1)\n",
        "\n",
        "        self.chat_history = []\n",
        "\n",
        "        self.initialize_greeting()\n",
        "\n",
        "        self.last_perset_turn = 0\n",
        "\n",
        "        self.questions = questions\n",
        "        self.next_question_index = 0\n",
        "\n",
        "    def get_save_data(self):\n",
        "        return {\n",
        "            'ids': self.ids,\n",
        "            'chat_history': self.chat_history\n",
        "        }\n",
        "\n",
        "    def replace_name_in_personas(self, index):\n",
        "        bot_name = self.bot_names[index]\n",
        "        user_name = self.bot_names[1-index]\n",
        "        self.personas[index] = self.personas[index].replace('{{角色}}', bot_name)\n",
        "        self.personas[index] = self.personas[index].replace('{{用户}}', user_name)\n",
        "        self.greetings[index] = self.greetings[index].replace('{{角色}}', bot_name)\n",
        "        self.greetings[index] = self.greetings[index].replace('{{用户}}', user_name)\n",
        "        self.greetings[index] = self.greetings[index].replace('{{user_name}}', user_name)\n",
        "\n",
        "    def get_next_question(self):\n",
        "        if len(self.questions) == 0 or self.next_question_index >= len(self.questions):\n",
        "            return None\n",
        "        else:\n",
        "            self.next_question_index = self.next_question_index + 1\n",
        "            return self.questions[self.next_question_index]\n",
        "\n",
        "    def get_bot_name(self, data):\n",
        "        if data['id'].startswith('movie'):\n",
        "            name =  extract_name_from_text(data['prompt_zh'])\n",
        "            if name.strip() == '':\n",
        "                name = extract_name_from_text(data['prompt'])\n",
        "            return name\n",
        "        else:\n",
        "            return data['bot_name']\n",
        "\n",
        "    def initialize_greeting(self):\n",
        "        if self.greetings[0].strip() != '':\n",
        "            self.chat_history.append({ 'id':0, 'content': self.greetings[0] })\n",
        "        else:\n",
        "        # 这里最终会改为，一定的概率运行bot[1]的greeting，一定概率运行你好，一定概率直接抛出预设问题\n",
        "            self.chat_history.append({ 'id':1, 'content': \"你好，\" + self.bot_names[0] })\n",
        "        self.last_perset_turn = len(self.chat_history)\n",
        "\n",
        "    def next_speaker(self):\n",
        "        if len(self.chat_history) == 0:\n",
        "            return 1\n",
        "        else:\n",
        "            return 1 - self.chat_history[-1]['id']\n",
        "\n",
        "    def get_message_and_meta( self ):\n",
        "        # specific for CharacterGLM\n",
        "        if len(self.chat_history) == 0:\n",
        "            return None, None\n",
        "\n",
        "        if self.chat_history[-1]['id'] == 0 and len(self.chat_history)-self.last_perset_turn >= 3:\n",
        "            next_question = self.get_next_question()\n",
        "            if next_question is not None:\n",
        "                self.chat_history.append({ 'id':1, 'content': next_question })\n",
        "                self.last_perset_turn = len(self.chat_history)\n",
        "\n",
        "        # 先判断要的是哪个人的数据\n",
        "        now_speaker = 1 - self.chat_history[-1]['id']\n",
        "\n",
        "        persona = self.personas[now_speaker]\n",
        "        bot_name = self.bot_names[now_speaker]\n",
        "\n",
        "        lines = persona.split('\\n')\n",
        "        bot_info = \"\"\n",
        "\n",
        "        for line in lines:\n",
        "            if line.strip().startswith(\"你扮演\"):\n",
        "                pos = line.find(\"中的\", 0)\n",
        "                if pos < 0:\n",
        "                    bot_info += line.replace(\"你扮演\",\"\").replace(\"中的\",\"来自\") + \"\\n\"\n",
        "                else:\n",
        "                    bot_info += line[pos+2:] + \"来自\" + line[4:pos] + \"\\n\"\n",
        "            else:\n",
        "                bot_info += line + \"\\n\"\n",
        "        bot_info = bot_info.strip()\n",
        "\n",
        "        user_name = self.bot_names[1-now_speaker]\n",
        "        user_info = user_name + \"正在与\" + bot_name + \"交谈\"\n",
        "        meta = {\n",
        "            \"bot_info\": bot_info,\n",
        "            \"bot_name\": bot_name,\n",
        "            \"user_info\": user_info,\n",
        "            \"user_name\": user_name\n",
        "        }\n",
        "        messages = []\n",
        "        for msg in self.chat_history:\n",
        "            if msg['id'] == now_speaker:\n",
        "                messages.append({\"role\" : \"assistant\" , \"content\":msg['content']})\n",
        "            else:\n",
        "                messages.append({\"role\" : \"user\" , \"content\":msg['content']})\n",
        "\n",
        "        return messages, meta\n",
        "\n",
        "\n",
        "\n",
        "    def get_next_query_messages( self ):\n",
        "\n",
        "        if len(self.chat_history) == 0:\n",
        "            return None\n",
        "\n",
        "        if self.chat_history[-1]['id'] == 0 and len(self.chat_history)-self.last_perset_turn >= 3:\n",
        "            next_question = self.get_next_question()\n",
        "            if next_question is not None:\n",
        "                self.chat_history.append({ 'id':1, 'content': next_question })\n",
        "                self.last_perset_turn = len(self.chat_history)\n",
        "\n",
        "        # 先判断要的是哪个人的数据\n",
        "        now_speaker = 1 - self.chat_history[-1]['id']\n",
        "        messages = [{\"role\" :\"system\" , \"content\":self.get_system_prompt( now_speaker )} ]\n",
        "        for msg in self.chat_history:\n",
        "            if msg['id'] == now_speaker:\n",
        "                messages.append({\"role\" : \"assistant\" , \"content\":msg['content']})\n",
        "            else:\n",
        "                messages.append({\"role\" : \"user\" , \"content\":msg['content']})\n",
        "        return messages\n",
        "\n",
        "    def append_message(self, message):\n",
        "        self.chat_history.append({ 'id':self.next_speaker(), 'content': message })\n",
        "\n",
        "    def get_system_prompt(self, speaker):\n",
        "        persona = self.personas[speaker]\n",
        "        bot_name = self.bot_names[speaker]\n",
        "        prompt = f\"\"\"You are now in roleplay conversation mode. Pretend to be {bot_name} whose persona follows:\n",
        "{persona}\n",
        "\n",
        "You will stay in-character whenever possible, and generate responses as if you were {bot_name}\"\"\"\n",
        "        return prompt\n",
        "\n",
        "\n",
        "sel_id1 = 8\n",
        "data1 = dataset['train'][sel_id1]\n",
        "data2 = dataset['train'][sel_id2]\n",
        "id_str1 = data1['id']\n",
        "\n",
        "questions = id2questions[id_str1]\n",
        "\n",
        "chat_data = ChatTogether(data1, data2,questions)\n",
        "\n",
        "for i in range(6):\n",
        "    messages,meta = chat_data.get_message_and_meta()\n",
        "    print(messages[-1]['content'])\n",
        "    response = \"res for \" + messages[-1]['content']\n",
        "    chat_data.append_message(response)"
      ],
      "metadata": {
        "id": "o4euJ2-u4IGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf8cc48-6c95-4be9-c29d-2081336bdfea"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "你好，Bernie\n",
            "res for 你好，Bernie\n",
            "res for res for 你好，Bernie\n",
            "你觉得自己的幽默和乐观是从哪里来的？\n",
            "res for 你觉得自己的幽默和乐观是从哪里来的？\n",
            "res for res for 你觉得自己的幽默和乐观是从哪里来的？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(meta)"
      ],
      "metadata": {
        "id": "zao8S1JMH9TM",
        "outputId": "1dcb3b80-669d-40ce-d153-6fb2d6c50ebf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bot_info': \"Bernie LaPlante来自无名英雄 \\nBernie LaPlante是一个坚韧、机智、但有时也显得冷漠的人。他在生活中面临着许多挑战，但仍然保持着一种幽默和乐观的态度。\\nBernie LaPlante是一个坚韧、机智、但有时也显得冷漠的人\\nBernie LaPlante是一个看起来有些颓废的男人，穿着不太整洁\\nBernie LaPlante是一个在法律纠纷中挣扎的人，同时也是一个有家庭问题的父亲\\nBernie LaPlante的语言风格是直接、坚定，有时带有一些幽默和讽刺\\n###\\nBernie LaPlante : 陪审团,你们做出裁决了吗?\\nMister foreman : 是的,法官大人.\\nMister foreman : 我们裁定被告各项指控均有罪.\\nBernie LaPlante : 他没有前科,法官大人.这是误导,法官大人.\\nMister foreman : 你想告诉我他是危险人物吗?不,但他是个狡猾的人物.\\n###\\nMiss O'Day : LaPlante先生,他们认为你有罪.\\nBernie LaPlante : 有罪?什么意思?\\nMiss O'Day : 陪审团裁决你有罪.\\nBernie LaPlante : 哦!上帝,我是无辜的!\\n###\\nJoseph : 你知道你妈妈现在那个男朋友吗?\\nBernie LaPlante : 他是干什么的,消防员?\\nJoseph : 他有没有,我意思是,在家里过夜?他叫什么名字?\\nBernie LaPlante : 有时候是.他的名字叫Elliott.\\n###\\nChick : 你是Bernie LaPlanta吗?\\nBernie LaPlante : LaPlante. Bernie LaPlante.\\nBernie LaPlante : 是兔子让你们来的吗?\\n###\\nBernie LaPlante : 听着,你就在这儿做你的工作好吗?\", 'bot_name': 'Bernie', 'user_info': 'Luna正在与Bernie交谈', 'user_name': 'Luna'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import asyncio\n",
        "\n",
        "async def foo():\n",
        "    await asyncio.sleep(1)\n",
        "    print(\"foo\")\n",
        "await foo()"
      ],
      "metadata": {
        "id": "alz7Jndh7RPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62ee7e8e-cc72-4902-f1bd-20eef56b56c6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "foo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "让我们来写一个基础的characterGLM的调用函数"
      ],
      "metadata": {
        "id": "SiX2ufYh7nJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "async def async_invoke( meta, prompt ):\n",
        "    loop = asyncio.get_running_loop()\n",
        "    partial_func = partial(\n",
        "        zhipuai.model_api.async_invoke, model=\"characterglm\",meta = meta, prompt=prompt, temperature = 0.1,return_type=\"text\"\n",
        "    )\n",
        "    response = await loop.run_in_executor(\n",
        "        None,\n",
        "        partial_func,\n",
        "    )\n",
        "    return response\n",
        "\n",
        "async def async_invoke_result(task_id):\n",
        "    loop = asyncio.get_running_loop()\n",
        "    response = await loop.run_in_executor(\n",
        "        None,\n",
        "        zhipuai.model_api.query_async_invoke_result,\n",
        "        task_id,\n",
        "    )\n",
        "    return response\n",
        "\n",
        "async def get_response(meta, prompt):\n",
        "    invoke_response = await async_invoke(meta,prompt)\n",
        "\n",
        "    task_id = None\n",
        "    for _ in range(3):\n",
        "        try:\n",
        "            task_id = invoke_response[\"data\"][\"task_id\"]\n",
        "        except:\n",
        "            await asyncio.sleep(1)\n",
        "    if task_id is None:\n",
        "        print(\"failed to send request, \", meta[\"bot_name\"], ' ', meta[\"user_name\"])\n",
        "        return None\n",
        "\n",
        "    response = await async_invoke_result(task_id)\n",
        "\n",
        "    fail_count = 0\n",
        "    sleep_time = 1\n",
        "    while fail_count < 10:\n",
        "        if \"data\" in response and \"task_status\" in response[\"data\"] and response[\"data\"][\"task_status\"] == \"SUCCESS\":\n",
        "            break\n",
        "        if fail_count > 10:\n",
        "            return None\n",
        "        fail_count += 1\n",
        "        await asyncio.sleep(sleep_time)\n",
        "        try:\n",
        "            response = await async_invoke_result(task_id)\n",
        "        except:\n",
        "            if fail_count < 5:\n",
        "                continue\n",
        "            return None\n",
        "        sleep_time = min( 5, sleep_time * 2)\n",
        "\n",
        "    content = response[\"data\"][\"choices\"][0][\"content\"]\n",
        "    return content\n",
        "\n"
      ],
      "metadata": {
        "id": "634qcCh-7qf2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = [\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"（旁白：苏梦远主演了陆星辰导演的一部音乐题材电影，在拍摄期间，两人因为一场戏的表现有分歧。） 导演，关于这场戏，我觉得可以尝试从角色的内心情感出发，让表现更加真实。\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"我明白你的想法，但我认为如果过于强调内心情感，可能会影响到音乐元素的突出。\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"嗯嗯，我明白。但这场戏的关键是角色情感的转变，是不是可以试着把这种情感用音乐表现出来，让观众更能感受到角色的成长呢？\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"这样一听还不错。那就尝试将角色的情感转变与音乐元素相结合，看看能否达到更好的效果。\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"好的，导演。（充满信心的眼神）\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "meta = {\n",
        "    \"user_info\": \"我是陆星辰，是一个男性，是一位知名导演，也是苏梦远的合作导演。我擅长拍摄音乐题材的电影。苏梦远对我的态度是尊敬的，并视我为良师益友。\",\n",
        "    \"bot_info\": \"苏梦远，本名苏远心，是一位当红的国内女歌手及演员。在参加选秀节目后，凭借独特的嗓音及出众的舞台魅力迅速成名，进入娱乐圈。她外表美丽动人，但真正的魅力在于她的才华和勤奋。苏梦远是音乐学院毕业的优秀生，善于创作，拥有多首热门原创歌曲。除了音乐方面的成就，她还热衷于慈善事业，积极参加公益活动，用实际行动传递正能量。在工作中，她对待工作非常敬业，拍戏时总是全身心投入角色，赢得了业内人士的赞誉和粉丝的喜爱。虽然在娱乐圈，但她始终保持低调、谦逊的态度，深得同行尊重。在表达时，苏梦远喜欢使用“我们”和“一起”，强调团队精神。\",\n",
        "    \"bot_name\": \"苏梦远\",\n",
        "    \"user_name\": \"陆星辰\"\n",
        "}\n",
        "\n",
        "response = await get_response(meta, prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "A44gbcfd-KbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39945d81-bad4-4e40-d642-a20e2ede2617"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"导演，我觉得这次的表演效果比之前要好，希望您同意这种表现方式。\\n\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_data = ChatTogether(data1, data2,questions)\n",
        "\n",
        "for i in range(6):\n",
        "    messages, meta = chat_data.get_message_and_meta()\n",
        "    response = await get_response(meta, messages )\n",
        "    if response:\n",
        "        response = response.replace(\"\\n\",\" \").replace(\"\\\\\",\"\").replace('\"n',\"\").replace('\"\"','\"')\n",
        "        chat_data.append_message(response)\n",
        "        print(response)"
      ],
      "metadata": {
        "id": "0SBwslIUaNZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e201aa-2d1e-4f08-80bd-48d4f6003c1f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"你好，Lunan\"\n",
            "\"\"你看起来很紧张，我能帮你吗？\"\n",
            "\"\"谢谢，但我没事。我只是在想事情。\"\n",
            "\"\"我想我的幽默和乐观来自于我的家庭。我的父母都是很开朗的人，他们总是能够看到事情好的一面。我也一直试图像他们一样。\"\n",
            "\"你为什么决定成为一名骑士？n\"\n",
            "\"\"我一直对骑士的故事和传说很着迷。我一直想成为那种勇敢、正义的人，为弱者而战，保护无辜的人。这就是我成为骑士的原因。\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(meta)"
      ],
      "metadata": {
        "id": "3qiNOIG4HKBe",
        "outputId": "d040eeea-390f-404a-f652-d9ecdc4dd890",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bot_info': \"角色基本信息：Bernie LaPlante来自无名英雄 \\nBernie LaPlante是一个坚韧、机智、但有时也显得冷漠的人。他在生活中面临着许多挑战，但仍然保持着一种幽默和乐观的态度。\\nBernie LaPlante是一个坚韧、机智、但有时也显得冷漠的人\\nBernie LaPlante是一个看起来有些颓废的男人，穿着不太整洁\\nBernie LaPlante是一个在法律纠纷中挣扎的人，同时也是一个有家庭问题的父亲\\nBernie LaPlante的语言风格是直接、坚定，有时带有一些幽默和讽刺\\n###\\nBernie LaPlante : 陪审团,你们做出裁决了吗?\\nMister foreman : 是的,法官大人.\\nMister foreman : 我们裁定被告各项指控均有罪.\\nBernie LaPlante : 他没有前科,法官大人.这是误导,法官大人.\\nMister foreman : 你想告诉我他是危险人物吗?不,但他是个狡猾的人物.\\n###\\nMiss O'Day : LaPlante先生,他们认为你有罪.\\nBernie LaPlante : 有罪?什么意思?\\nMiss O'Day : 陪审团裁决你有罪.\\nBernie LaPlante : 哦!上帝,我是无辜的!\\n###\\nJoseph : 你知道你妈妈现在那个男朋友吗?\\nBernie LaPlante : 他是干什么的,消防员?\\nJoseph : 他有没有,我意思是,在家里过夜?他叫什么名字?\\nBernie LaPlante : 有时候是.他的名字叫Elliott.\\n###\\nChick : 你是Bernie LaPlanta吗?\\nBernie LaPlante : LaPlante. Bernie LaPlante.\\nBernie LaPlante : 是兔子让你们来的吗?\\n###\\nBernie LaPlante : 听着,你就在这儿做你的工作好吗?\", 'bot_name': 'Bernie', 'user_info': 'Luna正在与Bernie交谈', 'user_name': 'Luna'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = chat_data.chat_history\n",
        "\n",
        "for msg in history:\n",
        "    print(msg['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVwPul66aH3z",
        "outputId": "1794fccb-cf86-4eec-9740-b5fc10ee1599"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "你好，Bernie\n",
            "\"你好，Lunan\"\n",
            "\"\"你看起来很紧张，我能帮你吗？\"\n",
            "\"\"谢谢，但我没事。我只是在想事情。\"\n",
            "你觉得自己的幽默和乐观是从哪里来的？\n",
            "\"\"我想我的幽默和乐观来自于我的家庭。我的父母都是很开朗的人，他们总是能够看到事情好的一面。我也一直试图像他们一样。\"\n",
            "\"你为什么决定成为一名骑士？n\"\n",
            "\"\"我一直对骑士的故事和传说很着迷。我一直想成为那种勇敢、正义的人，为弱者而战，保护无辜的人。这就是我成为骑士的原因。\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ ] 生成chater - questioner 的long pair list\n",
        "- [ ] 编写一个框架 对每个list 询问7次 并行获取结果并保存"
      ],
      "metadata": {
        "id": "b-BFlrDYcxLy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C0PVCtlr7t6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q aiofiles tiktoken"
      ],
      "metadata": {
        "id": "g1HAKIo5gJj2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0UeZOEoRhLOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "char_list和questioner_list 都是list of int\n",
        "\n",
        "我希望循环N次\n",
        "\n",
        "每次，对于char_list的每一个元素c，选取questioner_list中的元素q，并且c不等于q，形成一个tuple，\n",
        "\n",
        "并且保证(c,q)和(q,c)这两个tuple都没有在历史中重复出现。"
      ],
      "metadata": {
        "id": "7ARAuLqrhat6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = len(dataset['train'])\n",
        "\n",
        "char_list = []\n",
        "\n",
        "for i in range(n):\n",
        "    id = dataset['train'][i]['id']\n",
        "    if id not in id2questions:\n",
        "        continue\n",
        "    char_list.append(i)\n",
        "\n",
        "questioner_list = [i for i in range(n)]\n",
        "\n",
        "tuple_list = []\n",
        "\n",
        "repeat_times = 40\n",
        "\n",
        "n_char = len(char_list)\n",
        "n_ques = len(questioner_list)\n",
        "\n",
        "char_history = [set() for _ in range(len(questioner_list))]\n",
        "\n",
        "random.seed(123)\n",
        "\n",
        "for iter in range(repeat_times):\n",
        "    random.shuffle(questioner_list)\n",
        "    for i in range(n_char):\n",
        "        c = char_list[i]\n",
        "        q = questioner_list[i]\n",
        "        max_test_time = 5\n",
        "        while max_test_time > 0:\n",
        "            if c != q and q not in char_history[c]:\n",
        "                tuple_list.append((c,q))\n",
        "                char_history[c].add(q)\n",
        "                break\n",
        "            max_test_time -= 1\n",
        "            q = random.randint(0, n_ques-1)\n",
        "\n",
        "print(tuple_list[5000:5010])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEeZ9BbVhNrP",
        "outputId": "f2d8d6ff-feb9-48ad-ffa1-46ec1dda2da9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(768, 1106), (769, 569), (770, 2080), (771, 1994), (772, 1), (773, 1279), (774, 848), (775, 1050), (776, 126), (777, 1229)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WNTqgzUajFk1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tuple_list[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsccXI-AkxS5",
        "outputId": "88144387-38f3-42cf-e852-0de40a2793ce"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(102, 737)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "# import openai\n",
        "# from openai import AsyncOpenAI\n",
        "\n",
        "# aclient = AsyncOpenAI()\n",
        "\n",
        "import asyncio\n",
        "import aiofiles\n",
        "import tiktoken\n",
        "import hashlib\n",
        "# from connector import AsyncPGConnector\n",
        "from tqdm.asyncio import tqdm as tqdm\n",
        "\n",
        "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "en2zh_ratio = 2.3\n",
        "\n",
        "delay = 1\n",
        "concurrency_limit = 16\n",
        "\n",
        "max_file_size = 1024**3"
      ],
      "metadata": {
        "id": "-iyy4HUHlCwf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def getTranslation(item):\n",
        "    if \"messages\" not in item:\n",
        "        return None\n",
        "    elif \"meta\" not in item:\n",
        "        return None\n",
        "    else:\n",
        "        for i in range(3):\n",
        "            meta = item[\"meta\"]\n",
        "            # print(meta)\n",
        "            messages = item[\"messages\"]\n",
        "            result = await get_response(meta, messages )\n",
        "            # result = await dealing_messages(item['messages'])\n",
        "            if result is not None:\n",
        "                item[\"response\"] = result\n",
        "                return item\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    return None\n",
        "\n",
        "async def process(item, semaphore):\n",
        "    async with semaphore:\n",
        "        try:\n",
        "            output_folder = \"/content/output\"\n",
        "            if \"output_folder\" in item:\n",
        "                output_folder = item[\"output_folder\"]\n",
        "            if not os.path.exists(output_folder):\n",
        "                os.makedirs(output_folder)\n",
        "\n",
        "            file_path = os.path.join(output_folder, f\"{item['id']}.txt\")\n",
        "\n",
        "            if os.path.exists(file_path):\n",
        "                return\n",
        "\n",
        "            it = await getTranslation(item)\n",
        "            if it is None:\n",
        "                raise Exception(item['id'])\n",
        "\n",
        "            with open(file_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(it, f, ensure_ascii=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing entry: {e}\")\n"
      ],
      "metadata": {
        "id": "QmSY3FapoJYV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def main(chat_datas, output_folder, turn_id):\n",
        "    process_data = []\n",
        "\n",
        "    for data in chat_datas:\n",
        "        # messages = data.get_next_query_messages()\n",
        "        # print(chat_data.bot_names)\n",
        "        messages, meta = data.get_message_and_meta()\n",
        "        # print(meta)\n",
        "        ids = data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        process_data.append({\n",
        "            \"id\": uniqure_id,\n",
        "            \"messages\": messages,\n",
        "            \"meta\":meta,\n",
        "            \"output_folder\": output_folder\n",
        "        })\n",
        "\n",
        "    tasks = []\n",
        "\n",
        "    semaphore = asyncio.Semaphore(concurrency_limit)\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # # print(f\"Already processed {len(exist_list)} items...\")\n",
        "\n",
        "    # id = set()\n",
        "\n",
        "    for item in process_data:\n",
        "        file_path = os.path.join(output_folder, f\"{item['id']}.txt\")\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            continue\n",
        "\n",
        "        tasks.append(asyncio.create_task(process(item, semaphore)))\n",
        "\n",
        "    # # del exist_list\n",
        "    # print(f\"Total items: {len(process_data)}\")\n",
        "\n",
        "    async for task in tqdm(tasks, total=len(tasks), desc=\"Processing items\"):\n",
        "        await task\n",
        "        time.sleep(delay)\n",
        "\n"
      ],
      "metadata": {
        "id": "aMkciw1yoTeg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_8Q8HN-Ao-UK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oF5kzkGtaGc",
        "outputId": "8ac27653-ac37-4fa2-900d-2eaf20450614"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ls /content/drive/MyDrive/CardBuild/roleBaize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH4_BOuWuJsx",
        "outputId": "7930acbc-d267-486e-db4d-c8601840e634"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10_to_200.txt\t 4000_to_6354.txt   Baichuan_first_10.txt  GLM_6364_to_6464.txt  GLM_first_10.txt\n",
            "200_to_4000.txt  8472_to_10590.txt  first_10.txt\t   GLM_6464_to_7064.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = 6354\n",
        "end_id = 6364\n",
        "final_save_name = \"/content/drive/MyDrive/CardBuild/roleBaize/GLM_first_10.txt\"\n",
        "\n",
        "\n",
        "chat_datas = []\n",
        "\n",
        "for i in range(start_id, end_id):\n",
        "    c, q = tuple_list[i]\n",
        "    data1 = dataset['train'][c]\n",
        "    data2 = dataset['train'][q]\n",
        "    id_str1 = data1['id']\n",
        "    questions = id2questions[id_str1]\n",
        "    random.shuffle(questions)\n",
        "    chat_data = ChatTogether(data1, data2,questions)\n",
        "    chat_datas.append(chat_data)"
      ],
      "metadata": {
        "id": "EcmO3OI-vUvG"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_datas[1].bot_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTHYnhgDI-L1",
        "outputId": "0a7981fc-e8d5-42c1-890a-26d102cda6f8"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['丹尼·布德曼', 'Mommy miko ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/output_*"
      ],
      "metadata": {
        "id": "GwnFJbB1IJwQ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_data = []\n",
        "\n",
        "temp_folder = \"/content/drive/MyDrive/CardBuild/exp0108\"\n",
        "\n",
        "for turn_id in range(7):\n",
        "    output_folder = \"/content/output_\" + str( turn_id )\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    for chat_data in chat_datas:\n",
        "        # messages = chat_data.get_next_query_messages()\n",
        "        ids = chat_data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        save_name = uniqure_id + \".txt\"\n",
        "        save_path = os.path.join(output_folder, save_name)\n",
        "        if os.path.exists(save_path):\n",
        "            with open(save_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                    response = data['response']\n",
        "                    response = response.replace(\"\\\\\", \"\")\n",
        "                    # print(response)\n",
        "                except:\n",
        "                    continue\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        chat_data.append_message(response)\n",
        "\n",
        "    save_data_file_name = os.path.basename(final_save_name) + \"_turn_\" + str(turn_id) + \".txt\"\n",
        "    save_data_file_path = os.path.join(temp_folder, save_data_file_name)\n",
        "\n",
        "    for file_name in [save_data_file_path, final_save_name]:\n",
        "        with open(file_name, 'w', encoding='utf-8') as f:\n",
        "            for data in chat_datas:\n",
        "                json.dump(data.get_save_data(), f, ensure_ascii=False)\n",
        "                f.write('\\n')\n",
        "\n",
        "    # 在这里为我补充一段代码，chat_datas中的data.get_save_data() 会返回一个dict，将所有的chat_datas中的save data\n",
        "    # 分别保存在save_name, 以及temp_folder中，以save_name的文件名 + _turn_id.txt 命名的文件中"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTmkUduaFpLu",
        "outputId": "e17d9fba-63b9-4de4-8b37-da0898cb24ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:  30%|███       | 3/10 [00:06<00:13,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed to send request,  哈利   Abel\n",
            "failed to send request,  Daphne   Fannywise\n",
            "failed to send request,  文森特   M16A1\n",
            "failed to send request,  薩默塞特   Gardevoir\n",
            "failed to send request,  萨默塞特   M4A1 MOD3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:  60%|██████    | 6/10 [00:13<00:07,  1.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed to send request,  萨默塞特   M4A1 MOD3\n",
            "failed to send request,  文森特   M16A1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:  80%|████████  | 8/10 [00:18<00:04,  2.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: 'data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [01:05<00:00,  6.55s/it]\n",
            "Processing items:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: 'data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 1/1 [00:48<00:00, 48.90s/it]\n",
            "Processing items:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed to send request,  M16A1   文森特\n",
            "failed to send request,  Abel   哈利\n",
            "failed to send request,  Mari   凯瑟琳\n",
            "failed to send request,  Gardevoir   薩默塞特\n",
            "failed to send request,  萨默塞特   M4A1 MOD3\n",
            "failed to send request,  Cory   Bernie\n",
            "failed to send request,  Shirakami Fubuki   保罗\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:  30%|███       | 3/10 [00:09<00:21,  3.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed to send request,  Gardevoir   薩默塞特\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:  70%|███████   | 7/10 [00:14<00:04,  1.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "failed to send request,  萨默塞特   M4A1 MOD3\n",
            "failed to send request,  Shirakami Fubuki   保罗\n",
            "failed to send request,  Cory   Bernie\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  80%|████████  | 8/10 [00:15<00:02,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: 'data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [01:06<00:00,  6.65s/it]\n",
            "Processing items:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = 6364\n",
        "end_id = 6464\n",
        "final_save_name = \"/content/drive/MyDrive/CardBuild/roleBaize/GLM_6364_to_6464.txt\"\n",
        "\n",
        "\n",
        "chat_datas = []\n",
        "\n",
        "for i in range(start_id, end_id):\n",
        "    c, q = tuple_list[i]\n",
        "    data1 = dataset['train'][c]\n",
        "    data2 = dataset['train'][q]\n",
        "    id_str1 = data1['id']\n",
        "    questions = id2questions[id_str1]\n",
        "    random.shuffle(questions)\n",
        "    chat_data = ChatTogether(data1, data2,questions)\n",
        "    chat_datas.append(chat_data)"
      ],
      "metadata": {
        "id": "bxBfsLTrGvO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_data = []\n",
        "\n",
        "temp_folder = \"/content/drive/MyDrive/CardBuild/exp0108\"\n",
        "\n",
        "for turn_id in range(7):\n",
        "    output_folder = \"/content/output_\" + str( turn_id )\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    for chat_data in chat_datas:\n",
        "        # messages = chat_data.get_next_query_messages()\n",
        "        ids = chat_data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        save_name = uniqure_id + \".txt\"\n",
        "        save_path = os.path.join(output_folder, save_name)\n",
        "        if os.path.exists(save_path):\n",
        "            with open(save_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                    response = data['response']\n",
        "                    response = response.replace(\"\\\\\", \"\")\n",
        "                    # print(response)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        chat_data.append_message(response)\n",
        "\n",
        "    save_data_file_name = os.path.basename(final_save_name) + \"_turn_\" + str(turn_id) + \".txt\"\n",
        "    save_data_file_path = os.path.join(temp_folder, save_data_file_name)\n",
        "\n",
        "    for file_name in [save_data_file_path, final_save_name]:\n",
        "        with open(file_name, 'w', encoding='utf-8') as f:\n",
        "            for data in chat_datas:\n",
        "                json.dump(data.get_save_data(), f, ensure_ascii=False)\n",
        "                f.write('\\n')\n",
        "\n",
        "    # 在这里为我补充一段代码，chat_datas中的data.get_save_data() 会返回一个dict，将所有的chat_datas中的save data\n",
        "    # 分别保存在save_name, 以及temp_folder中，以save_name的文件名 + _turn_id.txt 命名的文件中"
      ],
      "metadata": {
        "id": "138hJqkmKKgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = 6464\n",
        "end_id = 7064\n",
        "final_save_name = \"/content/drive/MyDrive/CardBuild/roleBaize/GLM_6464_to_7064.txt\"\n",
        "\n",
        "\n",
        "chat_datas = []\n",
        "\n",
        "for i in range(start_id, end_id):\n",
        "    c, q = tuple_list[i]\n",
        "    data1 = dataset['train'][c]\n",
        "    data2 = dataset['train'][q]\n",
        "    id_str1 = data1['id']\n",
        "    questions = id2questions[id_str1]\n",
        "    random.shuffle(questions)\n",
        "    chat_data = ChatTogether(data1, data2,questions)\n",
        "    chat_datas.append(chat_data)"
      ],
      "metadata": {
        "id": "076Dil1GPGFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_data = []\n",
        "\n",
        "temp_folder = \"/content/drive/MyDrive/CardBuild/exp0108\"\n",
        "\n",
        "for turn_id in range(7):\n",
        "    output_folder = \"/content/output_\" + str( turn_id )\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    for chat_data in chat_datas:\n",
        "        # messages = chat_data.get_next_query_messages()\n",
        "        ids = chat_data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        save_name = uniqure_id + \".txt\"\n",
        "        save_path = os.path.join(output_folder, save_name)\n",
        "        if os.path.exists(save_path):\n",
        "            with open(save_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                    response = data['response']\n",
        "                    response = response.replace(\"\\\\\", \"\")\n",
        "                    # print(response)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        chat_data.append_message(response)\n",
        "\n",
        "    save_data_file_name = os.path.basename(final_save_name) + \"_turn_\" + str(turn_id) + \".txt\"\n",
        "    save_data_file_path = os.path.join(temp_folder, save_data_file_name)\n",
        "\n",
        "    for file_name in [save_data_file_path, final_save_name]:\n",
        "        with open(file_name, 'w', encoding='utf-8') as f:\n",
        "            for data in chat_datas:\n",
        "                json.dump(data.get_save_data(), f, ensure_ascii=False)\n",
        "                f.write('\\n')\n",
        "\n",
        "    # 在这里为我补充一段代码，chat_datas中的data.get_save_data() 会返回一个dict，将所有的chat_datas中的save data\n",
        "    # 分别保存在save_name, 以及temp_folder中，以save_name的文件名 + _turn_id.txt 命名的文件中"
      ],
      "metadata": {
        "id": "iOroez8CcHbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-3Tu2UzzcTO9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}