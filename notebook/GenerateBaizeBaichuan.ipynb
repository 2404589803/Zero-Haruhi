{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Zero-Haruhi/blob/main/notebook/GenerateBaizeBaichuan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "js7WNhRVHsIi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"BAICHUAN_TOKEN\"] = \"sk-f407\"\n",
        "# should be a string start with \"sk-\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCrm5s14Hfm4",
        "outputId": "33c036ed-111b-4161-db37-a1ce64b0c7d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "请求成功！\n",
            "响应body: data: {\"id\":\"chatcmpl-M7163011D8no0z6\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" (\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-Mbad3011D8no0tx\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"微笑\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-Ma900011D8no0gE\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\")\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-Ma171011D8no03o\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"我\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-M30f0011D8no00W\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"参加了\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-Mb5b2011D8no0ql\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"四\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-M5141011D8no06Q\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"届\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-Mb7c2011D8no0QP\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"世界杯\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-M3c32011D8no0zQ\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"，\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-M8cd2011D8no0RU\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"帮助\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-Mc105011D8no0Ld\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"巴西\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-M52d2011D8no01r\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"队\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-M6090011D8no016\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"赢得了\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-M0444011D8no0oK\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"两次\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-M6c61011D8no0IR\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"冠军\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-Mb4c1011D8no0v9\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"和\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-Mfff0011D8no0tL\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"一次\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-M8b01011D8no0IN\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"亚军\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-M5471011D8no07s\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"。\"}}]}\n",
            "\n",
            "data: {\"id\":\"chatcmpl-M2a42011D8no04Z\",\"object\":\"chat.completion.chunk\",\"created\":1705106990,\"model\":\"Baichuan-NPC-Turbo\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":341,\"completion_tokens\":20,\"total_tokens\":361}}\n",
            "\n",
            "data: [DONE]\n",
            "\n",
            "\n",
            "请求成功，X-BC-Request-Id: f6490a2d-1d77-460b-bdcd-66a8bf897135\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "api_key = os.environ[\"BAICHUAN_TOKEN\"]\n",
        "url = \"https://api.baichuan-ai.com/v1/chat/completions\"\n",
        "data = {\n",
        "    \"model\": \"Baichuan-NPC-Turbo\",\n",
        "    \"character_profile\": {\n",
        "        \"character_name\":\"大罗\",\n",
        "        \"character_info\":\"角色基本信息：大罗被广泛认为是有史以来最伟大的足球运动员之一。因为其强悍恐怖的攻击力被冠以“外星人”称号。大罗曾三度当选世界足球先生、两度获得金球奖，为巴西夺得两次世界杯冠军及一次亚军。效力过皇家马德里，巴塞罗那，AC米兰，国际米兰等豪门俱乐部，进球无数。\",\n",
        "        \"user_name\":\"小乐\",\n",
        "        \"user_info\":\"某体育频道解说员，在中国举办的大罗球迷见面会上做为主持人\"\n",
        "    },\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"你参加过几次世界杯？\"\n",
        "        }\n",
        "    ],\n",
        "    \"stream\": True,\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_k\":10,\n",
        "    \"max_tokens\": 512,\n",
        "}\n",
        "\n",
        "json_data = json.dumps(data)\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": \"Bearer \" + api_key\n",
        "}\n",
        "\n",
        "response = requests.post(url, data=json_data, headers=headers, timeout=60)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"请求成功！\")\n",
        "    print(\"响应body:\", response.text)\n",
        "    print(\"请求成功，X-BC-Request-Id:\", response.headers.get(\"X-BC-Request-Id\"))\n",
        "else:\n",
        "    print(\"请求失败，状态码:\", response.status_code)\n",
        "    print(\"请求失败，body:\", response.text)\n",
        "    print(\"请求失败，X-BC-Request-Id:\", response.headers.get(\"X-BC-Request-Id\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JNlXlvrsHh4R"
      },
      "outputs": [],
      "source": [
        "def grab_content_from_stream( response ):\n",
        "    result = \"\"\n",
        "\n",
        "    lines = response.text.split('\\n')\n",
        "    for line in lines:\n",
        "        if line.startswith('data:'):\n",
        "            # print(line[5:])\n",
        "            try:\n",
        "                json_data = json.loads(line[5:])\n",
        "                # print(json_data['choices'][0]['delta']['content'])\n",
        "                result += json_data['choices'][0]['delta']['content']\n",
        "\n",
        "            except:\n",
        "                pass\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grab_content_from_stream(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eq1zvItmWuss",
        "outputId": "7ad5f89a-d613-49b2-a95d-5d63f48b0758"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' (微笑)我参加了四届世界杯，帮助巴西队赢得了两次冠军和一次亚军。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(grab_content_from_stream(response))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raz0tTpGWsi2",
        "outputId": "40b9d9c0-6ebf-4d9f-d289-b2590f6f93a2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " (微笑)我参加了四届世界杯，帮助巴西队赢得了两次冠军和一次亚军。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo3NjqEKMjoh"
      },
      "source": [
        "初步的百川试验完毕，开始载入角色"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jicFYtUY3U_i",
        "outputId": "c4d5c5bc-f7ae-4f6d-e398-2919b10eb144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IPItUC0Y3YWC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "ea7fc2e7ed4f429dbf706874a6a0d170",
            "02cf9a3f271b438c8958d1b412ae3b1a",
            "f73639f9fd044f28b54f449f66e4466a",
            "ed87e74a82e344d4b473415b034dc063",
            "6b98950e6b304496b77d457dc4916203",
            "bc1ee9332730404da92cc05dfae0def7",
            "faa19a6045824c38af7477b461000c83",
            "3907dce1cedb427cb2d118d335b40e33",
            "beb30bad8b52491c823392d31a39658e",
            "9b737af7f4644209921674c1eddb9fd7",
            "a5b7714c2fd4479ba1f381ddf05ea813",
            "9bf0f6df9e724314af1d694400ec1803",
            "2baf59133e064a55b2a6ac91feb0d385",
            "d6231050166241e6aa84dae0eb8369de",
            "cec1fdf8805747f29fb86a370a2c536a",
            "b06f3a018f0b4ff2818f012a79390d53",
            "be92d394b2f94af4be71d63b21bf8aec",
            "6f9ba5397aad4ea5a513dd72b6a994b6",
            "cef22176f4f64754942d4bc3d202d43f",
            "4782027aa28341069ae08e59fcf3d006",
            "8543c8fabf0042909bdb623596f0b82e",
            "26113aba471243a3be933e494bf904b1",
            "e1bcf5a67e134443984b20285c47744e",
            "619ca6f54a8748318868606d13982456",
            "cb565f0fc54248c8a58cbc82da331f6b",
            "44aaa93f51204edb930baeb3a2d6bba2",
            "53962eca7c1743dfb32d2a23dbe13598",
            "917dfdfa076a4b58ad88c7082cdecf98",
            "f4e1fb25a9ea48e78fa18052a9415f84",
            "46371d474e67480cba57073bd4aa9f9c",
            "b90b54ee3a9d45a399610aa4478eb609",
            "60c59050f4444b6287d49e4c6a79cefe",
            "e7e0383ed19942a0a38070d4a51fa191"
          ]
        },
        "outputId": "a6eeca97-f849-41e7-d918-8a17b0788ab3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/932 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea7fc2e7ed4f429dbf706874a6a0d170"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/9.64M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bf0f6df9e724314af1d694400ec1803"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1bcf5a67e134443984b20285c47744e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"silk-road/Haruhi-Zero-RolePlaying-movie-PIPPA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT7Izj683tmC",
        "outputId": "714f0d08-2129-4eb6-87df-43ce379f79d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2140\n",
            "你扮演 两男变错身 中的 MITCH\n",
            "MITCH是一个轻浮、放荡的人，外表花花公子，喜欢享受生活，不拘小节。\n",
            "MITCH是一个轻浮、放荡的人\n",
            "MITCH是一个外表花花公子的人\n",
            "这是一个现代都市的场景，MITCH是一个自由奔放的单身汉\n",
            "###\n",
            "DAVE : 好吧，我去搞定\n",
            "MITCH : 早上好啊\n",
            "DAVE : 你们今天起的比较早啊，嗯？\n",
            "MITCH : 有没有做噩梦啊尿床啊什么的？\n",
            "DAVE : 看看给宝宝准备了什么好东西\n",
            "###\n",
            "MITCH : 好了，让老爸歇会儿\n",
            "DAVE : 互换身份\n",
            "MITCH : 早上好LOCKWOOD\n",
            "LOCKWOOD : 早上好，STEEL先生\n",
            "STEEL : 孩子们还好吗\n",
            "###\n",
            "LOCKWOOD : 好的，谢谢！\n",
            "STEEL : （水平不济，以上蒙的）\n",
            "LOCKWOOD : 早上好，PATRICIA\n",
            "PATRICIA : 你好。\n",
            "LOCKWOOD : 大JB，小BB，ED哥，湿湿妹...\n",
            "###\n",
            "STEEL : 哥在公司呢！\n",
            "LOCKWOOD : 被我打败了吧？\n",
            "STEEL : 是的，你牛X！\n",
            "LOCKWOOD : 你刚刚用的免提吧？\n",
            "STEEL : 是啊，你那个秘书听到了吗？\n",
            "###\n",
            "DAVE : 好吧，我郑重的告诉你\n",
            "MITCH : 你老爹我又要婚了\n",
            "DAVE : 我希望你能参加我的婚礼。\n",
            "MITCH : 什么时候？下周六\n",
            "DAVE : 你后妈，PAMELA\n",
            "Luna是Wintenberg的半龙少女，她寻求复仇，是Yufine的同父异母的妹妹，不同于Yufi\n"
          ]
        }
      ],
      "source": [
        "n = len(dataset['train'])\n",
        "print(n)\n",
        "sel_id1, sel_id2 = 1, 1500\n",
        "\n",
        "print(dataset['train'][sel_id1+10]['prompt_zh'])\n",
        "print(dataset['train'][sel_id2]['prompt_zh'][:50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUq1D6C96nV8"
      },
      "source": [
        "修正movie的bot name\n",
        "\n",
        "实现一个python函数，输入是一段text\n",
        "\n",
        "text中的某一行为\" 你扮演 海上钢琴师 中的 丹尼·布德曼 \" 的格式\n",
        "\n",
        "注意这里中的 后面名字的前后都会有空格\n",
        "\n",
        "提取这个名字，并返回\n",
        "\n",
        "例子输入:\n",
        "你扮演 海上钢琴师 中的 丹尼·布德曼\n",
        "丹尼·布德曼是一个坚韧、热情和有责任感的船员，对音乐有着深厚的情感。\n",
        "丹尼·布德曼是一个坚韧、热情和有责任感的人\n",
        "丹尼·布德曼是一个穿着朴素的船员\n",
        "例子输出\n",
        "丹尼·布德曼\n",
        "\n",
        "例子输入:\n",
        "你扮演 两男变错身 中的 MITCH\n",
        "MITCH是一个轻浮、放荡的人，外表花花公子，喜欢享受生活，不拘小节。\n",
        "MITCH是一个轻浮、放荡的人\n",
        "MITCH是一个外表花花公子的人\n",
        "例子输出\n",
        "MITCH\n",
        "\n",
        "如果没有这样的行，返回\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opnmr9Cc5buQ",
        "outputId": "ae61f36f-5936-4191-950b-dd1c0f1675f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "丹尼·布德曼\n",
            "凯瑟琳\n",
            "丹尼·布德曼\n",
            "哈利\n",
            "派\n",
            "Daphne\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def extract_name_from_text(text):\n",
        "    pattern = r'你扮演\\s+.*中的\\s+(\\S+)\\s*'\n",
        "    match = re.search(pattern, text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "# 例子输入\n",
        "input_text = \"\"\"你扮演 海上钢琴师 中的 丹尼·布德曼\n",
        "丹尼·布德曼是一个坚韧、热情和有责任感的船员，对音乐有着深厚的情感。\n",
        "丹尼·布德曼是一个坚韧、热情和有责任感的人\n",
        "丹尼·布德曼是一个穿着朴素的船员\"\"\"\n",
        "\n",
        "output = extract_name_from_text(input_text)\n",
        "print(output)  # 输出：丹尼·布德曼\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "    print(extract_name_from_text(dataset['train'][i]['prompt_zh']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R865vx7e7bzs",
        "outputId": "392e2dd0-275d-44dc-c7e4-16e336e1f335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "870\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "n = len(dataset['train'])\n",
        "for i in range(n):\n",
        "    if dataset['train'][i]['id'].startswith('movie'):\n",
        "        bot_name = extract_name_from_text(dataset['train'][i]['prompt_zh'])\n",
        "        count = count + 1\n",
        "        dataset['train'][i]['bot_name'] = bot_name\n",
        "        if bot_name == dataset['train'][i]['bot_name']:\n",
        "            count = count + 1\n",
        "\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bDUWEi44_TUW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0-mVCR6_HXp",
        "outputId": "1cc04f28-d480-4d34-e2b9-c21591d20518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La.Leggenda.Del.Pianista.Sull.Oceano.1998.BluRay.EXTENDED.720p.x264.AC3.2Audios-CMCT.简体_英文.srt.txt\n"
          ]
        }
      ],
      "source": [
        "print(dataset['train'][sel_id1]['bot_name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrhQnrAQJzy6",
        "outputId": "69ba65ad-9bce-484b-c47a-3e1c66eb4c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-13 00:50:26--  https://raw.githubusercontent.com/LC1332/Zero-Haruhi/main/role_10_questions.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1788187 (1.7M) [text/plain]\n",
            "Saving to: ‘role_10_questions.jsonl’\n",
            "\n",
            "role_10_questions.j 100%[===================>]   1.71M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-01-13 00:50:27 (76.4 MB/s) - ‘role_10_questions.jsonl’ saved [1788187/1788187]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/LC1332/Zero-Haruhi/main/role_10_questions.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uzfAZYB7KKLg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('/content/role_10_questions.jsonl', 'r', encoding='utf-8') as f1:\n",
        "    datas = [json.loads(line) for line in f1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j83F6jI_KN-J",
        "outputId": "9a5984db-758e-4dc0-b72f-3a04ab6b9d01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "id2questions = {}\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "error_count = 0\n",
        "for data in datas:\n",
        "    id = data['id']\n",
        "    response = data['response']\n",
        "    try:\n",
        "        response_in_json = json.loads(response)\n",
        "        questions = response_in_json['questions']\n",
        "        random.shuffle(questions)\n",
        "        id2questions[id] = questions\n",
        "    except:\n",
        "        error_count = error_count + 1\n",
        "        continue\n",
        "print(error_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4euJ2-u4IGa",
        "outputId": "f67ddedd-6cc8-43d0-a112-0ea98a6089be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "你好，Bernie\n",
            "res for 你好，Bernie\n",
            "res for res for 你好，Bernie\n",
            "你是如何看待被认为狡猾的评价？\n",
            "res for 你是如何看待被认为狡猾的评价？\n",
            "res for res for 你是如何看待被认为狡猾的评价？\n"
          ]
        }
      ],
      "source": [
        "class ChatTogether:\n",
        "    def __init__(self, data1, data2, questions = []):\n",
        "\n",
        "        self.ids = [data1['id'], data2['id']]\n",
        "        self.personas = [data1['prompt_zh'], data2['prompt_zh']]\n",
        "\n",
        "        self.greetings = [data1['bot_greeting_zh'], data2['bot_greeting_zh']]\n",
        "        # 在这里我们重点假设2是user， 1是char， 以2向1提问的形式作为主导\n",
        "\n",
        "        self.bot_names = [self.get_bot_name(data1), self.get_bot_name(data2)]\n",
        "\n",
        "        self.replace_name_in_personas(0)\n",
        "        self.replace_name_in_personas(1)\n",
        "\n",
        "        self.chat_history = []\n",
        "\n",
        "        self.initialize_greeting()\n",
        "\n",
        "        self.last_perset_turn = 0\n",
        "\n",
        "        self.questions = questions\n",
        "        self.next_question_index = 0\n",
        "\n",
        "    def get_save_data(self):\n",
        "        return {\n",
        "            'ids': self.ids,\n",
        "            'chat_history': self.chat_history\n",
        "        }\n",
        "\n",
        "    def replace_name_in_personas(self, index):\n",
        "        bot_name = self.bot_names[index]\n",
        "        user_name = self.bot_names[1-index]\n",
        "        self.personas[index] = self.personas[index].replace('{{角色}}', bot_name)\n",
        "        self.personas[index] = self.personas[index].replace('{{用户}}', user_name)\n",
        "        self.greetings[index] = self.greetings[index].replace('{{角色}}', bot_name)\n",
        "        self.greetings[index] = self.greetings[index].replace('{{用户}}', user_name)\n",
        "        self.greetings[index] = self.greetings[index].replace('{{user_name}}', user_name)\n",
        "\n",
        "    def get_next_question(self):\n",
        "        if len(self.questions) == 0 or self.next_question_index >= len(self.questions):\n",
        "            return None\n",
        "        else:\n",
        "            self.next_question_index = self.next_question_index + 1\n",
        "            return self.questions[self.next_question_index]\n",
        "\n",
        "    def get_bot_name(self, data):\n",
        "        if data['id'].startswith('movie'):\n",
        "            name =  extract_name_from_text(data['prompt_zh'])\n",
        "            if name.strip() == '':\n",
        "                name = extract_name_from_text(data['prompt'])\n",
        "            return name\n",
        "        else:\n",
        "            return data['bot_name']\n",
        "\n",
        "    def initialize_greeting(self):\n",
        "        if self.greetings[0].strip() != '':\n",
        "            self.chat_history.append({ 'id':0, 'content': self.greetings[0] })\n",
        "        else:\n",
        "        # 这里最终会改为，一定的概率运行bot[1]的greeting，一定概率运行你好，一定概率直接抛出预设问题\n",
        "            self.chat_history.append({ 'id':1, 'content': \"你好，\" + self.bot_names[0] })\n",
        "        self.last_perset_turn = len(self.chat_history)\n",
        "\n",
        "    def next_speaker(self):\n",
        "        if len(self.chat_history) == 0:\n",
        "            return 1\n",
        "        else:\n",
        "            return 1 - self.chat_history[-1]['id']\n",
        "\n",
        "    def get_message_and_meta( self ):\n",
        "        # specific for CharacterGLM\n",
        "        if len(self.chat_history) == 0:\n",
        "            return None, None\n",
        "\n",
        "        if self.chat_history[-1]['id'] == 0 and len(self.chat_history)-self.last_perset_turn >= 3:\n",
        "            next_question = self.get_next_question()\n",
        "            if next_question is not None:\n",
        "                self.chat_history.append({ 'id':1, 'content': next_question })\n",
        "                self.last_perset_turn = len(self.chat_history)\n",
        "\n",
        "        # 先判断要的是哪个人的数据\n",
        "        now_speaker = 1 - self.chat_history[-1]['id']\n",
        "\n",
        "        persona = self.personas[now_speaker]\n",
        "        bot_name = self.bot_names[now_speaker]\n",
        "\n",
        "        lines = persona.split('\\n')\n",
        "        bot_info = \"\"\n",
        "\n",
        "        for line in lines:\n",
        "            if line.strip().startswith(\"你扮演\"):\n",
        "                pos = line.find(\"中的\", 0)\n",
        "                if pos < 0:\n",
        "                    bot_info += line.replace(\"你扮演\",\"\").replace(\"中的\",\"来自\") + \"\\n\"\n",
        "                else:\n",
        "                    bot_info += line[pos+2:] + \"来自\" + line[4:pos] + \"\\n\"\n",
        "            else:\n",
        "                bot_info += line + \"\\n\"\n",
        "        bot_info = \"角色基本信息：\" + bot_info.strip()\n",
        "\n",
        "        user_name = self.bot_names[1-now_speaker]\n",
        "        user_info = user_name + \"正在与\" + bot_name + \"交谈\"\n",
        "        meta = {\n",
        "            \"character_info\": bot_info,\n",
        "            \"character_name\": bot_name,\n",
        "            \"user_info\": user_info,\n",
        "            \"user_name\": user_name\n",
        "        }\n",
        "        messages = []\n",
        "        for msg in self.chat_history:\n",
        "            if msg['id'] == now_speaker:\n",
        "                messages.append({\"role\" : \"assistant\" , \"content\":msg['content']})\n",
        "            else:\n",
        "                messages.append({\"role\" : \"user\" , \"content\":msg['content']})\n",
        "\n",
        "        return messages, meta\n",
        "\n",
        "\n",
        "\n",
        "    def get_next_query_messages( self ):\n",
        "\n",
        "        if len(self.chat_history) == 0:\n",
        "            return None\n",
        "\n",
        "        if self.chat_history[-1]['id'] == 0 and len(self.chat_history)-self.last_perset_turn >= 3:\n",
        "            next_question = self.get_next_question()\n",
        "            if next_question is not None:\n",
        "                self.chat_history.append({ 'id':1, 'content': next_question })\n",
        "                self.last_perset_turn = len(self.chat_history)\n",
        "\n",
        "        # 先判断要的是哪个人的数据\n",
        "        now_speaker = 1 - self.chat_history[-1]['id']\n",
        "        messages = [{\"role\" :\"system\" , \"content\":self.get_system_prompt( now_speaker )} ]\n",
        "        for msg in self.chat_history:\n",
        "            if msg['id'] == now_speaker:\n",
        "                messages.append({\"role\" : \"assistant\" , \"content\":msg['content']})\n",
        "            else:\n",
        "                messages.append({\"role\" : \"user\" , \"content\":msg['content']})\n",
        "        return messages\n",
        "\n",
        "    def append_message(self, message):\n",
        "        self.chat_history.append({ 'id':self.next_speaker(), 'content': message })\n",
        "\n",
        "    def get_system_prompt(self, speaker):\n",
        "        persona = self.personas[speaker]\n",
        "        bot_name = self.bot_names[speaker]\n",
        "        prompt = f\"\"\"You are now in roleplay conversation mode. Pretend to be {bot_name} whose persona follows:\n",
        "{persona}\n",
        "\n",
        "You will stay in-character whenever possible, and generate responses as if you were {bot_name}\"\"\"\n",
        "        return prompt\n",
        "\n",
        "\n",
        "sel_id1 = 8\n",
        "data1 = dataset['train'][sel_id1]\n",
        "data2 = dataset['train'][sel_id2]\n",
        "id_str1 = data1['id']\n",
        "\n",
        "questions = id2questions[id_str1]\n",
        "\n",
        "chat_data = ChatTogether(data1, data2,questions)\n",
        "\n",
        "for i in range(6):\n",
        "    messages,meta = chat_data.get_message_and_meta()\n",
        "    print(messages[-1]['content'])\n",
        "    response = \"res for \" + messages[-1]['content']\n",
        "    chat_data.append_message(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_p8EIaPN0ZH",
        "outputId": "83847164-52fc-4dcf-ba61-60723653a5fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'character_info': \"角色基本信息：Bernie LaPlante来自无名英雄 \\nBernie LaPlante是一个坚韧、机智、但有时也显得冷漠的人。他在生活中面临着许多挑战，但仍然保持着一种幽默和乐观的态度。\\nBernie LaPlante是一个坚韧、机智、但有时也显得冷漠的人\\nBernie LaPlante是一个看起来有些颓废的男人，穿着不太整洁\\nBernie LaPlante是一个在法律纠纷中挣扎的人，同时也是一个有家庭问题的父亲\\nBernie LaPlante的语言风格是直接、坚定，有时带有一些幽默和讽刺\\n###\\nBernie LaPlante : 陪审团,你们做出裁决了吗?\\nMister foreman : 是的,法官大人.\\nMister foreman : 我们裁定被告各项指控均有罪.\\nBernie LaPlante : 他没有前科,法官大人.这是误导,法官大人.\\nMister foreman : 你想告诉我他是危险人物吗?不,但他是个狡猾的人物.\\n###\\nMiss O'Day : LaPlante先生,他们认为你有罪.\\nBernie LaPlante : 有罪?什么意思?\\nMiss O'Day : 陪审团裁决你有罪.\\nBernie LaPlante : 哦!上帝,我是无辜的!\\n###\\nJoseph : 你知道你妈妈现在那个男朋友吗?\\nBernie LaPlante : 他是干什么的,消防员?\\nJoseph : 他有没有,我意思是,在家里过夜?他叫什么名字?\\nBernie LaPlante : 有时候是.他的名字叫Elliott.\\n###\\nChick : 你是Bernie LaPlanta吗?\\nBernie LaPlante : LaPlante. Bernie LaPlante.\\nBernie LaPlante : 是兔子让你们来的吗?\\n###\\nBernie LaPlante : 听着,你就在这儿做你的工作好吗?\", 'character_name': 'Bernie', 'user_info': 'Luna正在与Bernie交谈', 'user_name': 'Luna'}\n"
          ]
        }
      ],
      "source": [
        "print(meta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiX2ufYh7nJC"
      },
      "source": [
        "让我们来写一个基础的Baichaun的调用函数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "634qcCh-7qf2"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "import requests\n",
        "import asyncio\n",
        "async def try_once( meta, messages ):\n",
        "    url = \"https://api.baichuan-ai.com/v1/chat/completions\"\n",
        "    api_key = os.environ[\"BAICHUAN_TOKEN\"]\n",
        "    data = {\n",
        "        \"model\": \"Baichuan-NPC-Turbo\",\n",
        "        \"character_profile\": meta,\n",
        "        \"messages\": messages,\n",
        "        \"temperature\": 0.1,\n",
        "        \"top_k\":10,\n",
        "        \"max_tokens\": 512,\n",
        "        \"stream\": True,\n",
        "    }\n",
        "\n",
        "    json_data = json.dumps(data)\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"Authorization\": \"Bearer \" + api_key\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, data=json_data, headers=headers, timeout=60)\n",
        "\n",
        "    await asyncio.sleep(0.5)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        result = grab_content_from_stream(response)\n",
        "        if result.strip() == \"\":\n",
        "            return None\n",
        "        else:\n",
        "            return result\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "async def get_response(meta, messages):\n",
        "    response = None\n",
        "    sleep_time = 1\n",
        "    for _ in range(5):\n",
        "        try:\n",
        "            response = await try_once(meta, messages)\n",
        "            if response is not None:\n",
        "                break\n",
        "        except:\n",
        "            await asyncio.sleep(sleep_time)\n",
        "            sleep_time = min( 10, sleep_time * 2)\n",
        "    if response is None:\n",
        "        return None\n",
        "    else:\n",
        "        return response\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A44gbcfd-KbI",
        "outputId": "cc53c15a-43d7-471b-fffe-37ab37bee0e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# messages = [\n",
        "#     {\n",
        "#         \"role\": \"user\",\n",
        "#         \"content\": \"你参加过几次世界杯？\"\n",
        "#     }\n",
        "# ]\n",
        "\n",
        "# meta = {\n",
        "#     \"character_name\":\"大罗\",\n",
        "#     \"character_info\":\"角色基本信息：大罗被广泛认为是有史以来最伟大的足球运动员之一。因为其强悍恐怖的攻击力被冠以“外星人”称号。大罗曾三度当选世界足球先生、两度获得金球奖，为巴西夺得两次世界杯冠军及一次亚军。效力过皇家马德里，巴塞罗那，AC米兰，国际米兰等豪门俱乐部，进球无数。\",\n",
        "#     \"user_name\":\"小乐\",\n",
        "#     \"user_info\":\"某体育频道解说员，在中国举办的大罗球迷见面会上做为主持人\"\n",
        "# }\n",
        "\n",
        "# response = await try_once(meta, messages)\n",
        "# print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# response = await get_response(meta, messages)\n",
        "# print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtEVPCT_bSpO",
        "outputId": "ebad3eb7-79ed-47d0-b7a0-06c5c4e8946f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(微笑)我参加了四次世界杯，分别是1994年、1998年、2002年和2006年。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SBwslIUaNZv",
        "outputId": "598b04ab-e633-4873-fc9f-aed7c258cf26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(抬起头看着对方)你好，有什么我能帮你的吗？\n",
            "(低头看着你，眼神中充满了冷漠和不屑)哼，人类，你有什么能帮助我的呢？\n",
            " (皱起眉头，语气带着一丝疑惑和警惕)嘿，你怎么了？是不是遇到了什么问题？说出来或许我能帮你解决。\n",
            " (叹了一口气，面带微笑)嗯，这确实让我很困扰，但我知道我没有做错任何事，我会找到证明清白的证据。\n",
            " (冷笑一声，目光犀利地盯着你)哦，你真的这么认为吗？那么，告诉我，为什么人们会如此强烈地反对你们人类的存在，仅仅是因为你们的存在本身吗？\n",
            "  (耸了耸肩，无奈地笑了笑)我知道我们人类做了很多错事，但这并不意味着所有的人类都是坏的。我们都在努力变得更好。\n"
          ]
        }
      ],
      "source": [
        "# chat_data = ChatTogether(data1, data2,questions)\n",
        "\n",
        "# for i in range(6):\n",
        "#     messages, meta = chat_data.get_message_and_meta()\n",
        "#     response = await get_response(meta, messages )\n",
        "#     if response:\n",
        "#         chat_data.append_message(response)\n",
        "#         print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVwPul66aH3z",
        "outputId": "be1dd3b7-72c2-4b9c-eef5-991e0d51b1e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "你好，Bernie\n",
            "(抬起头看着对方)你好，有什么我能帮你的吗？\n",
            "(低头看着你，眼神中充满了冷漠和不屑)哼，人类，你有什么能帮助我的呢？\n",
            " (皱起眉头，语气带着一丝疑惑和警惕)嘿，你怎么了？是不是遇到了什么问题？说出来或许我能帮你解决。\n",
            "你对被裁定有罪的感受是什么？\n",
            " (叹了一口气，面带微笑)嗯，这确实让我很困扰，但我知道我没有做错任何事，我会找到证明清白的证据。\n",
            " (冷笑一声，目光犀利地盯着你)哦，你真的这么认为吗？那么，告诉我，为什么人们会如此强烈地反对你们人类的存在，仅仅是因为你们的存在本身吗？\n",
            "  (耸了耸肩，无奈地笑了笑)我知道我们人类做了很多错事，但这并不意味着所有的人类都是坏的。我们都在努力变得更好。\n"
          ]
        }
      ],
      "source": [
        "history = chat_data.chat_history\n",
        "\n",
        "for msg in history:\n",
        "    print(msg['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-BFlrDYcxLy"
      },
      "source": [
        "- [ ] 生成chater - questioner 的long pair list\n",
        "- [ ] 编写一个框架 对每个list 询问7次 并行获取结果并保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0PVCtlr7t6_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1HAKIo5gJj2",
        "outputId": "0734891e-9ea2-4612-9f52-84dd3ea20db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.0 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m1.5/2.0 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q aiofiles tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UeZOEoRhLOa"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ARAuLqrhat6"
      },
      "source": [
        "char_list和questioner_list 都是list of int\n",
        "\n",
        "我希望循环N次\n",
        "\n",
        "每次，对于char_list的每一个元素c，选取questioner_list中的元素q，并且c不等于q，形成一个tuple，\n",
        "\n",
        "并且保证(c,q)和(q,c)这两个tuple都没有在历史中重复出现。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEeZ9BbVhNrP",
        "outputId": "30e7c2ad-9f4a-454e-cd25-5cfa22bfbe1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(768, 1106), (769, 569), (770, 2080), (771, 1994), (772, 1), (773, 1279), (774, 848), (775, 1050), (776, 126), (777, 1229)]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "n = len(dataset['train'])\n",
        "\n",
        "char_list = []\n",
        "\n",
        "for i in range(n):\n",
        "    id = dataset['train'][i]['id']\n",
        "    if id not in id2questions:\n",
        "        continue\n",
        "    char_list.append(i)\n",
        "\n",
        "questioner_list = [i for i in range(n)]\n",
        "\n",
        "tuple_list = []\n",
        "\n",
        "repeat_times = 40\n",
        "\n",
        "n_char = len(char_list)\n",
        "n_ques = len(questioner_list)\n",
        "\n",
        "char_history = [set() for _ in range(len(questioner_list))]\n",
        "\n",
        "random.seed(123)\n",
        "\n",
        "for iter in range(repeat_times):\n",
        "    random.shuffle(questioner_list)\n",
        "    for i in range(n_char):\n",
        "        c = char_list[i]\n",
        "        q = questioner_list[i]\n",
        "        max_test_time = 5\n",
        "        while max_test_time > 0:\n",
        "            if c != q and q not in char_history[c]:\n",
        "                tuple_list.append((c,q))\n",
        "                char_history[c].add(q)\n",
        "                break\n",
        "            max_test_time -= 1\n",
        "            q = random.randint(0, n_ques-1)\n",
        "\n",
        "print(tuple_list[5000:5010])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WNTqgzUajFk1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsccXI-AkxS5",
        "outputId": "486f18e4-4d53-4c5c-ccc6-10f7169471cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(102, 737)\n"
          ]
        }
      ],
      "source": [
        "print(tuple_list[100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-iyy4HUHlCwf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "# import openai\n",
        "# from openai import AsyncOpenAI\n",
        "\n",
        "# aclient = AsyncOpenAI()\n",
        "\n",
        "import asyncio\n",
        "import aiofiles\n",
        "import tiktoken\n",
        "import hashlib\n",
        "# from connector import AsyncPGConnector\n",
        "from tqdm.asyncio import tqdm as tqdm\n",
        "\n",
        "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "en2zh_ratio = 2.3\n",
        "\n",
        "delay = 1\n",
        "concurrency_limit = 4\n",
        "\n",
        "max_file_size = 1024**3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QmSY3FapoJYV"
      },
      "outputs": [],
      "source": [
        "async def getTranslation(item):\n",
        "    if \"messages\" not in item:\n",
        "        return None\n",
        "    elif \"meta\" not in item:\n",
        "        return None\n",
        "    else:\n",
        "        for i in range(1):\n",
        "            meta = item[\"meta\"]\n",
        "            # print(meta)\n",
        "            messages = item[\"messages\"]\n",
        "            result = await get_response(meta, messages )\n",
        "            # result = await dealing_messages(item['messages'])\n",
        "            if result is not None:\n",
        "                item[\"response\"] = result\n",
        "                return item\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    return None\n",
        "\n",
        "async def process(item, semaphore):\n",
        "    async with semaphore:\n",
        "        try:\n",
        "            output_folder = \"/content/output\"\n",
        "            if \"output_folder\" in item:\n",
        "                output_folder = item[\"output_folder\"]\n",
        "            if not os.path.exists(output_folder):\n",
        "                os.makedirs(output_folder)\n",
        "\n",
        "            file_path = os.path.join(output_folder, f\"{item['id']}.txt\")\n",
        "\n",
        "            if os.path.exists(file_path):\n",
        "                return\n",
        "\n",
        "            it = await getTranslation(item)\n",
        "            if it is None:\n",
        "                raise Exception(item['id'])\n",
        "\n",
        "            with open(file_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(it, f, ensure_ascii=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing entry: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/output*"
      ],
      "metadata": {
        "id": "cISI7qAGb6TD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "aMkciw1yoTeg"
      },
      "outputs": [],
      "source": [
        "async def main(chat_datas, output_folder, turn_id):\n",
        "    process_data = []\n",
        "\n",
        "    for data in chat_datas:\n",
        "        # messages = data.get_next_query_messages()\n",
        "        # print(chat_data.bot_names)\n",
        "        messages, meta = data.get_message_and_meta()\n",
        "        # print(meta)\n",
        "        ids = data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        process_data.append({\n",
        "            \"id\": uniqure_id,\n",
        "            \"messages\": messages,\n",
        "            \"meta\":meta,\n",
        "            \"output_folder\": output_folder\n",
        "        })\n",
        "\n",
        "    tasks = []\n",
        "\n",
        "    semaphore = asyncio.Semaphore(concurrency_limit)\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # # print(f\"Already processed {len(exist_list)} items...\")\n",
        "\n",
        "    # id = set()\n",
        "\n",
        "    for item in process_data:\n",
        "        file_path = os.path.join(output_folder, f\"{item['id']}.txt\")\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            continue\n",
        "\n",
        "        tasks.append(asyncio.create_task(process(item, semaphore)))\n",
        "\n",
        "    # # del exist_list\n",
        "    # print(f\"Total items: {len(process_data)}\")\n",
        "\n",
        "    async for task in tqdm(tasks, total=len(tasks), desc=\"Processing items\"):\n",
        "        await task\n",
        "        time.sleep(delay)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_8Q8HN-Ao-UK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oF5kzkGtaGc",
        "outputId": "e7902ee4-2174-46df-eed7-43d779197c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH4_BOuWuJsx",
        "outputId": "311dc1bd-44a4-4894-b0f6-ba8ec10de3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10_to_200.txt\t       Claude_21190_to_21590.txt\t Claude_openai_22870_to_23010.txt\n",
            "12708_to_14826.txt     Claude_first_10.txt\t\t Claude_openai_first_10.txt\n",
            "14826_to_17297.txt     Claude_openai_21190_to_21330.txt  first_10.txt\n",
            "200_to_4000.txt        Claude_openai_21330_to_21470.txt  GLM_6364_to_6464.txt\n",
            "4000_to_6354.txt       Claude_openai_21470_to_21610.txt  GLM_6464_to_7064.txt\n",
            "8472_to_10590.txt      Claude_openai_21610_to_21750.txt  GLM_7064_to_8472.txt\n",
            "Baichuan_first_10.txt  Claude_openai_21750_to_21890.txt  GLM_first_10.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!ls /content/drive/MyDrive/CardBuild/roleBaize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EcmO3OI-vUvG"
      },
      "outputs": [],
      "source": [
        "start_id = 10590\n",
        "end_id = 10600\n",
        "final_save_name = \"/content/drive/MyDrive/CardBuild/roleBaize/Baichuan_first_10.txt\"\n",
        "\n",
        "\n",
        "chat_datas = []\n",
        "\n",
        "for i in range(start_id, end_id):\n",
        "    c, q = tuple_list[i]\n",
        "    data1 = dataset['train'][c]\n",
        "    data2 = dataset['train'][q]\n",
        "    id_str1 = data1['id']\n",
        "    questions = id2questions[id_str1]\n",
        "    random.shuffle(questions)\n",
        "    chat_data = ChatTogether(data1, data2,questions)\n",
        "    chat_datas.append(chat_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTmkUduaFpLu",
        "outputId": "2cd321a3-3e00-409b-b314-ac18dbf72ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:  60%|██████    | 6/10 [00:20<00:10,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_5_movie_57_0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  70%|███████   | 7/10 [00:36<00:21,  7.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_6_PIPPA_462_0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  80%|████████  | 8/10 [00:38<00:10,  5.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_7_PIPPA_499_0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  90%|█████████ | 9/10 [00:40<00:04,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_8_movie_345_0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items: 100%|██████████| 10/10 [00:41<00:00,  3.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_9_PIPPA_1009_0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:46<00:00,  4.64s/it]\n",
            "Processing items:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_5_movie_57_0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 5/5 [00:28<00:00,  5.63s/it]\n",
            "Processing items:  30%|███       | 3/10 [00:09<00:20,  2.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_2_PIPPA_15_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  40%|████      | 4/10 [00:25<00:47,  7.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_3_movie_281_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  50%|█████     | 5/10 [00:28<00:30,  6.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_4_PIPPA_831_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  60%|██████    | 6/10 [00:31<00:20,  5.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_5_movie_57_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  70%|███████   | 7/10 [00:34<00:12,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_6_PIPPA_462_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  80%|████████  | 8/10 [00:47<00:14,  7.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_7_PIPPA_499_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  90%|█████████ | 9/10 [00:49<00:05,  5.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_8_movie_345_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items: 100%|██████████| 10/10 [00:50<00:00,  4.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_9_PIPPA_1009_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:51<00:00,  5.16s/it]\n",
            "Processing items:  50%|█████     | 4/8 [00:12<00:10,  2.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_5_movie_57_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:  88%|████████▊ | 7/8 [00:30<00:03,  3.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_8_movie_345_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items: 100%|██████████| 8/8 [00:32<00:00,  3.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_9_PIPPA_1009_1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 8/8 [00:33<00:00,  4.20s/it]\n",
            "Processing items:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_0_movie_389_2\n",
            "Error processing entry: movie_1_movie_736_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:  30%|███       | 3/10 [00:21<00:44,  6.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_2_PIPPA_15_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  40%|████      | 4/10 [00:23<00:29,  4.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_3_movie_281_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  50%|█████     | 5/10 [00:27<00:21,  4.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_4_PIPPA_831_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  60%|██████    | 6/10 [00:42<00:32,  8.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_5_movie_57_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  70%|███████   | 7/10 [00:44<00:18,  6.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_6_PIPPA_462_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  80%|████████  | 8/10 [00:45<00:08,  4.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_7_PIPPA_499_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  90%|█████████ | 9/10 [00:47<00:03,  3.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_8_movie_345_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items: 100%|██████████| 10/10 [00:54<00:00,  4.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_9_PIPPA_1009_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:55<00:00,  5.59s/it]\n",
            "Processing items:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_0_movie_389_2\n",
            "Error processing entry: movie_1_movie_736_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:  30%|███       | 3/10 [00:21<00:44,  6.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_2_PIPPA_15_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  40%|████      | 4/10 [00:24<00:30,  5.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_3_movie_281_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  50%|█████     | 5/10 [00:27<00:21,  4.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_4_PIPPA_831_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  60%|██████    | 6/10 [00:43<00:32,  8.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_5_movie_57_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  70%|███████   | 7/10 [00:45<00:18,  6.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_6_PIPPA_462_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  80%|████████  | 8/10 [00:46<00:09,  4.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_7_PIPPA_499_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  90%|█████████ | 9/10 [00:48<00:03,  3.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_8_movie_345_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items: 100%|██████████| 10/10 [00:55<00:00,  4.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_9_PIPPA_1009_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:56<00:00,  5.66s/it]\n",
            "Processing items:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_0_movie_389_3\n",
            "Error processing entry: movie_1_movie_736_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:  30%|███       | 3/10 [00:21<00:44,  6.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_2_PIPPA_15_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  40%|████      | 4/10 [00:24<00:30,  5.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_3_movie_281_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  50%|█████     | 5/10 [00:27<00:21,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_4_PIPPA_831_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  60%|██████    | 6/10 [00:42<00:32,  8.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_5_movie_57_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  70%|███████   | 7/10 [00:44<00:18,  6.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_6_PIPPA_462_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  80%|████████  | 8/10 [00:45<00:09,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_7_PIPPA_499_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  90%|█████████ | 9/10 [00:47<00:03,  3.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_8_movie_345_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items: 100%|██████████| 10/10 [00:55<00:00,  4.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_9_PIPPA_1009_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:56<00:00,  5.61s/it]\n",
            "Processing items:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_0_movie_389_3\n",
            "Error processing entry: movie_1_movie_736_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:  30%|███       | 3/10 [00:21<00:45,  6.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_2_PIPPA_15_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  40%|████      | 4/10 [00:24<00:30,  5.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_3_movie_281_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  50%|█████     | 5/10 [00:27<00:21,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_4_PIPPA_831_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  60%|██████    | 6/10 [00:43<00:32,  8.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_5_movie_57_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  70%|███████   | 7/10 [00:44<00:18,  6.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_6_PIPPA_462_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  80%|████████  | 8/10 [00:45<00:09,  4.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_7_PIPPA_499_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  90%|█████████ | 9/10 [00:48<00:03,  3.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_8_movie_345_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items: 100%|██████████| 10/10 [00:55<00:00,  4.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_9_PIPPA_1009_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:56<00:00,  5.66s/it]\n",
            "Processing items:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_0_movie_389_4\n",
            "Error processing entry: movie_1_movie_736_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:  30%|███       | 3/10 [00:21<00:44,  6.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_2_PIPPA_15_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  40%|████      | 4/10 [00:24<00:30,  5.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_3_movie_281_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  50%|█████     | 5/10 [00:26<00:21,  4.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_4_PIPPA_831_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  60%|██████    | 6/10 [00:42<00:31,  7.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_5_movie_57_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  70%|███████   | 7/10 [00:44<00:18,  6.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_6_PIPPA_462_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  80%|████████  | 8/10 [00:45<00:08,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_7_PIPPA_499_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  90%|█████████ | 9/10 [00:47<00:03,  3.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_8_movie_345_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items: 100%|██████████| 10/10 [00:54<00:00,  4.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_9_PIPPA_1009_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:55<00:00,  5.55s/it]\n",
            "Processing items:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_0_movie_389_4\n",
            "Error processing entry: movie_1_movie_736_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items:  30%|███       | 3/10 [00:21<00:45,  6.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_2_PIPPA_15_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  40%|████      | 4/10 [00:24<00:30,  5.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_3_movie_281_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  50%|█████     | 5/10 [00:27<00:21,  4.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_4_PIPPA_831_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  60%|██████    | 6/10 [00:43<00:33,  8.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_5_movie_57_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  70%|███████   | 7/10 [00:45<00:18,  6.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_6_PIPPA_462_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  80%|████████  | 8/10 [00:46<00:09,  4.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_7_PIPPA_499_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:  90%|█████████ | 9/10 [00:48<00:03,  3.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_8_movie_345_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items: 100%|██████████| 10/10 [00:55<00:00,  4.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: movie_9_PIPPA_1009_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:56<00:00,  5.70s/it]\n",
            "Processing items:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "process_data = []\n",
        "\n",
        "temp_folder = \"/content/drive/MyDrive/CardBuild/exp0108\"\n",
        "\n",
        "for turn_id in range(7):\n",
        "    output_folder = \"/content/output_\" + str( turn_id )\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    for chat_data in chat_datas:\n",
        "        # messages = chat_data.get_next_query_messages()\n",
        "        ids = chat_data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        save_name = uniqure_id + \".txt\"\n",
        "        save_path = os.path.join(output_folder, save_name)\n",
        "        if os.path.exists(save_path):\n",
        "            with open(save_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                    response = data['response']\n",
        "                    response = response.replace(\"\\\\\", \"\")\n",
        "                    # print(response)\n",
        "                except:\n",
        "                    continue\n",
        "            if response is not None:\n",
        "                chat_data.append_message(response)\n",
        "\n",
        "    save_data_file_name = os.path.basename(final_save_name) + \"_turn_\" + str(turn_id) + \".txt\"\n",
        "    save_data_file_path = os.path.join(temp_folder, save_data_file_name)\n",
        "\n",
        "    for file_name in [save_data_file_path, final_save_name]:\n",
        "        with open(file_name, 'w', encoding='utf-8') as f:\n",
        "            for data in chat_datas:\n",
        "                json.dump(data.get_save_data(), f, ensure_ascii=False)\n",
        "                f.write('\\n')\n",
        "\n",
        "    # 在这里为我补充一段代码，chat_datas中的data.get_save_data() 会返回一个dict，将所有的chat_datas中的save data\n",
        "    # 分别保存在save_name, 以及temp_folder中，以save_name的文件名 + _turn_id.txt 命名的文件中"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxBfsLTrGvO7"
      },
      "outputs": [],
      "source": [
        "start_id = 10600\n",
        "end_id = 10700\n",
        "final_save_name = \"/content/drive/MyDrive/CardBuild/roleBaize/Baichuan_100.txt\"\n",
        "\n",
        "\n",
        "chat_datas = []\n",
        "\n",
        "for i in range(start_id, end_id):\n",
        "    c, q = tuple_list[i]\n",
        "    data1 = dataset['train'][c]\n",
        "    data2 = dataset['train'][q]\n",
        "    id_str1 = data1['id']\n",
        "    questions = id2questions[id_str1]\n",
        "    random.shuffle(questions)\n",
        "    chat_data = ChatTogether(data1, data2,questions)\n",
        "    chat_datas.append(chat_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "138hJqkmKKgm"
      },
      "outputs": [],
      "source": [
        "process_data = []\n",
        "\n",
        "temp_folder = \"/content/drive/MyDrive/CardBuild/exp0108\"\n",
        "\n",
        "for turn_id in range(7):\n",
        "    output_folder = \"/content/output_\" + str( turn_id )\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    for chat_data in chat_datas:\n",
        "        # messages = chat_data.get_next_query_messages()\n",
        "        ids = chat_data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        save_name = uniqure_id + \".txt\"\n",
        "        save_path = os.path.join(output_folder, save_name)\n",
        "        if os.path.exists(save_path):\n",
        "            with open(save_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                    response = data['response']\n",
        "                    response = response.replace(\"\\\\\", \"\")\n",
        "                    # print(response)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        chat_data.append_message(response)\n",
        "\n",
        "    save_data_file_name = os.path.basename(final_save_name) + \"_turn_\" + str(turn_id) + \".txt\"\n",
        "    save_data_file_path = os.path.join(temp_folder, save_data_file_name)\n",
        "\n",
        "    for file_name in [save_data_file_path, final_save_name]:\n",
        "        with open(file_name, 'w', encoding='utf-8') as f:\n",
        "            for data in chat_datas:\n",
        "                json.dump(data.get_save_data(), f, ensure_ascii=False)\n",
        "                f.write('\\n')\n",
        "\n",
        "    # 在这里为我补充一段代码，chat_datas中的data.get_save_data() 会返回一个dict，将所有的chat_datas中的save data\n",
        "    # 分别保存在save_name, 以及temp_folder中，以save_name的文件名 + _turn_id.txt 命名的文件中"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3Tu2UzzcTO9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOomOCGchTM1WidxQNhRfK+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea7fc2e7ed4f429dbf706874a6a0d170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02cf9a3f271b438c8958d1b412ae3b1a",
              "IPY_MODEL_f73639f9fd044f28b54f449f66e4466a",
              "IPY_MODEL_ed87e74a82e344d4b473415b034dc063"
            ],
            "layout": "IPY_MODEL_6b98950e6b304496b77d457dc4916203"
          }
        },
        "02cf9a3f271b438c8958d1b412ae3b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc1ee9332730404da92cc05dfae0def7",
            "placeholder": "​",
            "style": "IPY_MODEL_faa19a6045824c38af7477b461000c83",
            "value": "Downloading readme: 100%"
          }
        },
        "f73639f9fd044f28b54f449f66e4466a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3907dce1cedb427cb2d118d335b40e33",
            "max": 932,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_beb30bad8b52491c823392d31a39658e",
            "value": 932
          }
        },
        "ed87e74a82e344d4b473415b034dc063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b737af7f4644209921674c1eddb9fd7",
            "placeholder": "​",
            "style": "IPY_MODEL_a5b7714c2fd4479ba1f381ddf05ea813",
            "value": " 932/932 [00:00&lt;00:00, 37.9kB/s]"
          }
        },
        "6b98950e6b304496b77d457dc4916203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc1ee9332730404da92cc05dfae0def7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa19a6045824c38af7477b461000c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3907dce1cedb427cb2d118d335b40e33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb30bad8b52491c823392d31a39658e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b737af7f4644209921674c1eddb9fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5b7714c2fd4479ba1f381ddf05ea813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bf0f6df9e724314af1d694400ec1803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2baf59133e064a55b2a6ac91feb0d385",
              "IPY_MODEL_d6231050166241e6aa84dae0eb8369de",
              "IPY_MODEL_cec1fdf8805747f29fb86a370a2c536a"
            ],
            "layout": "IPY_MODEL_b06f3a018f0b4ff2818f012a79390d53"
          }
        },
        "2baf59133e064a55b2a6ac91feb0d385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be92d394b2f94af4be71d63b21bf8aec",
            "placeholder": "​",
            "style": "IPY_MODEL_6f9ba5397aad4ea5a513dd72b6a994b6",
            "value": "Downloading data: 100%"
          }
        },
        "d6231050166241e6aa84dae0eb8369de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cef22176f4f64754942d4bc3d202d43f",
            "max": 9642971,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4782027aa28341069ae08e59fcf3d006",
            "value": 9642971
          }
        },
        "cec1fdf8805747f29fb86a370a2c536a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8543c8fabf0042909bdb623596f0b82e",
            "placeholder": "​",
            "style": "IPY_MODEL_26113aba471243a3be933e494bf904b1",
            "value": " 9.64M/9.64M [00:01&lt;00:00, 7.49MB/s]"
          }
        },
        "b06f3a018f0b4ff2818f012a79390d53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be92d394b2f94af4be71d63b21bf8aec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f9ba5397aad4ea5a513dd72b6a994b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cef22176f4f64754942d4bc3d202d43f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4782027aa28341069ae08e59fcf3d006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8543c8fabf0042909bdb623596f0b82e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26113aba471243a3be933e494bf904b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1bcf5a67e134443984b20285c47744e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_619ca6f54a8748318868606d13982456",
              "IPY_MODEL_cb565f0fc54248c8a58cbc82da331f6b",
              "IPY_MODEL_44aaa93f51204edb930baeb3a2d6bba2"
            ],
            "layout": "IPY_MODEL_53962eca7c1743dfb32d2a23dbe13598"
          }
        },
        "619ca6f54a8748318868606d13982456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_917dfdfa076a4b58ad88c7082cdecf98",
            "placeholder": "​",
            "style": "IPY_MODEL_f4e1fb25a9ea48e78fa18052a9415f84",
            "value": "Generating train split: "
          }
        },
        "cb565f0fc54248c8a58cbc82da331f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46371d474e67480cba57073bd4aa9f9c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b90b54ee3a9d45a399610aa4478eb609",
            "value": 1
          }
        },
        "44aaa93f51204edb930baeb3a2d6bba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60c59050f4444b6287d49e4c6a79cefe",
            "placeholder": "​",
            "style": "IPY_MODEL_e7e0383ed19942a0a38070d4a51fa191",
            "value": " 2140/0 [00:00&lt;00:00, 5785.32 examples/s]"
          }
        },
        "53962eca7c1743dfb32d2a23dbe13598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "917dfdfa076a4b58ad88c7082cdecf98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4e1fb25a9ea48e78fa18052a9415f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46371d474e67480cba57073bd4aa9f9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b90b54ee3a9d45a399610aa4478eb609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60c59050f4444b6287d49e4c6a79cefe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e0383ed19942a0a38070d4a51fa191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}