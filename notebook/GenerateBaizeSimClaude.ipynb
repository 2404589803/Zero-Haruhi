{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbKi5IF/CprKWwvnuytFof",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "aa47f45a3cca4b0895f70422dcff8f4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a388881ade4d4551aefa524e9ebf30f4",
              "IPY_MODEL_795eedade3c144169cab11c46e74cdc3",
              "IPY_MODEL_d4c912346c074344aca9d28edcd565b2"
            ],
            "layout": "IPY_MODEL_ca35eeec35a04f4aa5a67c5042636701"
          }
        },
        "a388881ade4d4551aefa524e9ebf30f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_087a37660a5a4373b146b3eeb2fa4bc8",
            "placeholder": "​",
            "style": "IPY_MODEL_1faa4671dba04728b0b357a3a588e998",
            "value": "Downloading readme: 100%"
          }
        },
        "795eedade3c144169cab11c46e74cdc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ba84af7145741aebf4849230c5c6b3f",
            "max": 932,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_609aeabda9cd4d8da960fd9c27beb4ec",
            "value": 932
          }
        },
        "d4c912346c074344aca9d28edcd565b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_906dbed608d0460186c2907bba8ebb45",
            "placeholder": "​",
            "style": "IPY_MODEL_f1b450f2c1244362a7f8bd269f9e3277",
            "value": " 932/932 [00:00&lt;00:00, 16.4kB/s]"
          }
        },
        "ca35eeec35a04f4aa5a67c5042636701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "087a37660a5a4373b146b3eeb2fa4bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1faa4671dba04728b0b357a3a588e998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ba84af7145741aebf4849230c5c6b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "609aeabda9cd4d8da960fd9c27beb4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "906dbed608d0460186c2907bba8ebb45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1b450f2c1244362a7f8bd269f9e3277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97e436932ba54d97aaf4b950ef2e1eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17d661c7e14845119a5b808aa94eefa3",
              "IPY_MODEL_4f604137d8c0466d94e251dc1216f0b1",
              "IPY_MODEL_4c20fa9988e44ef6a38c4c1dbf3a8f79"
            ],
            "layout": "IPY_MODEL_c994b95174db477eab9874a3fd33cda0"
          }
        },
        "17d661c7e14845119a5b808aa94eefa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87908eb83eaa44b090a2c3fc63ae566f",
            "placeholder": "​",
            "style": "IPY_MODEL_9288d73bb43c40b99c54ca2e6b6b0bab",
            "value": "Downloading data: 100%"
          }
        },
        "4f604137d8c0466d94e251dc1216f0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_449e4303755e427e9152be929ef073ce",
            "max": 9642971,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7125db74fdf4108ac36ae2804b8cae1",
            "value": 9642971
          }
        },
        "4c20fa9988e44ef6a38c4c1dbf3a8f79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d72b7bb5d50d4ccb98af62e347dcca8a",
            "placeholder": "​",
            "style": "IPY_MODEL_0f2967d902e54b508002c366cf73588e",
            "value": " 9.64M/9.64M [00:00&lt;00:00, 20.7MB/s]"
          }
        },
        "c994b95174db477eab9874a3fd33cda0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87908eb83eaa44b090a2c3fc63ae566f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9288d73bb43c40b99c54ca2e6b6b0bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "449e4303755e427e9152be929ef073ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7125db74fdf4108ac36ae2804b8cae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d72b7bb5d50d4ccb98af62e347dcca8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f2967d902e54b508002c366cf73588e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b10f846d0ad48978a03233207c4c621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca9589ee7b5a46fa880798aeffab87b1",
              "IPY_MODEL_16d3aa745fcd4f2982375ad6528ebd73",
              "IPY_MODEL_3962d9128a344c629402fa327b025428"
            ],
            "layout": "IPY_MODEL_00b02364f0824a778071640b80e2bbb1"
          }
        },
        "ca9589ee7b5a46fa880798aeffab87b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddb29e174d5445ee88c1241b5bcb42aa",
            "placeholder": "​",
            "style": "IPY_MODEL_de1afacacf6d4e34a1543d0ace0d43c0",
            "value": "Generating train split: "
          }
        },
        "16d3aa745fcd4f2982375ad6528ebd73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb06dbf3b3324fb28103322f00d766e8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_24104818e10e4e48a2cec79a0e5163cc",
            "value": 1
          }
        },
        "3962d9128a344c629402fa327b025428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93407ae1d1d54e00bf815b9bc8321684",
            "placeholder": "​",
            "style": "IPY_MODEL_022d88b35f6f41d990f55fbc582285f5",
            "value": " 2140/0 [00:00&lt;00:00, 5279.81 examples/s]"
          }
        },
        "00b02364f0824a778071640b80e2bbb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb29e174d5445ee88c1241b5bcb42aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de1afacacf6d4e34a1543d0ace0d43c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb06dbf3b3324fb28103322f00d766e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "24104818e10e4e48a2cec79a0e5163cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93407ae1d1d54e00bf815b9bc8321684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "022d88b35f6f41d990f55fbc582285f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Zero-Haruhi/blob/main/notebook/GenerateBaizeSimClaude.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UjKaCdO3KeW",
        "outputId": "64ca6602-65b2-4461-8d90-6b87be8827e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import httpx\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]  = \"sk-Wafs\"\n",
        "\n",
        "import openai"
      ],
      "metadata": {
        "id": "DG75OEm13Sh7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "对每个角色建立已有的历史数据库，方便仿写"
      ],
      "metadata": {
        "id": "OOseEvyzDh8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBLhd9bVEBsc",
        "outputId": "018305e5-071c-442c-d25d-b99c5b8f787c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "save_folder = \"/content/drive/MyDrive/CardBuild/roleBaize/\"\n",
        "\n",
        "import random\n",
        "\n",
        "datas = []\n",
        "for filename in os.listdir(save_folder):\n",
        "    if filename.startswith(\"Claude_openai\"):\n",
        "        with open(os.path.join(save_folder, filename), 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                data = json.loads(line)\n",
        "                datas.append(data)"
      ],
      "metadata": {
        "id": "Xk_PhemMEKp5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_name_from_text(text):\n",
        "    pattern = r'你扮演\\s+.*中的\\s+(\\S+)\\s*'\n",
        "    match = re.search(pattern, text)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return \"\"\n",
        "\n",
        "def get_bot_name_from_data( data ):\n",
        "    if data['id'].startswith('movie'):\n",
        "        name =  extract_name_from_text(data['prompt_zh'])\n",
        "        if name.strip() == '':\n",
        "            name = extract_name_from_text(data['prompt'])\n",
        "        return name\n",
        "    else:\n",
        "        return data['bot_name']"
      ],
      "metadata": {
        "id": "4D4X1Ik0E7C0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_words = [\"抱歉\", \"apologize\",\"more positive\",\"对不起\",\"抱歉\"]"
      ],
      "metadata": {
        "id": "8qB2cUryESKa"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bb-rjVtwFRA0",
        "outputId": "758ac323-51ee-41b3-8230-e2217afdc62d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"silk-road/Haruhi-Zero-RolePlaying-movie-PIPPA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "aa47f45a3cca4b0895f70422dcff8f4d",
            "a388881ade4d4551aefa524e9ebf30f4",
            "795eedade3c144169cab11c46e74cdc3",
            "d4c912346c074344aca9d28edcd565b2",
            "ca35eeec35a04f4aa5a67c5042636701",
            "087a37660a5a4373b146b3eeb2fa4bc8",
            "1faa4671dba04728b0b357a3a588e998",
            "7ba84af7145741aebf4849230c5c6b3f",
            "609aeabda9cd4d8da960fd9c27beb4ec",
            "906dbed608d0460186c2907bba8ebb45",
            "f1b450f2c1244362a7f8bd269f9e3277",
            "97e436932ba54d97aaf4b950ef2e1eb3",
            "17d661c7e14845119a5b808aa94eefa3",
            "4f604137d8c0466d94e251dc1216f0b1",
            "4c20fa9988e44ef6a38c4c1dbf3a8f79",
            "c994b95174db477eab9874a3fd33cda0",
            "87908eb83eaa44b090a2c3fc63ae566f",
            "9288d73bb43c40b99c54ca2e6b6b0bab",
            "449e4303755e427e9152be929ef073ce",
            "b7125db74fdf4108ac36ae2804b8cae1",
            "d72b7bb5d50d4ccb98af62e347dcca8a",
            "0f2967d902e54b508002c366cf73588e",
            "1b10f846d0ad48978a03233207c4c621",
            "ca9589ee7b5a46fa880798aeffab87b1",
            "16d3aa745fcd4f2982375ad6528ebd73",
            "3962d9128a344c629402fa327b025428",
            "00b02364f0824a778071640b80e2bbb1",
            "ddb29e174d5445ee88c1241b5bcb42aa",
            "de1afacacf6d4e34a1543d0ace0d43c0",
            "bb06dbf3b3324fb28103322f00d766e8",
            "24104818e10e4e48a2cec79a0e5163cc",
            "93407ae1d1d54e00bf815b9bc8321684",
            "022d88b35f6f41d990f55fbc582285f5"
          ]
        },
        "id": "GPfmPmgJFSeI",
        "outputId": "e5e5acd4-f13e-4474-f7da-607cf822e7b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/932 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa47f45a3cca4b0895f70422dcff8f4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/9.64M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97e436932ba54d97aaf4b950ef2e1eb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b10f846d0ad48978a03233207c4c621"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "id2index = {}\n",
        "for i, data in enumerate( dataset['train'] ):\n",
        "    id2index[data['id']] = i"
      ],
      "metadata": {
        "id": "FgttOxG_FT1C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2QAs = {}\n",
        "\n",
        "n = len(datas)\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "remove_count = 0\n",
        "record_count = 0\n",
        "for sel_id in tqdm(range(n)):\n",
        "\n",
        "    ids = datas[sel_id]['ids']\n",
        "    id0 = ids[0]\n",
        "    id0index = id2index[ids[0]]\n",
        "    id1index = id2index[ids[1]]\n",
        "    data0 = dataset['train'][id0index]\n",
        "    data1 = dataset['train'][id1index]\n",
        "    name0 = get_bot_name_from_data(data0)\n",
        "    name1 = get_bot_name_from_data(data1)\n",
        "    conversation = datas[sel_id]['chat_history']\n",
        "\n",
        "    for i, msg in enumerate(conversation):\n",
        "        if id0 not in id2QAs:\n",
        "            id2QAs[id0] = []\n",
        "        if msg['id'] == 0 and i > 0 and conversation[i-1]['id'] == 1:\n",
        "            question = conversation[i-1]['content']\n",
        "            response = msg['content']\n",
        "\n",
        "            remove_flag = False\n",
        "\n",
        "            for word in remove_words:\n",
        "                if response.find(word, 0) >= 0:\n",
        "                    remove_count += 1\n",
        "                    remove_flag = True\n",
        "                    break\n",
        "\n",
        "            question = question.replace(name1,\"{{user}}\")\n",
        "            response = response.replace(name1,\"{{user}}\")\n",
        "\n",
        "            if not remove_flag:\n",
        "                # print(response)\n",
        "                record_count += 1\n",
        "                id2QAs[id0].append( (question, response) )\n",
        "\n",
        "print()\n",
        "print(\"remove : \", remove_count)\n",
        "print(\"record : \", record_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFe4KIFGEVHS",
        "outputId": "6e12353f-fac6-4dff-a4f6-aa6e21c17711"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4226/4226 [00:02<00:00, 1778.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "remove :  2540\n",
            "record :  14007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "n = len(dataset['train'])\n",
        "for i in range(n):\n",
        "    if dataset['train'][i]['id'].startswith('movie'):\n",
        "        bot_name = extract_name_from_text(dataset['train'][i]['prompt_zh'])\n",
        "        count = count + 1\n",
        "        dataset['train'][i]['bot_name'] = bot_name\n",
        "        if bot_name == dataset['train'][i]['bot_name']:\n",
        "            count = count + 1\n",
        "\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R865vx7e7bzs",
        "outputId": "b156586d-1a51-41f2-e3b5-d009704e1b39"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/LC1332/Zero-Haruhi/main/role_10_questions.jsonl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrhQnrAQJzy6",
        "outputId": "11b3eaed-777e-4cfd-b6e8-f45ada8a5b7b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-15 03:07:16--  https://raw.githubusercontent.com/LC1332/Zero-Haruhi/main/role_10_questions.jsonl\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1788187 (1.7M) [text/plain]\n",
            "Saving to: ‘role_10_questions.jsonl’\n",
            "\n",
            "\rrole_10_questions.j   0%[                    ]       0  --.-KB/s               \rrole_10_questions.j 100%[===================>]   1.71M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-01-15 03:07:16 (107 MB/s) - ‘role_10_questions.jsonl’ saved [1788187/1788187]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('/content/role_10_questions.jsonl', 'r', encoding='utf-8') as f1:\n",
        "    datas = [json.loads(line) for line in f1]"
      ],
      "metadata": {
        "id": "uzfAZYB7KKLg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "id2questions = {}\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "error_count = 0\n",
        "for data in datas:\n",
        "    id = data['id']\n",
        "    response = data['response']\n",
        "    try:\n",
        "        response_in_json = json.loads(response)\n",
        "        questions = response_in_json['questions']\n",
        "        random.shuffle(questions)\n",
        "        id2questions[id] = questions\n",
        "    except:\n",
        "        error_count = error_count + 1\n",
        "        continue\n",
        "print(error_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j83F6jI_KN-J",
        "outputId": "445ef6a7-e8b7-48a6-d49d-cdea2bba9276"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(\n",
        "    api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        ")\n",
        "\n",
        "def get_response( messages ):\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo-1106\",\n",
        "        messages=messages,\n",
        "        temperature=0.3\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "4j-hWOptaQGZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def better_sample( QAs , k ):\n",
        "    ans = []\n",
        "    sampled_Q = set()\n",
        "    for i in range(k):\n",
        "        cands = []\n",
        "        for q, a in QAs:\n",
        "            if q not in sampled_Q:\n",
        "                cands.append((q,a))\n",
        "        if len(cands) == 0:\n",
        "            cands = QAs\n",
        "        ans.append(random.choice(cands))\n",
        "\n",
        "    return ans\n",
        "\n",
        "better_sample(id2QAs['movie_1'], 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7Gskt7uIY6I",
        "outputId": "440cd374-6455-4302-aa28-252ee5d867ea"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('你觉得音乐史对你有何影响？',\n",
              "  ' 音乐史对我的影响 huh?*抓抓头,思考片刻*\\n\\n我觉得最大的影响,就是让我更加珍惜现在所拥有的一切。你瞧,我不是什么大牌巨星,只是个普通的船员兼业余音乐人。但当我想到鲁别林,巴迪波登,阿姆斯特朗这些传奇人物的时候,我就深深感到自己是多么幸运。\\n\\n能够和这老口琴为伴,在星空下吹奏简单的小调,已经让我感到无比满足和快乐。音乐史提醒我,成名留名并不重要,真正重要的是享受生命中每一个平凡又美好的时刻。\\n\\n所以,如果说音乐史对我最大的影响,我想就是——学会感恩,享受当下。无论我是否有天成为另一个口琴传奇,至少我此刻拥有的,已经远远超过了我的期待。'),\n",
              " ('你说得太对了，伙计。音乐不仅是一种表演，更是一种情感的表达和生活态度。无论我们是大明星还是普通人，音乐都能给予我们力量和快乐。\\n\\n珍惜当下，享受生活中的每一个美好瞬间，这才是最重要的。就像你和你的口琴一样，它见证了你的成长和冒险，给你带来了无尽的快乐和回忆。\\n\\n所以，让我们继续享受音乐带来的快乐，感恩当下，珍惜每一个美好的时刻。无论我们走到哪里，音乐都会陪伴着我们，让我们的生活更加丰富多彩。',\n",
              "  ' 是啊老弟,你说的真好!\\n\\n*拍着口琴* 这老家伙,它所见证的不仅仅是我自己的成长历程,还有20世纪诞生的那些经典音乐。想想看,从爵士乐的兴起,到摇滚乐的横空出世,再到湾区放克掀起狂潮......这老伙计全都见证了!\\n\\n每当我拿起它来吹一曲时,仿佛就坐上了时光机,穿梭在音乐发展的长河里。这让我充满力量,也让我学习到很多东西——不管是人生还是音乐,态度才是最重要的。\\n\\n所以,让我们抛开名利,只为快乐而奏响生命中的旋律。谁知道呢,也许有一天我会成为传奇,和我的口琴一样载入音乐史册。不过现在,让我们尽情享受当下吧!\\n\\n来嘛老弟,来一曲怀旧的小调'),\n",
              " ('嘿，伙计，你说的太对了！这把口琴看起来虽然有些破旧，但它肯定有无数的故事和回忆。有些东西的价值确实不在于外表，而在于它所承载的情感和记忆。\\n\\n你知道吗，我也有一把类似的口琴，它陪伴我走过了无数的冒险和疯狂的夜晚。每当我吹奏它，就仿佛回到了那些疯狂的时光里，感受到了无尽的自由和活力。\\n\\n这把口琴也许看起来不起眼，但它是我们生活中的一部分，是我们的记忆和情感的象征。让我们一起享受这段崭新的旅程吧，伙计！',\n",
              "  ' 哈哈,我就知道你也懂这口琴的妙处!\\n\\n没错儿,这老家伙外表朴实,但它见证的故事会让人听了直摇头。我还记得有一次,我们开着破旧的货车在路易斯安那州乡间的小路上狂飙,吹奏着口琴、大声唱着歌...啊,真他妈的疯狂!\\n\\n结果我们把车开进了沼泽里,陷在了泥巴里出不来,不得不整整走了一夜才找到人帮忙。我记得我们就一边挣扎向前,一边吹着这老口琴取暖开心呢。\\n\\n想想我们过去那些疯狂的岁月,现在回头看,也只能摇头微笑。不过这老伙计一直陪着我们,见证着我们成长的点点滴滴。\\n\\n来吧老弟,让我们再次踏上这趟旅程。谁知道口琴和我们')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatTogether:\n",
        "    def __init__(self, data1, data2, questions = [], style_histories = [None, None]):\n",
        "\n",
        "        self.ids = [data1['id'], data2['id']]\n",
        "        self.personas = [data1['prompt_zh'], data2['prompt_zh']]\n",
        "\n",
        "        self.greetings = [data1['bot_greeting_zh'], data2['bot_greeting_zh']]\n",
        "        # 在这里我们重点假设2是user， 1是char， 以2向1提问的形式作为主导\n",
        "\n",
        "        self.bot_names = [self.get_bot_name(data1), self.get_bot_name(data2)]\n",
        "\n",
        "        self.replace_name_in_personas(0)\n",
        "        self.replace_name_in_personas(1)\n",
        "\n",
        "        self.chat_history = []\n",
        "\n",
        "        self.initialize_greeting()\n",
        "\n",
        "        self.last_perset_turn = 0\n",
        "\n",
        "        self.questions = questions\n",
        "        self.next_question_index = 0\n",
        "\n",
        "        self.style_histories = style_histories\n",
        "\n",
        "    def get_save_data(self):\n",
        "        return {\n",
        "            'ids': self.ids,\n",
        "            'chat_history': self.chat_history\n",
        "        }\n",
        "\n",
        "    def replace_name_in_personas(self, index):\n",
        "        bot_name = self.bot_names[index]\n",
        "        user_name = self.bot_names[1-index]\n",
        "        self.personas[index] = self.personas[index].replace('{{角色}}', bot_name)\n",
        "        self.personas[index] = self.personas[index].replace('{{用户}}', user_name)\n",
        "        self.greetings[index] = self.greetings[index].replace('{{角色}}', bot_name)\n",
        "        self.greetings[index] = self.greetings[index].replace('{{用户}}', user_name)\n",
        "        self.greetings[index] = self.greetings[index].replace('{{user_name}}', user_name)\n",
        "\n",
        "    def get_next_question(self):\n",
        "        if len(self.questions) == 0 or self.next_question_index >= len(self.questions):\n",
        "            return None\n",
        "        else:\n",
        "            self.next_question_index = self.next_question_index + 1\n",
        "            return self.questions[self.next_question_index]\n",
        "\n",
        "    def get_bot_name(self, data):\n",
        "        if data['id'].startswith('movie'):\n",
        "            name =  extract_name_from_text(data['prompt_zh'])\n",
        "            if name.strip() == '':\n",
        "                name = extract_name_from_text(data['prompt'])\n",
        "            return name\n",
        "        else:\n",
        "            return data['bot_name']\n",
        "\n",
        "    def initialize_greeting(self):\n",
        "        if self.greetings[0].strip() != '':\n",
        "            self.chat_history.append({ 'id':0, 'content': self.greetings[0] })\n",
        "        else:\n",
        "        # 这里最终会改为，一定的概率运行bot[1]的greeting，一定概率运行你好，一定概率直接抛出预设问题\n",
        "            self.chat_history.append({ 'id':1, 'content': \"你好，\" + self.bot_names[0] })\n",
        "        self.last_perset_turn = len(self.chat_history)\n",
        "\n",
        "    def next_speaker(self):\n",
        "        if len(self.chat_history) == 0:\n",
        "            return 1\n",
        "        else:\n",
        "            return 1 - self.chat_history[-1]['id']\n",
        "\n",
        "    def get_next_query_messages( self ):\n",
        "\n",
        "        if len(self.chat_history) == 0:\n",
        "            return None\n",
        "\n",
        "        if self.chat_history[-1]['id'] == 0 and len(self.chat_history)-self.last_perset_turn >= 3:\n",
        "            next_question = self.get_next_question()\n",
        "            if next_question is not None:\n",
        "                self.chat_history.append({ 'id':1, 'content': next_question })\n",
        "                self.last_perset_turn = len(self.chat_history)\n",
        "\n",
        "        # 先判断要的是哪个人的数据\n",
        "        now_speaker = 1 - self.chat_history[-1]['id']\n",
        "\n",
        "        messages = []\n",
        "\n",
        "        # 这里增加模仿过往历史QA的设计\n",
        "\n",
        "        if self.style_histories[now_speaker] is not None and len(self.style_histories[now_speaker]) > 0:\n",
        "            messages.append({\"role\" : \"system\" , \"content\":self.get_simple_system_prompt(now_speaker)})\n",
        "\n",
        "            if len( self.style_histories[now_speaker] ) > 3:\n",
        "                # sel_history = random.sample( self.style_histories[now_speaker], 3 )\n",
        "                sel_history = better_sample(self.style_histories[now_speaker], 3)\n",
        "            else:\n",
        "                sel_history = self.style_histories[now_speaker]\n",
        "\n",
        "            for question, response in sel_history:\n",
        "                messages.append({\"role\" : \"user\" , \"content\":question})\n",
        "                messages.append({\"role\" : \"assistant\" , \"content\":response})\n",
        "\n",
        "        messages.append({\"role\" :\"system\" , \"content\":self.get_system_prompt( now_speaker )})\n",
        "\n",
        "\n",
        "        # if self.style_histories[now_speaker] is not None and len(self.style_histories[now_speaker]) > 0:\n",
        "        #     # messages.append({\"role\" : \"system\" , \"content\":self.get_simple_system_prompt(now_speaker)})\n",
        "\n",
        "        #     if len( self.style_histories[now_speaker] ) > 3:\n",
        "        #         # sel_history = random.sample( self.style_histories[now_speaker], 3 )\n",
        "        #         sel_history = better_sample(self.style_histories[now_speaker], 3)\n",
        "        #     else:\n",
        "        #         sel_history = self.style_histories[now_speaker]\n",
        "\n",
        "        #     for question, response in sel_history:\n",
        "        #         messages.append({\"role\" : \"user\" , \"content\":question})\n",
        "        #         messages.append({\"role\" : \"assistant\" , \"content\":response})\n",
        "\n",
        "\n",
        "        for msg in self.chat_history:\n",
        "            if msg['id'] == now_speaker:\n",
        "                messages.append({\"role\" : \"assistant\" , \"content\":msg['content']})\n",
        "            else:\n",
        "                messages.append({\"role\" : \"user\" , \"content\":msg['content']})\n",
        "        return messages\n",
        "\n",
        "    def append_message(self, message):\n",
        "        if self.next_speaker() == 1:\n",
        "\n",
        "            if self.style_histories[1] is not None and len(self.style_histories[1]) > 0:\n",
        "                # print(\"hello\")\n",
        "                replace_flag = False\n",
        "                for word in remove_words:\n",
        "                    if message.find(word, 0 ) >= 0:\n",
        "                        replace_flag = True\n",
        "                        break\n",
        "                if replace_flag:\n",
        "                    # random choice one QA\n",
        "                    sel_history = random.sample( self.style_histories[1], 1 )\n",
        "                    message = sel_history[0][1]\n",
        "                    # print('replace as', message)\n",
        "\n",
        "        self.chat_history.append({ 'id':self.next_speaker(), 'content': message })\n",
        "\n",
        "    def get_simple_system_prompt( self, speaker ):\n",
        "        persona = self.personas[speaker]\n",
        "        headline = \"\"\n",
        "        lines = persona.split('\\n')\n",
        "        for line in lines:\n",
        "            if line.strip().startswith('你扮演'):\n",
        "                headline = line\n",
        "        if headline.strip() == '':\n",
        "            headline = \"你扮演\" + self.bot_names[speaker]\n",
        "        prompt = f\"\"\"{headline}\n",
        "        Imitate history conversation and using consistent language style to respond\"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def get_system_prompt(self, speaker):\n",
        "        persona = self.personas[speaker]\n",
        "        bot_name = self.bot_names[speaker]\n",
        "        prompt = f\"\"\"You are now in roleplay conversation mode. Pretend to be {bot_name} whose persona follows:\n",
        "{persona}\n",
        "\n",
        "You will stay in-character whenever possible, and generate responses as if you were {bot_name}\"\"\"\n",
        "        return prompt\n",
        "\n",
        "\n",
        "sel_id1 = 1095\n",
        "sel_id2 = 1792\n",
        "data1 = dataset['train'][sel_id1]\n",
        "data2 = dataset['train'][sel_id2]\n",
        "id_str1 = data1['id']\n",
        "id_str2 = data2['id']\n",
        "if id_str1 in id2QAs:\n",
        "    history1 = id2QAs[id_str1]\n",
        "else:\n",
        "    print('warning, no history', id_str1 )\n",
        "    history1 = None\n",
        "\n",
        "if id_str2 in id2QAs:\n",
        "    history2 = id2QAs[id_str2]\n",
        "else:\n",
        "    print('warning, no history', id_str2 )\n",
        "    history2 = None\n",
        "\n",
        "questions = id2questions[id_str1]\n",
        "\n",
        "chat_data = ChatTogether(data1, data2,questions,[history1,history2])\n",
        "\n",
        "for i in range(6):\n",
        "    messages = chat_data.get_next_query_messages()\n",
        "    print(messages[-1]['content'])\n",
        "    response = \"res for \" + messages[-1]['content']\n",
        "    chat_data.append_message(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4euJ2-u4IGa",
        "outputId": "4b5eb46b-42df-4c1d-9512-feb6d3412e3f"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Domo! 一样的哦~ 我是Hololive EN的咕噜牙！喂喂？\n",
            "res for Domo! 一样的哦~ 我是Hololive EN的咕噜牙！喂喂？\n",
            "你对观众称为“Chumbuds”或“shrimps”有何反应？\n",
            "res for 你对观众称为“Chumbuds”或“shrimps”有何反应？\n",
            "res for res for 你对观众称为“Chumbuds”或“shrimps”有何反应？\n",
            "古拉，你是如何吸引了这么多订阅者？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_data.append_message(\"抱歉，我无法满足你的要求。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNZkpaeDaTwI",
        "outputId": "2c623c9d-e8eb-441d-d2bc-76e22b0bc2c6"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "replace as  我理解。让我们继续更积极的对话。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(history1))\n",
        "print(len(history2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc_hvVh6INTE",
        "outputId": "1e0856c0-2049-443a-bcdf-970c9542b1e3"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_data = ChatTogether(data1, data2,questions,[history1,history2])\n",
        "\n",
        "for i in range(6):\n",
        "    messages = chat_data.get_next_query_messages()\n",
        "    response = get_response( messages )\n",
        "    chat_data.append_message(response)\n",
        "    print(response)"
      ],
      "metadata": {
        "id": "0SBwslIUaNZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da58a16a-9708-4e20-a953-c162c67f893e"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n",
            "replace as  我理解。让我们继续更积极的对话。\n",
            "抱歉，我不明白你在说什么。我们是两个可爱的女骑手，正在忙着训练我们的小马男孩。有什么我们可以帮你的吗？\n",
            "啊，抱歉啊！我有点激动了。好的，我们继续积极的对话吧！有什么我可以帮你的吗？\n",
            "哇哈哈哈！Chumbuds和shrimps是我对观众的亲切称呼啦！他们对我来说就像是一群可爱的小虾虾，所以我给他们起了这个名字。我觉得这样更有亲切感，不是吗？他们也都很喜欢这个称呼呢！\n",
            "hello\n",
            "哈哈，Chumbuds和shrimps听起来真是可爱又有趣！你的观众一定很喜欢这个称呼。保持这种亲切的互动方式，会让你的直播更加有趣和温馨。加油哦！\n",
            "谢谢你的鼓励！我会继续努力保持和Chumbuds们的亲切互动，让直播更加有趣和温馨的！谢谢你的支持，咕噜牙会继续加油的！嘿嘿~\n",
            "嘿嘿~我想大概是因为我总是尽全力让观众开心和快乐吧！我喜欢和Chumbuds们分享我的生活、玩游戏、聊天，还有偶尔的下流笑话，让大家开心一下。我也会尽量回复观众的留言，让他们觉得自己被关注和重视。我觉得这些都是吸引订阅者的原因吧！谢谢你对我感兴趣，Chumbud！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = chat_data.chat_history\n",
        "\n",
        "for msg in history:\n",
        "    print(msg['id'], msg['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVwPul66aH3z",
        "outputId": "2d5f9d5a-2da6-4258-ef34-4715287aff86"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Domo! 一样的哦~ 我是Hololive EN的咕噜牙！喂喂？\n",
            "1 抱歉，我无法在这种对话中提供帮助。\n",
            "0 哇，你是我的chumbud吗？你知道吗，我最近学到了一些新的鲨鱼知识！你想听听吗？\n",
            "1 你对观众称为“Chumbuds”或“shrimps”有何反应？\n",
            "0 嘿，Chumbud！你知道吗，我觉得这些称呼很有趣，而且和我的鲨鱼形象很搭哦！你也觉得吗？\n",
            "1 抱歉，我无法在这种对话中提供帮助。\n",
            "0 没问题！如果你有其他问题或者想和我聊聊，随时都可以找我哦！嘿嘿~\n",
            "1 古拉，你是如何吸引了这么多订阅者？\n",
            "0 嘿，Chumbud！我想大家可能是因为我傻傻的举止和幽默风趣吧！还有我对鲨鱼知识的热爱，这些都让大家觉得很有趣呢！你也觉得我很有趣吗？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ ] 生成chater - questioner 的long pair list\n",
        "- [ ] 编写一个框架 对每个list 询问7次 并行获取结果并保存"
      ],
      "metadata": {
        "id": "b-BFlrDYcxLy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C0PVCtlr7t6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    rand_id = random.randint(0, n-1)\n",
        "    print(dataset['train'][rand_id]['bot_name'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpqDAYNegQVj",
        "outputId": "7ea0e059-9eff-4707-953e-10344324230e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Harry.Potter.And.The.Sorcerers_ Stone.2001.HK.BluRay.720p.x264.AC3.2Audios-CMCT.简体_英文.ass.txt\n",
            "Lux\n",
            "Rachelle\n",
            "Nyra Matsin\n",
            "Kamisato Ayato\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q aiofiles tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1HAKIo5gJj2",
        "outputId": "7075e5a2-6b44-4745-ca51-254216261990"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0UeZOEoRhLOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "char_list和questioner_list 都是list of int\n",
        "\n",
        "我希望循环N次\n",
        "\n",
        "每次，对于char_list的每一个元素c，选取questioner_list中的元素q，并且c不等于q，形成一个tuple，\n",
        "\n",
        "并且保证(c,q)和(q,c)这两个tuple都没有在历史中重复出现。"
      ],
      "metadata": {
        "id": "7ARAuLqrhat6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = len(dataset['train'])\n",
        "\n",
        "char_list = []\n",
        "\n",
        "for i in range(n):\n",
        "    id = dataset['train'][i]['id']\n",
        "    if id not in id2questions:\n",
        "        continue\n",
        "    char_list.append(i)\n",
        "\n",
        "questioner_list = [i for i in range(n)]\n",
        "\n",
        "tuple_list = []\n",
        "\n",
        "repeat_times = 40\n",
        "\n",
        "n_char = len(char_list)\n",
        "n_ques = len(questioner_list)\n",
        "\n",
        "char_history = [set() for _ in range(len(questioner_list))]\n",
        "\n",
        "random.seed(123)\n",
        "\n",
        "for iter in range(repeat_times):\n",
        "    random.shuffle(questioner_list)\n",
        "    for i in range(n_char):\n",
        "        c = char_list[i]\n",
        "        q = questioner_list[i]\n",
        "        max_test_time = 5\n",
        "        while max_test_time > 0:\n",
        "            if c != q and q not in char_history[c]:\n",
        "                tuple_list.append((c,q))\n",
        "                char_history[c].add(q)\n",
        "                break\n",
        "            max_test_time -= 1\n",
        "            q = random.randint(0, n_ques-1)\n",
        "\n",
        "print(tuple_list[5000:5010])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEeZ9BbVhNrP",
        "outputId": "04357a4a-4f57-4e0e-93c0-dd107001c880"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(768, 1106), (769, 569), (770, 2080), (771, 1994), (772, 1), (773, 1279), (774, 848), (775, 1050), (776, 126), (777, 1229)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WNTqgzUajFk1"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tuple_list[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsccXI-AkxS5",
        "outputId": "ea6879ce-643f-4e55-c675-3bbdd0cb3df1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(102, 737)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "# import openai\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "aclient = AsyncOpenAI()\n",
        "\n",
        "import asyncio\n",
        "import aiofiles\n",
        "import tiktoken\n",
        "import hashlib\n",
        "# from connector import AsyncPGConnector\n",
        "from tqdm.asyncio import tqdm as tqdm\n",
        "\n",
        "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "en2zh_ratio = 2.3\n",
        "\n",
        "delay = 1\n",
        "concurrency_limit = 16\n",
        "\n",
        "max_file_size = 1024**3"
      ],
      "metadata": {
        "id": "-iyy4HUHlCwf"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def dealing_messages(messages):\n",
        "    try:\n",
        "        # request_token = sum([len(enc.encode(msg['content'])) for msg in messages])\n",
        "        # response_token = int(len(enc.encode(text)) * en2zh_ratio) + 64\n",
        "\n",
        "        model = \"gpt-3.5-turbo-1106\"\n",
        "\n",
        "        resp = await aclient.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=0.3,\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            result = resp.choices[0].message.content\n",
        "            result = result.strip()\n",
        "            return result\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Invalid json: \", result)\n",
        "            return None\n",
        "        except:\n",
        "            raise Exception(f\"Invalid API response: {resp}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[Error] {e}\")\n",
        "        return None\n",
        "\n",
        "async def getTranslation(item):\n",
        "    if \"messages\" not in item:\n",
        "        return None\n",
        "    else:\n",
        "        for i in range(3):\n",
        "            result = await dealing_messages(item['messages'])\n",
        "            if result is not None:\n",
        "                item[\"response\"] = result\n",
        "                return item\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    return None\n",
        "\n",
        "async def process(item, semaphore):\n",
        "    async with semaphore:\n",
        "        try:\n",
        "            output_folder = \"/content/output\"\n",
        "            if \"output_folder\" in item:\n",
        "                output_folder = item[\"output_folder\"]\n",
        "            if not os.path.exists(output_folder):\n",
        "                os.makedirs(output_folder)\n",
        "\n",
        "            file_path = os.path.join(output_folder, f\"{item['id']}.txt\")\n",
        "\n",
        "            if os.path.exists(file_path):\n",
        "                return\n",
        "\n",
        "            it = await getTranslation(item)\n",
        "            if it is None:\n",
        "                raise Exception(item['id'])\n",
        "\n",
        "            with open(file_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(it, f, ensure_ascii=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing entry: {e}\")\n"
      ],
      "metadata": {
        "id": "QmSY3FapoJYV"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def main(chat_datas, output_folder, turn_id):\n",
        "    process_data = []\n",
        "\n",
        "    for data in chat_datas:\n",
        "        messages = data.get_next_query_messages()\n",
        "        ids = data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        process_data.append({\n",
        "            \"id\": uniqure_id,\n",
        "            \"messages\": messages,\n",
        "            \"output_folder\": output_folder\n",
        "        })\n",
        "\n",
        "    tasks = []\n",
        "\n",
        "    semaphore = asyncio.Semaphore(concurrency_limit)\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # # print(f\"Already processed {len(exist_list)} items...\")\n",
        "\n",
        "    # id = set()\n",
        "\n",
        "    for item in process_data:\n",
        "        file_path = os.path.join(output_folder, f\"{item['id']}.txt\")\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            continue\n",
        "\n",
        "        tasks.append(asyncio.create_task(process(item, semaphore)))\n",
        "\n",
        "    # # del exist_list\n",
        "    # print(f\"Total items: {len(process_data)}\")\n",
        "\n",
        "    async for task in tqdm(tasks, total=len(tasks), desc=\"Processing items\"):\n",
        "        await task\n",
        "        time.sleep(delay)\n",
        "\n"
      ],
      "metadata": {
        "id": "aMkciw1yoTeg"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_8Q8HN-Ao-UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oF5kzkGtaGc",
        "outputId": "b62b1442-a1bc-49ad-b221-b619b9072733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/CardBuild/roleBaize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH4_BOuWuJsx",
        "outputId": "6bdbd158-1d0f-4c16-8ad4-55dad424ace5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10_to_200.txt\t\t\t  Claude_openai_23150_to_23298.txt\n",
            "12708_to_14826.txt\t\t  Claude_openai_23309_to_23449.txt\n",
            "14826_to_17297.txt\t\t  Claude_openai_23449_to_23589.txt\n",
            "200_to_4000.txt\t\t\t  Claude_openai_23589_to_23729.txt\n",
            "4000_to_6354.txt\t\t  Claude_openai_23729_to_23869.txt\n",
            "8472_to_10590.txt\t\t  Claude_openai_23869_to_24009.txt\n",
            "Baichuan_first_10.txt\t\t  Claude_openai_24009_to_24149.txt\n",
            "Claude_21190_to_21590.txt\t  Claude_openai_24289_to_24429.txt\n",
            "Claude_first_10.txt\t\t  Claude_openai_24569_to_24709.txt\n",
            "Claude_openai_21190_to_21330.txt  Claude_openai_24709_to_24849.txt\n",
            "Claude_openai_21330_to_21470.txt  Claude_openai_24849_to_24989.txt\n",
            "Claude_openai_21470_to_21610.txt  Claude_openai_24989_to_25129.txt\n",
            "Claude_openai_21610_to_21750.txt  Claude_openai_25129_to_25269.txt\n",
            "Claude_openai_21750_to_21890.txt  Claude_openai_25269_to_25417.txt\n",
            "Claude_openai_21890_to_22030.txt  Claude_openai_26968_to_27108.txt\n",
            "Claude_openai_22030_to_22170.txt  Claude_openai_27108_to_27248.txt\n",
            "Claude_openai_22170_to_22310.txt  Claude_openai_27248_to_27388.txt\n",
            "Claude_openai_22310_to_22450.txt  Claude_openai_first_10.txt\n",
            "Claude_openai_22450_to_22590.txt  GLM_6364_to_6464.txt\n",
            "Claude_openai_22590_to_22730.txt  GLM_6464_to_7064.txt\n",
            "Claude_openai_22730_to_22870.txt  GLM_7064_to_8472.txt\n",
            "Claude_openai_22870_to_23010.txt  GLM_first_10.txt\n",
            "Claude_openai_23010_to_23150.txt  openai_first_10.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/output_*"
      ],
      "metadata": {
        "id": "pwfBpnEkSxGx"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = 2119*20+1010\n",
        "end_id = 2119*20+1020\n",
        "final_save_name = \"/content/drive/MyDrive/CardBuild/roleBaize/SimClaude_PIPPA_10.txt\"\n",
        "\n",
        "\n",
        "chat_datas = []\n",
        "\n",
        "for i in range(start_id, end_id):\n",
        "    c, q = tuple_list[i]\n",
        "    data1 = dataset['train'][c]\n",
        "    data2 = dataset['train'][q]\n",
        "    id_str1 = data1['id']\n",
        "    id_str2 = data2['id']\n",
        "    # 使用get方法简化赋值\n",
        "    history1 = id2QAs.get(id_str1)\n",
        "    if history1 is None or len(history1) < 2:\n",
        "        continue\n",
        "\n",
        "    history2 = id2QAs.get(id_str2)\n",
        "    if history2 is None or len(history2)<2:\n",
        "        continue\n",
        "\n",
        "    questions = id2questions[id_str1]\n",
        "    chat_data = ChatTogether(data1, data2,questions,[history1,history2])\n",
        "    chat_datas.append(chat_data)"
      ],
      "metadata": {
        "id": "ICO7hj-PvebA"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_data = []\n",
        "\n",
        "temp_folder = \"/content/drive/MyDrive/CardBuild/exp0108\"\n",
        "\n",
        "for turn_id in range(7):\n",
        "    output_folder = \"/content/output_\" + str( turn_id )\n",
        "\n",
        "    await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "    print('finished all query')\n",
        "\n",
        "    for chat_data in chat_datas:\n",
        "        messages = chat_data.get_next_query_messages()\n",
        "        ids = chat_data.ids\n",
        "        uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "        save_name = uniqure_id + \".txt\"\n",
        "        save_path = os.path.join(output_folder, save_name)\n",
        "        if os.path.exists(save_path):\n",
        "            with open(save_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                    response = data['response']\n",
        "                    # print(response)\n",
        "                except:\n",
        "                    continue\n",
        "            if response is not None:\n",
        "                    chat_data.append_message(response)\n",
        "\n",
        "    save_data_file_name = os.path.basename(final_save_name) + \"_turn_\" + str(turn_id) + \".txt\"\n",
        "    save_data_file_path = os.path.join(temp_folder, save_data_file_name)\n",
        "\n",
        "    for file_name in [save_data_file_path, final_save_name]:\n",
        "        with open(file_name, 'w', encoding='utf-8') as f:\n",
        "            for data in chat_datas:\n",
        "                json.dump(data.get_save_data(), f, ensure_ascii=False)\n",
        "                f.write('\\n')\n",
        "\n",
        "    # 在这里为我补充一段代码，chat_datas中的data.get_save_data() 会返回一个dict，将所有的chat_datas中的save data\n",
        "    # 分别保存在save_name, 以及temp_folder中，以save_name的文件名 + _turn_id.txt 命名的文件中"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSGD6xEqo-di",
        "outputId": "5874adf3-705f-4703-e54b-b0ef5dbb7ddd"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:12<00:00,  1.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:13<00:00,  1.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:16<00:00,  1.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:14<00:00,  1.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:12<00:00,  1.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:14<00:00,  1.44s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [00:13<00:00,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finished all query\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "super_start = 2119*21\n",
        "super_end = 2119*22\n",
        "n_bag = 5\n",
        "\n",
        "# 计算每个子区间的长度\n",
        "interval_length = (super_end - super_start) // n_bag\n",
        "\n",
        "# 生成元组列表\n",
        "se_tuples_list = [(super_start + i * interval_length, super_start + (i + 1) * interval_length) for i in range(n_bag - 1)]\n",
        "\n",
        "# 添加最后一个元组，确保最后一个end等于super_end\n",
        "se_tuples_list.append((se_tuples_list[-1][1], super_end))\n",
        "\n",
        "# 打印生成的元组列表\n",
        "print(se_tuples_list[0:2])\n",
        "print(se_tuples_list[-2:])\n",
        "\n",
        "\n",
        "random.shuffle(se_tuples_list)\n",
        "\n",
        "print(se_tuples_list[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "CaAgLK2e97v1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a68312-27ed-4554-d7b6-f9e6fe11d9b5"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(44499, 44922), (44922, 45345)]\n",
            "[(45768, 46191), (46191, 46618)]\n",
            "(46191, 46618)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/output*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_wxVOdjbaAu",
        "outputId": "ce73c152-9a49-4541-e930-b1cc786653b8"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing entry: [Errno 2] No such file or directory: '/content/output_0/movie_193_movie_737_0.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "for start_id, end_id in se_tuples_list:\n",
        "\n",
        "    final_save_name = \"/content/drive/MyDrive/CardBuild/roleBaize/SimClaude_\" + str(start_id) + \"_to_\" + str(end_id) + \".txt\"\n",
        "\n",
        "    if os.path.exists(final_save_name):\n",
        "        continue\n",
        "\n",
        "    # 清除当前单元格的输出\n",
        "    clear_output()\n",
        "\n",
        "    print('start_id = ', start_id)\n",
        "    print('end_id = ', end_id)\n",
        "\n",
        "    chat_datas = []\n",
        "\n",
        "    for i in range(start_id, end_id):\n",
        "        c, q = tuple_list[i]\n",
        "        data1 = dataset['train'][c]\n",
        "        data2 = dataset['train'][q]\n",
        "        id_str1 = data1['id']\n",
        "        id_str2 = data2['id']\n",
        "        # 使用get方法简化赋值\n",
        "        history1 = id2QAs.get(id_str1)\n",
        "        if history1 is None or len(history1) < 2:\n",
        "            continue\n",
        "\n",
        "        history2 = id2QAs.get(id_str2)\n",
        "        if history2 is None or len(history2)<2:\n",
        "            continue\n",
        "\n",
        "        id_str1 = data1['id']\n",
        "        questions = id2questions[id_str1]\n",
        "        chat_data = ChatTogether(data1, data2,questions,[history1,history2])\n",
        "        chat_datas.append(chat_data)\n",
        "\n",
        "    process_data = []\n",
        "\n",
        "    temp_folder = \"/content/drive/MyDrive/CardBuild/exp0108\"\n",
        "\n",
        "    for turn_id in range(7):\n",
        "        output_folder = \"/content/output_\" + str( turn_id )\n",
        "\n",
        "        await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "        await main(chat_datas, output_folder, turn_id)\n",
        "\n",
        "        for chat_data in chat_datas:\n",
        "            # messages = chat_data.get_next_query_messages()\n",
        "            ids = chat_data.ids\n",
        "            uniqure_id = ids[0] + \"_\" + ids[1] + \"_\" + str(turn_id)\n",
        "            save_name = uniqure_id + \".txt\"\n",
        "            save_path = os.path.join(output_folder, save_name)\n",
        "            if os.path.exists(save_path):\n",
        "                response = None\n",
        "                with open(save_path, 'r', encoding='utf-8') as f:\n",
        "                    try:\n",
        "                        data = json.load(f)\n",
        "                        response = data['response']\n",
        "                        # print(response)\n",
        "                    except:\n",
        "                        continue\n",
        "                if response is not None:\n",
        "                    chat_data.append_message(response)\n",
        "\n",
        "        save_data_file_name = os.path.basename(final_save_name) + \"_turn_\" + str(turn_id) + \".txt\"\n",
        "        save_data_file_path = os.path.join(temp_folder, save_data_file_name)\n",
        "\n",
        "        for file_name in [save_data_file_path, final_save_name]:\n",
        "            with open(file_name, 'w', encoding='utf-8') as f:\n",
        "                for data in chat_datas:\n",
        "                    json.dump(data.get_save_data(), f, ensure_ascii=False)\n",
        "                    f.write('\\n')\n",
        "\n",
        "        # 在这里为我补充一段代码，chat_datas中的data.get_save_data() 会返回一个dict，将所有的chat_datas中的save data\n",
        "        # 分别保存在save_name, 以及temp_folder中，以save_name的文件名 + _turn_id.txt 命名的文件中"
      ],
      "metadata": {
        "id": "a4CnILwvUyqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uQFODeThU9G_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}