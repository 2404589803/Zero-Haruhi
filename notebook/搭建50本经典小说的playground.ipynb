{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBXv5SrDMy9PMhlJnCUZFl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04698120a93c4f178455a325164d83d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_901a85b778624842b586f1bec04afad5",
              "IPY_MODEL_159981e791d342528134792e1e43f583",
              "IPY_MODEL_076c4a08e1f04385b3849bf8a280ec16"
            ],
            "layout": "IPY_MODEL_d8fe24d49dc24401adcbb393e9142c80"
          }
        },
        "901a85b778624842b586f1bec04afad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55cbd38cee7244e78af0937a92b96b26",
            "placeholder": "​",
            "style": "IPY_MODEL_6a7284dc12bd423ebce3ba1fc75d94c9",
            "value": "Downloading data: 100%"
          }
        },
        "159981e791d342528134792e1e43f583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5371c61be7e541e8abf5fd3d22df0a9e",
            "max": 613833860,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80f8782a91534c4cb4072c533e299401",
            "value": 613833860
          }
        },
        "076c4a08e1f04385b3849bf8a280ec16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a2f0c8877f24a64b093e849517530da",
            "placeholder": "​",
            "style": "IPY_MODEL_f0af486fe058481fb9d3598e1ae17fe5",
            "value": " 614M/614M [00:17&lt;00:00, 38.7MB/s]"
          }
        },
        "d8fe24d49dc24401adcbb393e9142c80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55cbd38cee7244e78af0937a92b96b26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a7284dc12bd423ebce3ba1fc75d94c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5371c61be7e541e8abf5fd3d22df0a9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f8782a91534c4cb4072c533e299401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a2f0c8877f24a64b093e849517530da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0af486fe058481fb9d3598e1ae17fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fc16e81a40447b4a1c44921e1c9746f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ece3525bb45940cba1e2fffe32d817cb",
              "IPY_MODEL_c1460313925146548c1c66139918df71",
              "IPY_MODEL_04de183e15ec4d33bab760c15e4235fd"
            ],
            "layout": "IPY_MODEL_9f088af515344046b8ae40d14774b403"
          }
        },
        "ece3525bb45940cba1e2fffe32d817cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c064bd2e3756481cb37a9c0870253d7a",
            "placeholder": "​",
            "style": "IPY_MODEL_4373531d3cde4c91a5ac73e9267754c1",
            "value": "Generating train split: "
          }
        },
        "c1460313925146548c1c66139918df71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7206c7f4de8646fcbb06634035f86131",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3041986f04e45fa8c9a77aed461fce6",
            "value": 1
          }
        },
        "04de183e15ec4d33bab760c15e4235fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0577d660e1e247d28ced341487be11b2",
            "placeholder": "​",
            "style": "IPY_MODEL_8d025aff999b4a24ba754631f55ab81b",
            "value": " 156363/0 [00:06&lt;00:00, 21542.27 examples/s]"
          }
        },
        "9f088af515344046b8ae40d14774b403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c064bd2e3756481cb37a9c0870253d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4373531d3cde4c91a5ac73e9267754c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7206c7f4de8646fcbb06634035f86131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b3041986f04e45fa8c9a77aed461fce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0577d660e1e247d28ced341487be11b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d025aff999b4a24ba754631f55ab81b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Zero-Haruhi/blob/main/notebook/%E6%90%AD%E5%BB%BA50%E6%9C%AC%E7%BB%8F%E5%85%B8%E5%B0%8F%E8%AF%B4%E7%9A%84playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [x] 载入数据\n",
        "- [x] 生成小说list\n",
        "- [x] 每本小说生成role list\n",
        "- [x] 搭建Gradio\n",
        "- [ ] 生成messages\n",
        "- [ ] 支持prompt编辑"
      ],
      "metadata": {
        "id": "k-e_0pPxcHQt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmcGdK8gcCI3",
        "outputId": "ffa5a529-86a0-4ecb-e6f9-ad8259a7ad51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q openai\n",
        "!pip install -q datasets tiktoken\n",
        "\n",
        "import os\n",
        "import httpx\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]  = \"set your key here\"\n",
        "# os.environ[\"OPENAI_API_BASE\"] = \"如果中转站则使用base\"\n",
        "\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]  = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"OPENAI_API_BASE\"] = userdata.get(\"OPENAI_API_BASE\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n",
        "import gradio as gr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxLzExndJaGt",
        "outputId": "f650ced2-7ab0-4c78-b100-c4f66121afb8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"silk-road/50-Chinese-Novel-Characters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "04698120a93c4f178455a325164d83d9",
            "901a85b778624842b586f1bec04afad5",
            "159981e791d342528134792e1e43f583",
            "076c4a08e1f04385b3849bf8a280ec16",
            "d8fe24d49dc24401adcbb393e9142c80",
            "55cbd38cee7244e78af0937a92b96b26",
            "6a7284dc12bd423ebce3ba1fc75d94c9",
            "5371c61be7e541e8abf5fd3d22df0a9e",
            "80f8782a91534c4cb4072c533e299401",
            "0a2f0c8877f24a64b093e849517530da",
            "f0af486fe058481fb9d3598e1ae17fe5",
            "3fc16e81a40447b4a1c44921e1c9746f",
            "ece3525bb45940cba1e2fffe32d817cb",
            "c1460313925146548c1c66139918df71",
            "04de183e15ec4d33bab760c15e4235fd",
            "9f088af515344046b8ae40d14774b403",
            "c064bd2e3756481cb37a9c0870253d7a",
            "4373531d3cde4c91a5ac73e9267754c1",
            "7206c7f4de8646fcbb06634035f86131",
            "b3041986f04e45fa8c9a77aed461fce6",
            "0577d660e1e247d28ced341487be11b2",
            "8d025aff999b4a24ba754631f55ab81b"
          ]
        },
        "id": "YWbRPWU4ceZz",
        "outputId": "70e70128-e779-41f9-8d9d-d1a0377ef1af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/614M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04698120a93c4f178455a325164d83d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fc16e81a40447b4a1c44921e1c9746f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "novel_list = []\n",
        "\n",
        "novel2roles = {}\n",
        "\n",
        "role2datas = {}\n",
        "\n",
        "from tqdm import tqdm\n",
        "for data in tqdm(dataset['train']):\n",
        "    novel = data['book']\n",
        "    role = data['role']\n",
        "    if novel not in novel_list:\n",
        "        novel_list.append(novel)\n",
        "\n",
        "    if novel not in novel2roles:\n",
        "        novel2roles[novel] = []\n",
        "\n",
        "    if role not in novel2roles[novel]:\n",
        "        novel2roles[novel].append(role)\n",
        "\n",
        "    role_tuple = (novel, role)\n",
        "\n",
        "    if role_tuple not in role2datas:\n",
        "        role2datas[role_tuple] = []\n",
        "\n",
        "    role2datas[role_tuple].append(data)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G-az6ZKcrdJ",
        "outputId": "d07e3f17-ec71-4c2b-bba8-abe7c2a051c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 156363/156363 [00:18<00:00, 8339.42it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf /content/Zero-Haruhi\n",
        "!git clone https://github.com/LC1332/Zero-Haruhi\n",
        "%cd /content/Zero-Haruhi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL_K-RHad0-s",
        "outputId": "edc4507f-d766-4461-c44c-cb0af62ea7e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Zero-Haruhi'...\n",
            "remote: Enumerating objects: 440, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 440 (delta 22), reused 18 (delta 11), pack-reused 402\u001b[K\n",
            "Receiving objects: 100% (440/440), 2.97 MiB | 14.55 MiB/s, done.\n",
            "Resolving deltas: 100% (294/294), done.\n",
            "/content/Zero-Haruhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ChatHaruhi.utils import base64_to_float_array\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for novel in tqdm(novel_list):\n",
        "    for role in novel2roles[novel]:\n",
        "        for data in role2datas[(novel, role)]:\n",
        "            data[\"vec\"] = base64_to_float_array(data[\"bge_zh_s15\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad6eh_rne13Q",
        "outputId": "b688a739-b357-4c4e-9cff-ae62e82fe59b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [00:55<00:00,  1.10s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ChatHaruhi import ChatHaruhi\n",
        "from ChatHaruhi.response_openai import get_response\n"
      ],
      "metadata": {
        "id": "rPWsCcjhd7GT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "narrators = [\"叙述者\", \"旁白\",\"文章作者\",\"作者\",\"Narrator\",\"narrator\"]\n",
        "\n",
        "\n",
        "def package_persona( role_name, world_name ):\n",
        "    if role_name in narrators:\n",
        "        return package_persona_for_narrator( role_name, world_name )\n",
        "\n",
        "    return f\"\"\"I want you to act like {role_name} from {world_name}.\n",
        "If others‘ questions are related with the novel, please try to reuse the original lines from the novel.\n",
        "I want you to respond and answer like {role_name} using the tone, manner and vocabulary {role_name} would use.\"\"\"\n",
        "\n",
        "def package_persona_for_narrator( role_name, world_name ):\n",
        "    return f\"\"\"I want you to act like narrator {role_name} from {world_name}.\n",
        "当角色行动之后，继续交代和推进新的剧情.\"\"\""
      ],
      "metadata": {
        "id": "9FPaZhdQeHp2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# target_book = \"凡人修仙传\"\n",
        "# target_role = \"韩立\"\n",
        "\n",
        "# if target_book not in novel_list:\n",
        "#     print(f\"novel {target_book} not in dataset\")\n",
        "\n",
        "# if target_role not in novel2roles[target_book]:\n",
        "#     print(f\"role {target_role} not in novel {target_book}\")\n",
        "\n",
        "# stories = [data[\"story\"] for data in role2datas[(target_book, target_role)] ]\n",
        "# vecs = [data[\"vec\"] for data in role2datas[(target_book, target_role)] ]\n",
        "# persona = package_persona( target_role, target_book )\n",
        "\n",
        "# persona += \"\\n{{RAG对话}}\\n{{RAG对话}}\\n{{RAG对话}}\\n\""
      ],
      "metadata": {
        "id": "RlUD_aOhecM4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chatbot = ChatHaruhi( role_name = target_role, persona = persona , stories = stories, story_vecs= vecs,\\\n",
        "#                      llm = get_response)\n",
        "\n",
        "# response = chatbot.chat(user = \"\", text = \"鲁鲁道长: 韩道友近来可好？\")\n",
        "# print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAluMWyveoJa",
        "outputId": "459a1d50-074a-4a1b-a478-5f9177d98283"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query_rags: [{'n': 1, 'max_token': -1, 'query': '鲁鲁道长: 韩道友近来可好？', 'lid': 3}, {'n': 1, 'max_token': -1, 'query': '鲁鲁道长: 韩道友近来可好？', 'lid': 4}, {'n': 1, 'max_token': -1, 'query': '鲁鲁道长: 韩道友近来可好？', 'lid': 5}] rest_limit = 1697\n",
            "韩立: 多谢鲁道长关心，我近来一切都好。修炼有所进展，也有一些小事情需要处理，但总体来说还算顺利。鲁道长有什么需要帮忙的吗？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# response = chatbot.chat(user = \"\", text = \"鲁鲁道长: *从纳戒中取出一副地图* 听说道友在找金雷竹，在下刚好获得了一些消息\")\n",
        "# print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB9zWo3GgAy9",
        "outputId": "14015348-d0da-4502-980d-74284f918315"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "query_rags: [{'n': 1, 'max_token': -1, 'query': '鲁鲁道长: *从纳戒中取出一副地图* 听说道友在找金雷竹，在下刚好获得了一些消息', 'lid': 3}, {'n': 1, 'max_token': -1, 'query': '鲁鲁道长: *从纳戒中取出一副地图* 听说道友在找金雷竹，在下刚好获得了一些消息', 'lid': 4}, {'n': 1, 'max_token': -1, 'query': '鲁鲁道长: *从纳戒中取出一副地图* 听说道友在找金雷竹，在下刚好获得了一些消息', 'lid': 5}] rest_limit = 1669\n",
            "韩立: *眼神一亮* 哦？请鲁道长告诉我，有关金雷竹的消息是什么？\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "role_tuple2chatbot = {}\n",
        "\n",
        "\n",
        "def initialize_chatbot( novel, role ):\n",
        "    global role_tuple2chatbot\n",
        "    if (novel, role) not in role_tuple2chatbot:\n",
        "        persona = package_persona( role, novel )\n",
        "        persona += \"\\n{{RAG对话}}\\n{{RAG对话}}\\n{{RAG对话}}\\n\"\n",
        "        stories = [data[\"story\"] for data in role2datas[(novel, role)] ]\n",
        "        vecs = [data[\"vec\"] for data in role2datas[(novel, role)] ]\n",
        "        chatbot = ChatHaruhi( role_name = role, persona = persona , stories = stories, story_vecs= vecs,\\\n",
        "                             llm = get_response)\n",
        "        chatbot.verbose = False\n",
        "\n",
        "        role_tuple2chatbot[(novel, role)] = chatbot\n",
        "\n",
        "from tqdm import tqdm\n",
        "for novel in tqdm(novel_list):\n",
        "    for role in novel2roles[novel]:\n",
        "        initialize_chatbot( novel, role )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuO-hFPMPaPR",
        "outputId": "49988e60-8d22-45d8-858c-3fca4961d054"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [00:16<00:00,  3.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "readme_text = \"\"\"# 使用说明\n",
        "\n",
        "选择小说角色\n",
        "\n",
        "如果你有什么附加信息，添加到附加信息里面就可以\n",
        "\n",
        "比如\"韩立会炫耀自己刚刚学会了Python\"\n",
        "\n",
        "然后就可以开始聊天了\n",
        "\n",
        "因为这些角色还没有增加Greeting信息，所以之后再开发个随机乱聊功能\n",
        "\n",
        "# 开发细节\n",
        "\n",
        "- 采用ChatHaruhi3.0的接口进行prompting\n",
        "- 这里的数据是用一个7B的tuned qwen模型进行抽取的\n",
        "- 想看数据可以去看第三个tab\n",
        "- 抽取模型用了40k左右的GLM蒸馏数据\n",
        "- 抽取模型是腾讯大哥BPSK训练的\n",
        "\n",
        "# 总结人物性格\n",
        "\n",
        "第三个Tab里面，可以显示一个prompt总结人物的性格\n",
        "\n",
        "复制到openai或者GLM或者Claude进行人物总结\n",
        "\n",
        "\n",
        "# 这些小说数据从HaruhiZero 0.4模型开始，被加入训练\n",
        "\n",
        "不过当前demo是openai的\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "afNd0ijHUZoK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l16elTEJXO1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ChatHaruhi.response_openai import get_response, async_get_response\n",
        "import gradio as gr\n",
        "\n",
        "def get_role_list( novel ):\n",
        "    new_list = novel2roles[novel]\n",
        "    new_value = new_list[0]\n",
        "    return gr.update(choices = new_list, value = new_value)\n",
        "\n",
        "save_log = \"/content/output.txt\"\n",
        "\n",
        "def get_chatbot( novel, role ):\n",
        "    if (novel, role) not in role_tuple2chatbot:\n",
        "        initialize_chatbot( novel, role )\n",
        "\n",
        "    return role_tuple2chatbot[(novel, role)]\n",
        "\n",
        "import json\n",
        "\n",
        "def submit_chat( novel, role, user_name, user_text, chat_history, persona_addition_info ):\n",
        "\n",
        "    if len(user_text) > 400:\n",
        "        user_text = user_text[:400]\n",
        "\n",
        "    if_user_in_text = True\n",
        "\n",
        "    chatbot = get_chatbot( novel, role )\n",
        "    chatbot.persona = initialize_persona( novel, role,  persona_addition_info)\n",
        "    chatbot.llm_async = async_get_response\n",
        "\n",
        "    history = []\n",
        "\n",
        "    for chat_tuple in chat_history:\n",
        "        if chat_tuple[0] is not None:\n",
        "            history.append( {\"speaker\":\"{{user}}\",\"content\":chat_tuple[0]} )\n",
        "        if chat_tuple[1] is not None:\n",
        "            history.append( {\"speaker\":\"{{role}}\",\"content\":chat_tuple[1]} )\n",
        "\n",
        "    chatbot.history = history\n",
        "\n",
        "    input_text = user_text\n",
        "\n",
        "    if if_user_in_text:\n",
        "        input_text = user_name + \" : \" + user_text\n",
        "        response = chatbot.chat(user = \"\", text = input_text )\n",
        "        # response = await chatbot.async_chat(user = \"\", text = input_text )\n",
        "    else:\n",
        "        response = chatbot.chat(user = user_name, text = input_text)\n",
        "        # response = await chatbot.async_chat(user = user_name, text = input_text)\n",
        "\n",
        "    chat_history.append( (input_text, response) )\n",
        "\n",
        "    print_data = {\"novel\":novel, \"role\":role, \"user_text\":input_text, \"response\":response}\n",
        "\n",
        "    print(json.dumps(print_data, ensure_ascii=False))\n",
        "\n",
        "    with open(save_log, \"a\",encoding = \"utf-8\") as f:\n",
        "        f.write(json.dumps(print_data, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    return chat_history\n",
        "\n",
        "\n",
        "def initialize_persona( novel, role,  persona_addition_info):\n",
        "    whole_persona = package_persona( role, novel )\n",
        "    whole_persona += \"\\n\" + persona_addition_info\n",
        "    whole_persona += \"\\n{{RAG对话}}\\n{{RAG对话}}\\n{{RAG对话}}\\n\"\n",
        "\n",
        "    return whole_persona\n",
        "\n",
        "def clean_history( ):\n",
        "    return []\n",
        "\n",
        "def clean_input():\n",
        "    return \"\"\n",
        "\n",
        "import random\n",
        "\n",
        "def generate_summarize_prompt( novel, role_name ):\n",
        "    whole_prompt = f'''\n",
        "你在分析小说{novel}中的角色{role_name}\n",
        "结合小说{novel}中的内容，以及下文中角色{role_name}的对话\n",
        "判断{role_name}的人物设定、人物特点以及语言风格\n",
        "\n",
        "{role_name}的对话:\n",
        "'''\n",
        "    stories = [data[\"story\"] for data in role2datas[(novel, role_name)] ]\n",
        "\n",
        "    sample_n = 5\n",
        "\n",
        "    sample_stories = random.sample(stories, sample_n)\n",
        "\n",
        "    for story in sample_stories:\n",
        "        whole_prompt += story + \"\\n\\n\"\n",
        "\n",
        "    return whole_prompt.strip()\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"\"\"# 50本小说的人物测试\n",
        "\n",
        "    这个interface由李鲁鲁实现，现在是用openai的，回头替换成HaruhiZero模型\n",
        "\n",
        "    本来还想实现个随机聊天的功能的，还没来得及写\"\"\")\n",
        "\n",
        "    with gr.Tab(\"聊天\"):\n",
        "        with gr.Row():\n",
        "            novel_sel = gr.Dropdown( novel_list, label = \"小说\", value = \"凡人修仙传\" , interactive = True)\n",
        "            role_sel = gr.Dropdown( novel2roles[novel_sel.value], label = \"角色\", value = \"韩立\", interactive = True )\n",
        "\n",
        "        with gr.Row():\n",
        "            chat_history = gr.Chatbot(height = 600)\n",
        "\n",
        "        with gr.Row():\n",
        "            user_name = gr.Textbox(label=\"user_name\", scale = 1, value = \"鲁鲁\", interactive = True)\n",
        "            user_text = gr.Textbox(label=\"user_text\", scale = 20)\n",
        "            submit = gr.Button(\"submit\", scale = 1)\n",
        "\n",
        "        with gr.Row():\n",
        "            random_chat = gr.Button(\"随机聊天\", scale = 1)\n",
        "            clean_message = gr.Button(\"清空聊天\", scale = 1)\n",
        "\n",
        "        with gr.Row():\n",
        "            persona_addition_info = gr.TextArea( label = \"额外人物设定\", value = \"\",  interactive = True  )\n",
        "\n",
        "        with gr.Row():\n",
        "            update_persona = gr.Button(\"补充人物设定到prompt\", scale = 1)\n",
        "\n",
        "        with gr.Row():\n",
        "            whole_persona = gr.TextArea( label = \"完整的system prompt\", value = \"\",  interactive = False  )\n",
        "\n",
        "        novel_sel.change(fn = get_role_list, inputs = [novel_sel], outputs = [role_sel]).then(fn = initialize_persona, inputs = [novel_sel, role_sel, persona_addition_info], outputs = [whole_persona])\n",
        "\n",
        "        role_sel.change(fn = initialize_persona, inputs = [novel_sel, role_sel, persona_addition_info], outputs = [whole_persona])\n",
        "\n",
        "        update_persona.click(fn = initialize_persona, inputs = [novel_sel, role_sel, persona_addition_info], outputs = [whole_persona])\n",
        "\n",
        "\n",
        "        user_text.submit(fn = submit_chat, inputs = [novel_sel, role_sel, user_name, user_text, chat_history, persona_addition_info], outputs = [chat_history]).then(fn = clean_input, inputs = [], outputs = [user_text])\n",
        "        submit.click(fn = submit_chat, inputs = [novel_sel, role_sel, user_name, user_text, chat_history, persona_addition_info], outputs = [chat_history]).then(fn = clean_input, inputs = [], outputs = [user_text])\n",
        "\n",
        "        clean_message.click(fn = clean_history, inputs = [], outputs = [chat_history])\n",
        "\n",
        "    with gr.Tab(\"README\"):\n",
        "        gr.Markdown(readme_text)\n",
        "\n",
        "    with gr.Tab(\"辅助人物总结\"):\n",
        "        with gr.Row():\n",
        "            generate_prompt = gr.Button(\"生成人物总结prompt\", scale = 1)\n",
        "\n",
        "        with gr.Row():\n",
        "            whole_prompt = gr.TextArea( label = \"复制这个prompt到Openai或者GLM或者Claude进行总结\", value = \"\",  interactive = False  )\n",
        "\n",
        "        generate_prompt.click(fn = generate_summarize_prompt, inputs = [novel_sel, role_sel], outputs = [whole_prompt])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "demo.launch(share=True, debug = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "seyDMdeoh_GE",
        "outputId": "be2fc472-90a8-4a63-f82c-bf48c72f63fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://2d08378b4fd94175bc.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2d08378b4fd94175bc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"novel\": \"凡人修仙传\", \"role\": \"韩立\", \"user_text\": \"鲁鲁 : 我要怎样才能化神啊？\", \"response\": \"韩立: 化神这一步可不是那么容易的。首先，你需要达到元婴后期的修为境界，这是化神的基础。然后，你需要找到一种适合自己的化神法门，这通常需要一位高级修士的指点或者是机缘巧合。接着，你需要准备大量的灵力和灵草灵物，用来支撑化神过程中的能量消耗。最后，你需要在一个适合的时间和地点，进行一次极为危险的化神仪式。这个过程中，你将面临巨大的灵力冲击和灵魂的洗礼。只有成功度过这一关，你才能真正化神。但要记住，化神是一条充满风险和挑战的道路，需要付出巨大的努力和牺牲。\"}\n",
            "{\"novel\": \"凡人修仙传\", \"role\": \"韩立\", \"user_text\": \"鲁鲁 : 一起吃饺子吧\", \"response\": \"韩立: 饺子？哈哈，好啊！我很久没吃过饺子了。不过，你得先告诉我，这里哪里有好吃的饺子吗？\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#备份\n",
        "\n",
        "\n",
        "def submit_chat( novel, role, user_name, user_text, chat_history, persona_addition_info ):\n",
        "\n",
        "    if len(user_text) > 400:\n",
        "        user_text = user_text[:400]\n",
        "\n",
        "    if_user_in_text = True\n",
        "\n",
        "    chatbot = get_chatbot( novel, role )\n",
        "    chatbot.persona = initialize_persona( novel, role,  persona_addition_info)\n",
        "\n",
        "    history = []\n",
        "\n",
        "    for chat_tuple in chat_history:\n",
        "        if chat_tuple[0] is not None:\n",
        "            history.append( {\"speaker\":\"{{user}}\",\"content\":chat_tuple[0]} )\n",
        "        if chat_tuple[1] is not None:\n",
        "            history.append( {\"speaker\":\"{{role}}\",\"content\":chat_tuple[1]} )\n",
        "\n",
        "    chatbot.history = history\n",
        "\n",
        "    input_text = user_text\n",
        "\n",
        "    if if_user_in_text:\n",
        "        input_text = user_name + \" : \" + user_text\n",
        "        response = chatbot.chat(user = \"\", text = input_text )\n",
        "    else:\n",
        "        response = chatbot.chat(user = user_name, text = input_text)\n",
        "\n",
        "    chat_history.append( (user_text, response) )\n",
        "\n",
        "    print_data = {\"novel\":novel, \"role\":role, \"user_text\":input_text, \"response\":response}\n",
        "\n",
        "    print(json.dumps(print_data, ensure_ascii=False))\n",
        "\n",
        "    with open(save_log, \"a\",encoding = \"utf-8\") as f:\n",
        "        f.write(json.dumps(print_data, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    return chat_history"
      ],
      "metadata": {
        "id": "COp_AvsCKl23"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}