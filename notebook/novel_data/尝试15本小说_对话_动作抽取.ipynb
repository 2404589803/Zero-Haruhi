{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFP8MTLALzyx2hXaGzDrR1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Zero-Haruhi/blob/main/notebook/%E5%B0%9D%E8%AF%9515%E6%9C%AC%E5%B0%8F%E8%AF%B4_%E5%AF%B9%E8%AF%9D_%E5%8A%A8%E4%BD%9C%E6%8A%BD%E5%8F%96.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q zhipuai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GJlehWyMPBa",
        "outputId": "fd1d3ad1-bf4f-4a26-eefb-990d1e5dd2ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "\n",
        "import zhipuai\n",
        "\n",
        "zhipuai.api_key  = \"7504\""
      ],
      "metadata": {
        "id": "VqEYW8boPaXn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z_hevNCrRIJ",
        "outputId": "764cc76a-444b-4b98-f1f9-f0ecd19699f1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_c1yqgApHy3",
        "outputId": "88c79131-ad90-47a3-b69c-dc948708b297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dialogueful_novel.jsonl  part_10.txt  part_2.txt  part_4.txt  part_6.txt  part_8.txt\n",
            "part_0.txt\t\t part_1.txt   part_3.txt  part_5.txt  part_7.txt  part_9.txt\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Wuxia/input/all_direct"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def count_quotes_super(text):\n",
        "\n",
        "#     quote_chars = '''「」\"“”:：'''\n",
        "#     count = 0\n",
        "#     for char in text:\n",
        "#         if char in quote_chars:\n",
        "#             count += 1\n",
        "#     return count\n",
        "\n",
        "def count_quotes_super(text):\n",
        "    quote_chars = set('「」\"“”:：')\n",
        "    return sum(char in quote_chars for char in text)\n"
      ],
      "metadata": {
        "id": "BYP_NSrwKi56"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "取出目标的小说"
      ],
      "metadata": {
        "id": "OJxLM4VSMqtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_novels = [   \"凡人修仙传\",   \"斗破苍穹\",   \"仙逆\",   \"遮天\",   \"吞噬星空\",   \"我的美女总裁老婆\",   \"全职高手\",   \"傲世九重天\",   \"网游之永生\",   \"超级兵王\",   \"斗罗大陆Ⅱ绝世唐门\",   \"坏蛋是怎样炼成的Ⅱ\",   \"修魂记\",   \"极品神医\",   \"大周皇族\"]\n",
        "novel2chapters = {}\n",
        "\n",
        "for novel in target_novels:\n",
        "    novel2chapters[novel] = []"
      ],
      "metadata": {
        "id": "-h2bXvuhMsnm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "\n",
        "\n",
        "for part_id in tqdm(range(0, 10)):\n",
        "    fname = \"/content/drive/MyDrive/Wuxia/input/all_direct/part_\"+ str(part_id) +\".txt\"\n",
        "\n",
        "    with open(fname, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            data = json.loads(line)\n",
        "            source = data[\"source\"].strip()\n",
        "            if source not in target_novels:\n",
        "                continue\n",
        "\n",
        "            novel2chapters[source].append(data[\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmZiCU8DasD-",
        "outputId": "93c5fcb5-d35d-44d2-e045-b7d6f0a3982f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [01:57<00:00, 11.70s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for novel in target_novels:\n",
        "    print(novel, len(novel2chapters[novel]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMMzRsjPNnLQ",
        "outputId": "544a3830-c44a-4f26-d46d-6225322cfccd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "凡人修仙传 2477\n",
            "斗破苍穹 1657\n",
            "仙逆 2132\n",
            "遮天 1856\n",
            "吞噬星空 1694\n",
            "我的美女总裁老婆 1675\n",
            "全职高手 1835\n",
            "傲世九重天 2885\n",
            "网游之永生 1732\n",
            "超级兵王 1712\n",
            "斗罗大陆Ⅱ绝世唐门 1724\n",
            "坏蛋是怎样炼成的Ⅱ 1491\n",
            "修魂记 1472\n",
            "极品神医 1231\n",
            "大周皇族 1212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里我们要预处理每个chunk，保留最多quote的部分"
      ],
      "metadata": {
        "id": "RvUN6DSOPGTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6Upbh1yPbJI",
        "outputId": "23ab3797-db3d-474a-800d-5070c2b0d81f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.0 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/2.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/2.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m1.5/2.0 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "enc= tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "o32ex7NjPnaq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_novel = \"斗破苍穹\"\n",
        "current_paragraph_id = 0\n",
        "\n",
        "text = novel2chapters[current_novel][current_paragraph_id]\n",
        "\n",
        "\n",
        "\n",
        "MAX_TOKEN = 1000\n",
        "\n",
        "def find_optimal_subsequence(quotes, tokens):\n",
        "    n = len(tokens)\n",
        "    total_tokens = sum(tokens)\n",
        "    max_quotes = 0\n",
        "    optimal_start_id = 0\n",
        "    optimal_end_id = 0\n",
        "\n",
        "    for start_id in range(n):\n",
        "        tokens_sum = 0\n",
        "        for end_id in range(start_id, n):\n",
        "            tokens_sum += tokens[end_id]\n",
        "            # 当当前子序列的tokens总数小于等于1000时，检查quotes的总和\n",
        "            if tokens_sum <= MAX_TOKEN:\n",
        "                current_quotes = sum(quotes[start_id:end_id + 1])\n",
        "                if current_quotes > max_quotes:\n",
        "                    max_quotes = current_quotes\n",
        "                    optimal_start_id = start_id\n",
        "                    optimal_end_id = end_id\n",
        "            else:\n",
        "                # 一旦tokens总数超过1000，跳出内部循环\n",
        "                break\n",
        "\n",
        "    return optimal_start_id, optimal_end_id+1, max_quotes\n",
        "\n",
        "def find_max_quote_part( text ):\n",
        "\n",
        "    lines = text.split(\"\\n\")\n",
        "    quote_per_line = [count_quotes_super(line) for line in lines]\n",
        "    # print(quote_per_line)\n",
        "    token_per_line = [len(enc.encode(line)) for line in lines]\n",
        "    # print(token_per_line)\n",
        "    # 执行函数并打印结果\n",
        "    start_id, end_id,max_quotes = find_optimal_subsequence(quote_per_line, token_per_line)\n",
        "\n",
        "    current_token = sum(token_per_line[start_id:end_id])\n",
        "\n",
        "    for new_start_id in range(start_id-1, 0 , -1):\n",
        "        if current_token + token_per_line[ new_start_id ] <= MAX_TOKEN:\n",
        "            start_id = new_start_id\n",
        "            current_token += token_per_line[ new_start_id ]\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    for new_end_id in range(end_id, len(lines)):\n",
        "        if current_token + token_per_line[new_end_id] <= MAX_TOKEN:\n",
        "            end_id += 1\n",
        "            current_token += token_per_line[ new_end_id ]\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    # try naive way\n",
        "    naive_count = 0\n",
        "    naive_quote_count = 0\n",
        "    naive_end = 0\n",
        "    for i in range(0, len(lines)):\n",
        "        naive_count += token_per_line[i]\n",
        "        if naive_count > MAX_TOKEN:\n",
        "            naive_end = i\n",
        "            break\n",
        "        naive_quote_count += quote_per_line[i]\n",
        "\n",
        "    if_naive = False\n",
        "\n",
        "    if naive_quote_count * 2 > max_quotes:\n",
        "        start_id = 0\n",
        "        end_id = naive_end\n",
        "        if_naive = True\n",
        "\n",
        "    rest_text = \"\\n\".join(lines[end_id:])\n",
        "\n",
        "    return \"\\n\".join( lines[start_id: end_id] ), if_naive, rest_text\n",
        "\n",
        "\n",
        "print(find_max_quote_part(text)[0])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1SaMg8vPLnA",
        "outputId": "eb0c98e2-2887-4ba6-fbf3-4d0ed19d9fb0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "“斗之力，三段！”\n",
            "望着测验魔石碑上面闪亮得甚至有些刺眼的五个大字，少年面无表情，唇角有着一抹自嘲，紧握的手掌，因为大力，而导致略微尖锐的指甲深深的刺进了掌心之中，带来一阵阵钻心的疼痛……\n",
            "“萧炎，斗之力，三段！级别：低级！”测验魔石碑之旁，一位中年男子，看了一眼碑上所显示出来的信息，语气漠然的将之公布了出来……\n",
            "中年男子话刚刚脱口，便是不出意外的在人头汹涌的广场上带起了一阵嘲讽的骚动。\n",
            "“三段？嘿嘿，果然不出我所料，这个“天才”这一年又是在原地踏步！”\n",
            "“哎，这废物真是把家族的脸都给丢光了。”\n",
            "“要不是族长是他的父亲，这种废物，早就被驱赶出家族，任其自生自灭了，哪还有机会待在家族中白吃白喝。”\n",
            "“唉，昔年那名闻乌坦城的天才少年，如今怎么落魄成这般模样了啊？”\n",
            "“谁知道呢，或许做了什么亏心事，惹得神灵降怒了吧……”\n",
            "周围传来的不屑嘲笑以及惋惜轻叹，落在那如木桩待在原地的少年耳中，恍如一根根利刺狠狠的扎在心脏一般，让得少年呼吸微微急促。\n",
            "少年缓缓抬起头来，露出一张有些清秀的稚嫩脸庞，漆黑的眸子木然的在周围那些嘲讽的同龄人身上扫过，少年嘴角的自嘲，似乎变得更加苦涩了。\n",
            "“这些人，都如此刻薄势力吗？或许是因为三年前他们曾经在自己面前露出过最谦卑的笑容，所以，如今想要讨还回去吧……”苦涩的一笑，萧炎落寞的转身，安静地回到了队伍的最后一排，孤单的身影，与周围的世界，有些格格不入。\n",
            "“下一个，萧媚！”\n",
            "听着测验人的喊声，一名少女快速的人群中跑出，少女刚刚出场，附近的议论声便是小了许多，一双双略微火热的目光，牢牢的锁定着少女的脸颊……\n",
            "少女年龄不过十四左右，虽然并算不上绝色，不过那张稚气未脱的小脸，却是蕴含着淡淡的妩媚，清纯与妩媚，矛盾的集合，让得她成功的成为了全场瞩目的焦点……\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "开始准备数据"
      ],
      "metadata": {
        "id": "knEJGFkLU25G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_datas = []\n",
        "for novel in tqdm(target_novels):\n",
        "    chapters = novel2chapters[novel]\n",
        "    for i, chap in enumerate( chapters ):\n",
        "        rest_text = chap\n",
        "        for j in range(3):\n",
        "            current_chunk, if_naive, rest_text = find_max_quote_part( rest_text )\n",
        "            part_id = novel + \"_\" + str(i) + \"_\" + str(j)\n",
        "            query_datas.append({\n",
        "                \"id\":part_id,\n",
        "                \"text\":current_chunk\n",
        "            })\n",
        "            if not if_naive:\n",
        "                break\n",
        "    # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ceha1_FzTnO-",
        "outputId": "aa387aac-1363-453f-8082-78a098d64423"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [02:09<00:00,  8.66s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(query_datas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRLOhFsxV90Y",
        "outputId": "d54c015a-1c13-4402-9819-3713fe13bc6b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_datas = [data for data in query_datas if len(data[\"text\"]) > 300]"
      ],
      "metadata": {
        "id": "Zu36GkHrbP_o"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "米唯实直接看这里"
      ],
      "metadata": {
        "id": "MMLBv-Megh1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这个pkl在\n",
        "\n",
        "https://drive.google.com/file/d/1addQ9H-qZbkqMfaTjN-2c0XyN7wqd-mE/view?usp=sharing"
      ],
      "metadata": {
        "id": "cLpAUNZnhgcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save query_datas into /content/query_datas.pkl\n",
        "\n",
        "import pickle\n",
        "\n",
        "# 将数据保存到文件\n",
        "with open('/content/drive/MyDrive/CardBuild/exp0204/all_inputs.pkl', 'wb') as file:\n",
        "    pickle.dump(query_datas, file)\n"
      ],
      "metadata": {
        "id": "Tpv_8802gQLM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "49198"
      ],
      "metadata": {
        "id": "4EcQNML4guMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(query_datas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx6j7jugbkrJ",
        "outputId": "028a1810-bebb-4fe4-f196-7f31a915c046"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/output"
      ],
      "metadata": {
        "id": "oK-9jJWQbl4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_datas[1000][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-dG6UQTSd4h",
        "outputId": "dbf91013-b47f-45a4-f4ba-00a69e618d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "“此事不用急，最好还是在这次大战后，再去办这事。毕竟只有让妙音门知道了我们逆星盟的势大，才更好下手一些。到时若是还不肯屈服的话，我听说妙音门有一段时间将总坛设在天星城内，到时我们随便找个私通星宫的借口，还怕此女不乖乖的就范。”老者神色平常的缓缓道。\n",
            "“好，就这么办。对方只有两名结丹初期的长老，还敢螳臂挡轮不成，还是苍道友足智多谋啊！”壮汉哈哈大笑的大喜道。\n",
            "老者闻言微然一笑，同时心里有几分自得的暗想道：“这样一来，就可以借势强压妙音门的这位姓韩长老，到时让其将聚集煞气的诀窍一同乖乖的奉上。真是一箭双雕啊！”\n",
            "想到这里，老者微眯起了双目，脸上露出了一丝诡异的神色。\n",
            "韩立飞离绿袍老者几人，遁光转眼间就到了港口上空。\n",
            "看了那些忙碌的逆星盟修士几眼后，他就要加速离开此地。\n",
            "可就在这时，一股强大的神识毫无遮掩忽然从天而降，一下将韩立罩在了其中。韩立木然一惊，但随即保持神色平静的浮在空中，身形一动不动。\n",
            "就像他心中早就有所预料的一样，对他们这些结丹期修士，逆星盟怎么可能就这样简单的仅凭件信物就放手。\n",
            "估计这是那领队的元婴期老怪，亲自用神识来探测一二的。以防有结丹期修士用秘术变幻了容貌，好伪造他人的身份蒙混过关。\n",
            "韩立的神情镇定异常，没露一丝慌乱之色。他自始至终就未曾想过，用什么假身份来做掩护。因为改变容貌的小把戏，除非两三种传闻中的古籍秘术和几件珍惜之极的宝物外，其余的根本瞒不过神识强大之人的看破。\n",
            "若是改头换面用什么假身份，万一被人看穿了，反而更显得他心虚可疑，大有弄巧成拙的可能。\n",
            "如此一来，他宁愿冒着以后被极阴等人追踪的可能，也一直用那妙音门长老的身份一路应付过来。\n",
            "想起来那些老怪追踪而来的时候，他早已到了外星海了才对。那时就彻底暴露了，也没有什么大的关系了。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task_prompt = \"\"\"### Example 1:\n",
        "input:\n",
        "5 老师严肃地看着学生们，说：「请大家认真听讲。」\n",
        "output:\n",
        "summary:\n",
        "老师让大家认真听讲\n",
        "extracted dialogues:\n",
        "id | [*action*] dialogue | said by | speaker\n",
        "5 | *严肃地看着学生们* \"请大家认真听讲。\" | said by | 老师\n",
        "\n",
        "### Example 2:\n",
        "input:\n",
        "2 李晓边走边说：“我们走快点，天快黑了。”张伟回答道：“好的，我跟上你。”\n",
        "3 “你走慢一点，我有点跟不上了”\n",
        "4 “加油张伟，部队还在前面等着我们”\n",
        "output:\n",
        "summary:\n",
        "李晓鼓励张伟抓紧赶路\n",
        "extracted dialogues:\n",
        "id | [*action*] dialogue | said by | speaker\n",
        "2 | *边走边说* \"我们走快点，天快黑了。\" | said by | 李晓\n",
        "2 | \"好的，我跟上你。\" | said by | 张伟\n",
        "3 | \"你走慢一点，我有点跟不上了\" | said by | 张伟\n",
        "4 | “加油张伟，部队还在前面等着我们” | said by | 李晓\n",
        "\n",
        "Please help me convert \"input\" into a script in CSV format. Extract the dialogues from the paragraphs and output them in CSV format. Let's approach this step by step:\n",
        "- Firstly, summarize the paragraph, starting with 'summary:'.\n",
        "- Then, extract dialogues, starting with 'extracted dialogues:'. For each line, if a dialogue occurs, extract it.\n",
        "- If the speaker performs a certain action, mark it with '*' on both sides of the action.\n",
        "- Output in the format: id | [*action*] dialogue | said by | speaker.\n",
        "\n",
        "input:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "d0O-OWEBRikA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "quote_per_line = [0, 0, 4, 0, 0, 0, 8, 4, 6, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 2, 2, 8, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "token_per_line = [98, 63, 148, 98, 68, 77, 121, 45, 67, 40, 132, 144, 103, 96, 100, 33, 69, 154, 76, 116, 65, 76, 74, 41, 114, 72, 112, 43, 103, 56, 122, 36, 42, 101, 66, 104, 68]\n",
        "\n",
        "我希望实现一个python函数，能够找到最优的start_id和end_id，使得sum(token_per_line[start_id:end_id]) 小于等于1000 的同时 sum(quote_per_line[start_id:end_id] )尽可能大，请用python为我实现\n",
        "\n",
        "Let's think it step by step\n",
        "\n",
        "先把问题转化为 左右各删去一个子序列，使得删去的总token > (sum_token - 1000 )的同时，删去的quote之和尽可能小\n",
        "\n",
        "遍历每一个start_id的情况，来确定最大的end_id\n",
        "\n",
        "从遍历的每个情况中取出最优的结果\n"
      ],
      "metadata": {
        "id": "WAH5XvzGP1M8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_line_head(text):\n",
        "    lines = text.split('\\n')\n",
        "    lines = [ line.strip() for line in lines ]\n",
        "    lines = [ line for line in lines if len(line) > 0 ]\n",
        "    lines = [ str(id+1) + \" \" + line for id, line in enumerate(lines)]\n",
        "    return \"\\n\".join(lines)\n"
      ],
      "metadata": {
        "id": "FB6pDiPYYzhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q langchain\n",
        "\n",
        "# from langchain_community.chat_models import ChatZhipuAI\n",
        "# from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
      ],
      "metadata": {
        "id": "nskq2iHbOj0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3lZ7txQvYzGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# async_chat = ChatZhipuAI(\n",
        "#     temperature=0,\n",
        "#     api_key=zhipuai.api_key,\n",
        "#     model=\"glm-3-turbo\",\n",
        "# )"
      ],
      "metadata": {
        "id": "LmE8lBHpW1M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# messages = [\n",
        "#     HumanMessage(content=task_prompt + query_datas[1000][\"text\"]),\n",
        "# ]"
      ],
      "metadata": {
        "id": "fpWzN7c2XOK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"user\", \"content\":task_prompt + add_line_head(query_datas[1000][\"text\"])}]"
      ],
      "metadata": {
        "id": "gtKmclPAYShC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from zhipuai import ZhipuAI\n",
        "client = ZhipuAI(api_key=zhipuai.api_key) # 填写您自己的APIKey\n",
        "response = client.chat.completions.create(\n",
        "    model=\"glm-3-turbo\",  # 填写需要调用的模型名称\n",
        "    messages=messages,\n",
        "    temperature=0.1\n",
        ")\n"
      ],
      "metadata": {
        "id": "Ti4_80N4XdVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35xjDnCOYrtO",
        "outputId": "bea7544a-8134-43e9-9f5b-9a40328765e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "summary:\n",
            "老者计划在大战后利用妙音门的弱势，迫使韩立屈服并获取其秘密。壮汉赞同此计，认为老者足智多谋。老者暗自得意，计划利用形势压迫韩立，并得到其煞气诀窍。韩立飞离老者，但在港口上空被逆星盟修士用神识探测。韩立保持镇定，决定不使用假身份，以免引起怀疑。\n",
            "\n",
            "extracted dialogues:\n",
            "id | [*action*] dialogue | said by | speaker\n",
            "1 | *神色平常的缓缓道* \"此事不用急，最好还是在这次大战后，再去办这事。毕竟只有让妙音门知道了我们逆星盟的势大，才更好下手一些。到时若是还不肯屈服的话，我听说妙音门有一段时间将总坛设在天星城内，到时我们随便找个私通星宫的借口，还怕此女不乖乖的就范。\" | said by | 老者\n",
            "2 | *哈哈大笑的大喜道* \"好，就这么办。对方只有两名结丹初期的长老，还敢螳臂挡轮不成，还是苍道友足智多谋啊！\" | said by | 壮汉\n",
            "3 | *微然一笑* \"这样一来，就可以借势强压妙音门的这位姓韩长老，到时让其将聚集煞气的诀窍一同乖乖的奉上。真是一箭双雕啊！\" | said by | 老者\n",
            "4 | *微眯起了双目，脸上露出了一丝诡异的神色* | said by | 老者\n",
            "5 | *飞离绿袍老者几人* | said by | 韩立\n",
            "6 | *看了那些忙碌的逆星盟修士几眼后，就要加速离开此地* | said by | 韩立\n",
            "7 | *一股强大的神识毫无遮拦忽然从天而降，一下将韩立罩在了其中* | said by | 逆星盟领队的元婴期老怪\n",
            "8 | *保持神色平静的浮在空中，身形一动不动* | said by | 韩立\n",
            "9 | *对他们这些结丹期修士，逆星盟怎么可能就这样简单的仅凭件信物就放手* | said by | 韩立\n",
            "10 | *神识来探测一二的。以防有结丹期修士用秘术变幻了容貌，好伪造他人的身份蒙混过关* | said by | 韩立\n",
            "11 | *没露一丝慌乱之色。他自始至终就未曾想过，用什么假身份来做掩护* | said by | 韩立\n",
            "12 | *宁愿冒着以后被极阴等人追踪的可能，也一直用那妙音门长老的身份一路应付过来* | said by | 韩立\n",
            "13 | *想起来那些老怪追踪而来的时候，他早已到了外星海了才对。那时就彻底暴露了，也没有什么大的关系了。* | said by | 韩立\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def get_response( messages ):\n",
        "    client = ZhipuAI(api_key=zhipuai.api_key) # 填写您自己的APIKey\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"glm-3-turbo\",  # 填写需要调用的模型名称\n",
        "        messages=messages,\n",
        "        temperature=0.1\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n"
      ],
      "metadata": {
        "id": "4jzrR8tFZN1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q aiofiles"
      ],
      "metadata": {
        "id": "IRSAcbEyZpph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "# import openai\n",
        "import asyncio\n",
        "import aiofiles\n",
        "import tiktoken\n",
        "import hashlib\n",
        "# from connector import AsyncPGConnector\n",
        "from tqdm.asyncio import tqdm as tqdm\n",
        "\n",
        "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "en2zh_ratio = 2.3\n",
        "\n",
        "delay = 1\n",
        "concurrency_limit = 16\n",
        "\n",
        "max_file_size = 1024**3"
      ],
      "metadata": {
        "id": "QNSQH_avZmIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def getTranslation(item):\n",
        "    if \"messages\" not in item:\n",
        "        return None\n",
        "    else:\n",
        "        messages = item['messages']\n",
        "        sleep_time = 1\n",
        "        for i in range(5):\n",
        "            result = await get_response( messages )\n",
        "            if result is not None:\n",
        "                item[\"response\"] = result\n",
        "                return item\n",
        "            else:\n",
        "                await asyncio.sleep(sleep_time)\n",
        "                sleep_time = min(5, sleep_time * 2)\n",
        "                continue\n",
        "\n",
        "    return None\n",
        "\n",
        "async def process(item, semaphore):\n",
        "    async with semaphore:\n",
        "        try:\n",
        "            output_folder = \"/content/output\"\n",
        "            if \"output_folder\" in item:\n",
        "                output_folder = item[\"output_folder\"]\n",
        "            if not os.path.exists(output_folder):\n",
        "                os.makedirs(output_folder)\n",
        "\n",
        "            file_path = os.path.join(output_folder, f\"{item['id']}.txt\")\n",
        "\n",
        "            if os.path.exists(file_path):\n",
        "                return\n",
        "\n",
        "            it = await getTranslation(item)\n",
        "            if it is None:\n",
        "                raise Exception(item['id'])\n",
        "\n",
        "            with open(file_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(it, f, ensure_ascii=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            # print(f\"Error processing entry: {e}\")\n",
        "            return\n"
      ],
      "metadata": {
        "id": "I9JaTHm7ZnRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data2messages( data ):\n",
        "    return [{\"role\": \"user\", \"content\":task_prompt + add_line_head(data[\"text\"])}]"
      ],
      "metadata": {
        "id": "1QY0Y4MsZ76I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_datas[0].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csRpYqsiaHxD",
        "outputId": "0def86e7-668b-438c-df34-80648923e94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['id', 'text'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def main( datas ):\n",
        "    process_data = []\n",
        "\n",
        "    output_folder = \"/content/output\"\n",
        "\n",
        "    for data in datas:\n",
        "        process_data.append({\n",
        "            \"id\": data['id'],\n",
        "            \"messages\": data2messages(data),\n",
        "            \"output_folder\": output_folder\n",
        "        })\n",
        "\n",
        "    tasks = []\n",
        "\n",
        "    semaphore = asyncio.Semaphore(concurrency_limit)\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for item in process_data:\n",
        "        file_path = os.path.join(output_folder, f\"{item['id']}.txt\")\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            continue\n",
        "\n",
        "        tasks.append(asyncio.create_task(process(item, semaphore)))\n",
        "\n",
        "    # # del exist_list\n",
        "    # print(f\"Total items: {len(process_data)}\")\n",
        "\n",
        "    async for task in tqdm(tasks, total=len(tasks), desc=\"Processing items\"):\n",
        "        await task\n",
        "        time.sleep(delay)\n",
        "\n"
      ],
      "metadata": {
        "id": "uvsqDFr7ZxvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/output"
      ],
      "metadata": {
        "id": "JrdvXMZKbufU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datas = query_datas"
      ],
      "metadata": {
        "id": "v0fhxKlzaYA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/CardBuild/exp0204/output/"
      ],
      "metadata": {
        "id": "BI3QRnPyb38B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = 0\n",
        "end_id = 10\n",
        "\n",
        "current_tasks = datas[start_id:end_id]\n",
        "\n",
        "await main(current_tasks)\n",
        "\n",
        "temp_output_folder = \"/content/output\"\n",
        "\n",
        "for id in range(start_id, end_id):\n",
        "    id_str = datas[id][\"id\"]\n",
        "    file_path = os.path.join(temp_output_folder, f\"{id_str}.txt\")\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            try:\n",
        "                data = json.load(f)\n",
        "                response = data[\"response\"]\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        if response is not None:\n",
        "            datas[id][\"response\"] = response\n",
        "\n",
        "final_save_name = \"/content/drive/MyDrive/CardBuild/exp0204/output/\" + str(start_id) + \"_to_\" + str(end_id) + \".txt\"\n",
        "\n",
        "with open(final_save_name, 'w', encoding='utf-8') as f:\n",
        "    for id in range(start_id, end_id):\n",
        "        json.dump(datas[id], f, ensure_ascii=False)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VJcSgzpae-v",
        "outputId": "2d444981-0fb1-4500-cd2b-2b867a5876dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 10/10 [02:05<00:00, 12.51s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "super_start = 10\n",
        "super_end = len(datas)\n",
        "n_bag = 300\n",
        "\n",
        "# 计算每个子区间的长度\n",
        "interval_length = (super_end - super_start) // n_bag\n",
        "\n",
        "# 生成元组列表\n",
        "se_tuples_list = [(super_start + i * interval_length, super_start + (i + 1) * interval_length) for i in range(n_bag - 1)]\n",
        "\n",
        "# 添加最后一个元组，确保最后一个end等于super_end\n",
        "se_tuples_list.append((se_tuples_list[-1][1], super_end))\n",
        "\n",
        "# 打印生成的元组列表\n",
        "print(se_tuples_list[0:2])\n",
        "print(se_tuples_list[-2:])\n",
        "\n",
        "import random\n",
        "\n",
        "random.shuffle(se_tuples_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K957UTWda_hU",
        "outputId": "d349d1eb-9586-42eb-da0a-918b9dde3ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(10, 173), (173, 336)]\n",
            "[(48584, 48747), (48747, 49198)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for start_id, end_id in se_tuples_list:\n",
        "    current_tasks = datas[start_id:end_id]\n",
        "\n",
        "    final_save_name = \"/content/drive/MyDrive/CardBuild/exp0204/output/\" + str(start_id) + \"_to_\" + str(end_id) + \".txt\"\n",
        "\n",
        "    if os.path.exists(final_save_name):\n",
        "        print(\"skip \", str(start_id) + \"_to_\" + str(end_id) )\n",
        "        continue\n",
        "\n",
        "    await main(current_tasks)\n",
        "    await main(current_tasks)\n",
        "\n",
        "    temp_output_folder = \"/content/output\"\n",
        "\n",
        "    for id in range(start_id, end_id):\n",
        "        id_str = datas[id][\"id\"]\n",
        "        file_path = os.path.join(temp_output_folder, f\"{id_str}.txt\")\n",
        "        if os.path.exists(file_path):\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                    response = data[\"response\"]\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            if response is not None:\n",
        "                datas[id][\"response\"] = response\n",
        "        # break\n",
        "\n",
        "    with open(final_save_name, 'w', encoding='utf-8') as f:\n",
        "        for id in range(start_id, end_id):\n",
        "            json.dump(datas[id], f, ensure_ascii=False)\n",
        "            f.write('\\n')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J60bUfbxal8y",
        "outputId": "fcf6a14b-7e63-4cf8-c69d-df220127f6c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing items:   0%|          | 0/163 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EtoNN-99dWSW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}