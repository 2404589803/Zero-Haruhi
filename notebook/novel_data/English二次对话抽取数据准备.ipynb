{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZfNhp6Wl7fB9ENeMaQ26j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Zero-Haruhi/blob/main/notebook/English%E4%BA%8C%E6%AC%A1%E5%AF%B9%E8%AF%9D%E6%8A%BD%E5%8F%96%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqEYW8boPaXn",
        "outputId": "bc548c3b-8354-46b7-8ccf-25a154e6f864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import httpx\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]  = \"sk-JEBR\"\n",
        "\n",
        "import openai\n",
        "from openai import AsyncOpenAI\n"
      ],
      "metadata": {
        "id": "aMr5D92qPcdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z_hevNCrRIJ",
        "outputId": "17661676-54ff-45f6-da6f-69bb76a5e14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_name = \"/content/drive/MyDrive/CardBuild/exp0122/english_segs.txt\"\n",
        "\n",
        "import json\n",
        "\n",
        "seg_datas = []\n",
        "\n",
        "with open(input_name, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        if line.strip() == \"\":\n",
        "            continue\n",
        "        data = json.loads(line)\n",
        "        seg_datas.append(data)\n"
      ],
      "metadata": {
        "id": "iU7X7B4sWfkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(seg_datas[0].keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQBEACCBWix2",
        "outputId": "af322168-2dbd-4649-a7b8-0294d053e527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['id', 'raw_seg'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(seg_datas[0]['id'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQy3cvL1XDiE",
        "outputId": "0dc8a39d-bb74-4883-8316-138ffae977b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(seg_datas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns9QtTBrXjyY",
        "outputId": "6c31b621-32e0-4f96-fecc-ced36e995065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2seg_index = {}\n",
        "for i, data in enumerate(seg_datas):\n",
        "    id2seg_index[str(data[\"id\"])+\"_first\"] =  i"
      ],
      "metadata": {
        "id": "Y_5EMjYHWkjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(seg_datas[0]['id'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Wl36VkFXCu2",
        "outputId": "6a05e2c1-ce9d-403d-c4e2-9ea760f2e612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/CardBuild/exp0122/first/\"\n",
        "\n",
        "datas = []\n",
        "\n",
        "import json\n",
        "\n",
        "# 遍历指定文件夹中的所有txt文件\n",
        "for filename in os.listdir(save_path):\n",
        "    if filename.endswith(\".txt\") and filename.startswith(\"0122english_\"):\n",
        "        # 构建完整的文件路径\n",
        "        file_path = os.path.join(save_path, filename)\n",
        "\n",
        "        # 打开并读取文件\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            for line in file:\n",
        "                data = json.loads(line)\n",
        "                response_str = data[\"response\"]\n",
        "                try:\n",
        "                    response = json.loads(response_str)\n",
        "                    data[\"response\"] = response\n",
        "                    datas.append(data)\n",
        "                except:\n",
        "                    continue\n"
      ],
      "metadata": {
        "id": "shZcUVDMVco4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(datas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTQbw-3QYE8c",
        "outputId": "3f4f0501-2580-4244-f010-699db2d52751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(datas[250].keys())\n",
        "print(datas[25]['id'])\n",
        "# print(datas[25][\"text\"])\n",
        "print(datas[25][\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTN1TPfoVyTl",
        "outputId": "6e7b0dd6-e9b5-478f-ad7b-b4146064f6ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['id', 'text', 'n_quote', 'response'])\n",
            "10233_first\n",
            "{'summary': 'Edith suggests Julian visit the gymnasium to see how they train. The doctor explains the public training for all-around physical development. They discuss the differences in physical education between the 20th and 21st centuries. They observe a foot race and discuss the inclusivity of the youth in the event.', 'conversations': [{'num': 1, 'dialogue': 'Considering what you have been telling Julian about women nowadays as compared with the old days, I wonder if he would not be interested in visiting the gymnasium this afternoon and seeing something of how we train ourselves? There are going to be some foot races and air races, and a number of other tests. It is the afternoon when our year has the grounds, and I ought to be there anyway.', 'said by': 'Edith'}, {'num': 3, 'dialogue': 'To this suggestion, which was eagerly accepted, I owe one of the most interesting and instructive experiences of those early days during which I was forming the acquaintance of the twentieth-century civilization.', 'said by': 'Narrator'}, {'num': 5, 'dialogue': 'Is she to compete in anything?', 'said by': 'Narrator'}, {'num': 6, 'dialogue': 'All her year--that is, all of her age--in this ward will be entered in more or less events.', 'said by': 'Doctor'}, {'num': 7, 'dialogue': \"What is Edith's specialty?\", 'said by': 'Narrator'}, {'num': 8, 'dialogue': 'As to specialties, our people do not greatly cultivate them. Of course, privately they do what they please, but the object of our public training is not so much to develop athletic specialties as to produce an all-around and well-proportioned physical development. We aim first of all to secure a certain standard of strength and measurement for legs, thighs, arms, loins, chest, shoulders, neck, etc. This is not the highest point of perfection either of physique or performance. It is the necessary minimum. All who attain it may be regarded as sound and proper men and women. It is then left to them as they please individually to develop themselves beyond that point in special directions.', 'said by': 'Doctor'}, {'num': 10, 'dialogue': 'It is as obligatory as any part of the educational course until the body is set, which we put at the age of twenty-four; but it is practically kept up through life, although, of course, that is according to just how one feels.', 'said by': 'Doctor'}, {'num': 11, 'dialogue': 'Do you mean that you take regular exercise in a gymnasium?', 'said by': 'Narrator'}, {'num': 12, 'dialogue': 'Why should I not? It is no less of an object to me to be well at sixty than it was at twenty.', 'said by': 'Doctor'}, {'num': 13, 'dialogue': 'Doctor, if I seem surprised you must remember that in my day it was an adage that no man over forty-five ought to allow himself to run for a car, and as for women, they stopped running at fifteen, when their bodies were put in a vise, their legs in bags, their toes in thumbscrews, and they bade farewell to health.', 'said by': 'Narrator'}, {'num': 14, 'dialogue': 'You do indeed seem to have disagreed terribly with your bodies. The women ignored theirs altogether, and as for the men, so far as I can make out, up to forty they abused their bodies, and after forty their bodies abused them, which, after all, was only fair. The vast mass of physical misery caused by weakness and sickness, resulting from wholly preventable causes, seems to us, next to the moral aspect of the subject, to be one of the largest single items chargeable to your system of economic inequality, for to that primal cause nearly every feature of the account appears directly or indirectly traceable. Neither souls nor bodies could be considered by your men in their mad struggle for a living, and for a grip on the livelihood of others, while the complicated system of bondage under which the women were held perverted mind and body alike, till it was a wonder if there were any health left in them.', 'said by': 'Doctor'}, {'num': 15, 'dialogue': 'Am I to understand that this is a fair sample of your youth, and not a picked assembly of the more athletic?', 'said by': 'Narrator'}, {'num': 17, 'dialogue': 'Certainly; all the youth in their twenty-third year who live in this ward are here to-day, with perhaps two or three exceptions on account of some special reason.', 'said by': 'Doctor'}, {'num': 18, 'dialogue': 'But where are the cripples, the deformed, the feeble, the consumptive?', 'said by': 'Narrator'}, {'num': 21, 'dialogue': 'Yes, replied my companion: he met with an accident, and will never be vigorous. He is the only sickly one of the class, and you see how much the others make of him. Your cripples and sickly were so many that pity itself grew weary and spent of tears, and compassion callous with use; but with us they are so few as to be our pets and darlings.', 'said by': 'Doctor'}, {'num': 22, 'dialogue': 'Edith, I see, was third in, said the doctor, reading from the signals. She will be pleased to have done so well, seeing you were here.', 'said by': 'Narrator'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "因为是第一次抽取，所以我们只要每个seg的第一个"
      ],
      "metadata": {
        "id": "4Cw4ig6FNFhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_quotes(text):\n",
        "\n",
        "    quote_chars = '''「」\"“”'''\n",
        "    count = 0\n",
        "    for char in text:\n",
        "        if char in quote_chars:\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "input_datas = []\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "for data in tqdm(datas):\n",
        "    id = data['id']\n",
        "    if id not in id2seg_index:\n",
        "        print(id, ' not found')\n",
        "        continue\n",
        "    seg_index = id2seg_index[id]\n",
        "    segs = seg_datas[seg_index][\"raw_seg\"]\n",
        "    if len(segs) < 2:\n",
        "        continue\n",
        "\n",
        "    if \"summary\" not in data[\"response\"]:\n",
        "        continue\n",
        "\n",
        "    text = data[\"response\"][\"summary\"] + \"\\n\" + segs[1]\n",
        "    id_str = data[\"id\"]\n",
        "    if id_str.endswith(\"_first\"):\n",
        "        id_str = id_str.replace(\"_first\", \"_second\")\n",
        "    else:\n",
        "        id_str = id_str + \"_second\"\n",
        "\n",
        "    input_data = {\n",
        "        \"id\": id_str,\n",
        "        \"text\": text,\n",
        "        \"n_quote\": count_quotes(text)\n",
        "    }\n",
        "    input_datas.append(input_data)\n",
        "    # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og2nVbjONDsU",
        "outputId": "82342aba-1b7a-4b97-ff55-baf13341de6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17593/17593 [00:03<00:00, 5825.69it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(input_datas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtGfckNFXTim",
        "outputId": "c3688df6-b469-4e86-fa34-c94ebd5e4865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_datas[0]['text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICH3VwiGQPjB",
        "outputId": "5d30622e-f23f-45e7-dbd5-e329f2022988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cory Doctorow wrote Little Brother in a white-hot fury over the course of eight weeks. The book was trying to get out of his head, leading to sleep deprivation and missed meals. The author's father was one of the few 'counterculture' people who thought computers were a good thing in the 1960s. The author's fascination with activist causes grew as he saw how communications tools were being used to bring information and revolution to authoritarian states. However, 17 years later, computers are being used to spy, control, and restrict freedoms. The author expresses concern about the dangers of technology and the loss of privacy and freedom. The book is meant to be part of the conversation about what an information society means and encourages taking action for freedom and privacy.\n",
            "I wrote Little Brother in a white-hot fury between May 7, 2007 and July 2, 2007: exactly eight weeks from the day I thought it up to the day I finished it (Alice, to whom this book is dedicated, had to put up with me clacking out the final chapter at 5AM in our hotel in Rome, where we were celebrating our anniversary). I'd always dreamed of having a book just materialize, fully formed, and come pouring out of my fingertips, no sweat and fuss -- but it wasn't nearly as much fun as I'd thought it would be. There were days when I wrote 10,000 words, hunching over my keyboard in airports, on subways, in taxis -- anywhere I could type. The book was trying to get out of my head, no matter what, and I missed so much sleep and so many meals that friends started to ask if I was unwell.\n",
            "When my dad was a young university student in the 1960s, he was one of the few \"counterculture\" people who thought computers were a good thing. For most young people, computers represented the de-humanization of society. University students were reduced to numbers on a punchcard, each bearing the legend \"DO NOT BEND, SPINDLE, FOLD OR MUTILATE,\" prompting some of the students to wear pins that said, \"I AM A STUDENT: DO NOT BEND, SPINDLE, FOLD OR MUTILATE ME.\" Computers were seen as a means to increase the ability of the authorities to regiment people and bend them to their will.\n",
            "When I was a 17, the world seemed like it was just going to get more free. The Berlin Wall was about to come down. Computers -- which had been geeky and weird a few years before -- were everywhere, and the modem I'd used to connect to local bulletin board systems was now connecting me to the entire world through the Internet and commercial online services like GEnie. My lifelong fascination with activist causes went into overdrive as I saw how the main difficulty in activism -- organizing -- was getting easier by leaps and bounds (I still remember the first time I switched from mailing out a newsletter with hand-written addresses to using a database with mail-merge). In the Soviet Union, communications tools were being used to bring information -- and revolution -- to the farthest-flung corners of the largest authoritarian state the Earth had ever seen.\n",
            "But 17 years later, things are very different. The computers I love are being co-opted, used to spy on us, control us, snitch on us. The National Security Agency has illegally wiretapped the entire USA and gotten away with it. Car rental companies and mass transit and traffic authorities are watching where we go, sending us automated tickets, finking us out to busybodies, cops and bad guys who gain illicit access to their databases. The Transport Security Administration maintains a \"no-fly\" list of people who'd never been convicted of any crime, but who are nevertheless considered too dangerous to fly. The list's contents are secret. The rule that makes it enforceable is secret. The criteria for being added to the list are secret. It has four-year-olds on it. And US senators. And decorated veterans -- actual war heroes.\n",
            "The 17 year olds I know understand to a nicety just how dangerous a computer can be. The authoritarian nightmare of the 1960s has come home for them. The seductive little boxes on their desks and in their pockets watch their every move, corral them in, systematically depriving them of those new freedoms I had enjoyed and made such good use of in my young adulthood.\n",
            "What's more, kids were clearly being used as guinea-pigs for a new kind of technological state that all of us were on our way to, a world where taking a picture was either piracy (in a movie theater or museum or even a Starbucks), or terrorism (in a public place), but where we could be photographed, tracked and logged hundreds of times a day by every tin-pot dictator, cop, bureaucrat and shop-keeper. A world where any measure, including torture, could be justified just by waving your hands and shouting \"Terrorism! 9/11! Terrorism!\" until all dissent fell silent.\n",
            "We don't have to go down that road.\n",
            "If you love freedom, if you think the human condition is dignified by privacy, by the right to be left alone, by the right to explore your weird ideas provided you don't hurt others, then you have common cause with the kids whose web-browsers and cell phones are being used to lock them up and follow them around.\n",
            "If you believe that the answer to bad speech is more speech -- not censorship -- then you have a dog in the fight.\n",
            "If you believe in a society of laws, a land where our rulers have to tell us the rules, and have to follow them too, then you're part of the same struggle that kids fight when they argue for the right to live under the same Bill of Rights that adults have.\n",
            "This book is meant to be part of the conversation about what an information society means: does it mean total control, or unheard-of liberty? It's not just a noun, it's a verb, it's something you do. DO SOMETHING\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "给定Paragraph，抽取其中的对话，并输出为json格式\n",
        "\n",
        "Let's think it step by step\n",
        "1. 对Paragraph进行总结，存储在summary字段\n",
        "2. 抽取每一句对话的内容 dialogue，以及对话的说话人 said by, 存储在conversations中\n",
        "\n"
      ],
      "metadata": {
        "id": "39lFGhV8NE72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_order = list(range(len(input_datas)))\n",
        "import random\n",
        "random.shuffle(random_order)\n",
        "\n",
        "for id in random_order:\n",
        "    data = input_datas[id]\n",
        "    if data[\"n_quote\"] > 30:\n",
        "        print(data[\"text\"])\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZO23Or1N6Fv",
        "outputId": "03cadee5-58b8-4690-d871-cd3ec1cea265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chapter 1\n",
            "It's been one week since Deuce has been born and Sarah and Damion are sitting in the hospital room alone and Sarah says,\"Are you going to change me now that Deuce has been born?\"  \"No. I absolutely refuse to change you,\" Damion said.  \"But what happens if they find us and the elder finds out that I had the baby and you haven't changed me yet?\" Sarah asked.  \"I-,\" Damion replied.  \"Well? Are you going to answer me?\" Sarah asked.  \"I don't know what's going to happen. If they find us they arer going to want me dead,\" Damion replied.  \"Why would they want you dead?\" Sarah asked.  \"Cause I killed Erika,\" Damion replied,\"When are you going to take Deuce home anyway?\"  \"I don't know,\" Sarah said in a pissed off tone.  \"Are you mad at me now?\" Damion asked.  \"What do you think?\" Sarah replied,\"Are you going to change me or let them kill me if they find us?\"  \"I would really hate to see you killed. But I also don't want this life for you,\" Damion said.  \"I understand that. But I don't want to life my life on the run all the time either,\" Sarah said.  \"I know you don't. That's why I made the decision to leave and never come back,\" Damion said,\"And you are going to stay here with your mom.\"  \"But Damion, I don't want you to leave. I want you to stay here with me,\" Sarah said, a tear slipping out of her eye.  \"I know. But you and Deuce will be safer if I'm gone,\" Damion said.  \"So you're just going to leave,\" Sarah said, another tear slipping from her eye.  \"I'm leaving cause I want you to be safe and live a human life. Trust me leaving you hurts me too. But it's the only way that I know you and Deuce will be safe,\" Damion said.  \"But Damion, will I ever see you again?\" Sarah said.  \"Only in your dreams. I'm never going to return here,\" Damion said.  \"Okay. When are you leaving?\" Sarah asked.  \"This is the last time you will ever see me,\" Damion replied.  \"Okay,\" Sarah said, Tears falling from her eyes.  Damion bends down and kisses Deuce on the forhead and then presses his lips to Sarah's with as much passion as he can. After a few min they break apart and Damion says,\"Goodbye Sarah. I will always love you.\"  \"Goodbye. Me too,\" Sarah said. Damion leaves and Sarah breaks down in tears and cries herself to sleep. The next morning A nurse walks in and says,\"You are going home today.\"  \"Okay. Thank you,\" Sarah said in a depressed tone. A few hours pass by and Sarah is at home feeding Deuce. While she is feeding Deuce her mom notices that she is depressed and says,\"Is everything okay dear?\"  \"No. Damion left and he isn't coming back,\" Sarah said.  \"It'll be okay,\" Chloe said.  \"I know. But the last words he said to me before he left yesterday are-,\" Sarah started but wasn't able to finish.  \"What were his last words to you?\" Chloe asked.  \"His lat words were, 'I will always love you.' It hurts to know that I'll never see him again other then in my dreams,\" Sarah repled.   \"Wow. At least you know that he still loves you,\" Chloe said.   \"Yeah. I guess,\" Sarah said.  Sarah finishes feeding Deuce and says,\"I'm going to put Deuce to bed. I'll talk to you later mom.\"  \"Okay. Talk to you later dear,\" Chloe said. Sarah goes up and puts Deuce in his crib and thinks, \"Why did you have to leave Damion?\"  After Sarah puts Deuce in his crib she goes to bed herself.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task_prompt = \"\"\"\"Given an input paragraph, extract the dialogues within it, and output them in JSON format.\n",
        "\n",
        "Let's think about it step by step:\n",
        "- Summarize the input paragraph into bullet points and store it in the 'summary' field.\n",
        "- recall the line number('num'), Extract the content of each dialogue ('dialogue'), identify the speaker for each sentence ('said by'), and store these in 'conversations'.\"\"\"\n",
        "\n",
        "\n",
        "long_task_prompt_prefix = \"\"\"Given an input paragraph, extract the dialogues within it, and output them in JSON format.\n",
        "\n",
        "Let's think about it step by step:\n",
        "- Summarize the input paragraph into bullet points and store it in the 'summary' field.\n",
        "- recall the line number('num'), Extract the content of each dialogue ('dialogue'), identify the speaker for each sentence ('said by'), and store these in 'conversations'.\"\"\"\n",
        "\n",
        "no_dialogue_prompt_hint = \"if it is not a dialogue, output conversation as an empty list\"\n",
        "\n",
        "long_task_prompt_example = \"\"\"\n",
        "Example input paragraph:\n",
        "1 The sun was setting behind the hills, casting long shadows across the valley. Birds chirped their evening songs, and a gentle breeze stirred the leaves.\n",
        "2 Amidst this serene scene, Alex and Jamie were having a heated argument. Alex exclaimed, 'I can't believe you didn't tell me about the meeting yesterday!' Jamie retorted, 'Well, I thought you already knew since it was on the calendar!'\n",
        "3 Their voices rose above the tranquil sounds of nature. Alex, trying to calm down, said, 'We need to communicate better in the future.'\n",
        "4 Jamie agreed, replying, 'You're right, I should have double-checked with you.'\n",
        "\n",
        "example output:\n",
        "{\n",
        "    \"summary\": \"Sunset behind hills, casting shadows in the valley. Birds chirping, gentle breeze stirring leaves. Alex and Jamie having a heated argument. Discussion about a missed meeting and communication issues.\",\n",
        "    \"conversations\": [\n",
        "        {\n",
        "            \"num\": 2,\n",
        "            \"dialogue\": \"I can't believe you didn't tell me about the meeting yesterday!\",\n",
        "            \"said by\": \"Alex\"\n",
        "        },\n",
        "        {\n",
        "            \"num\": 2,\n",
        "            \"dialogue\": \"Well, I thought you already knew since it was on the calendar!\",\n",
        "            \"said by\": \"Jamie\"\n",
        "        },\n",
        "        {\n",
        "            \"num\": 3,\n",
        "            \"dialogue\": \"We need to communicate better in the future.\",\n",
        "            \"said by\": \"Alex\"\n",
        "        },\n",
        "        {\n",
        "            \"num\": 4,\n",
        "            \"dialogue\": \"You're right, I should have double-checked with you.\",\n",
        "            \"said by\": \"Jamie\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "7l8sC21JN1FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q aiofiles tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdXZX7KgRlj0",
        "outputId": "c8a3a5ff-90ad-405c-ad79-57643b0a0f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/2.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/2.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m1.9/2.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "# import openai\n",
        "from openai import AsyncOpenAI\n",
        "\n",
        "aclient = AsyncOpenAI()\n",
        "\n",
        "import asyncio\n",
        "import aiofiles\n",
        "import tiktoken\n",
        "import hashlib\n",
        "# from connector import AsyncPGConnector\n",
        "from tqdm.asyncio import tqdm as tqdm\n",
        "\n",
        "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "en2zh_ratio = 2.3\n",
        "\n",
        "delay = 1\n",
        "concurrency_limit = 16\n",
        "\n",
        "max_file_size = 1024**3"
      ],
      "metadata": {
        "id": "z1oHyqNsELxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def dealing_messages(messages):\n",
        "    try:\n",
        "        # request_token = sum([len(enc.encode(msg['content'])) for msg in messages])\n",
        "        # response_token = int(len(enc.encode(text)) * en2zh_ratio) + 64\n",
        "\n",
        "        model = \"gpt-3.5-turbo-1106\"\n",
        "\n",
        "        resp = await aclient.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=0,\n",
        "            response_format={ \"type\": \"json_object\" }\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            result = resp.choices[0].message.content\n",
        "            result = result.strip()\n",
        "            return result\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"Invalid json: \", result)\n",
        "            return None\n",
        "        except:\n",
        "            raise Exception(f\"Invalid API response: {resp}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[Error] {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def add_line_num( text ):\n",
        "    new_text = \"\"\n",
        "    lines = text.split(\"\\n\")\n",
        "    line_count = 1\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":\n",
        "            new_text += \"\\n\"\n",
        "        else:\n",
        "            new_text += f\"{line_count} {line}\\n\"\n",
        "            line_count += 1\n",
        "    return new_text\n",
        "\n",
        "def data2messages( data ):\n",
        "    n_quote = data[\"n_quote\"]\n",
        "    if n_quote >= 20:\n",
        "        task_prompt = long_task_prompt_prefix + \"\\n\" + long_task_prompt_example\n",
        "    else:\n",
        "        task_prompt = long_task_prompt_prefix + \"\\n\" + no_dialogue_prompt_hint + \"\\n\" + long_task_prompt_example\n",
        "    input_text = add_line_num(data[\"text\"])\n",
        "    messages = [\n",
        "        {\"role\":\"system\",\"content\":task_prompt},\n",
        "        {\"role\":\"user\",\"content\":f\"input paragraph:\\n{input_text}\"}\n",
        "    ]\n",
        "    return messages"
      ],
      "metadata": {
        "id": "wgtJmUwmQitK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def getTranslation(item):\n",
        "    if \"messages\" not in item:\n",
        "        return None\n",
        "    else:\n",
        "        for i in range(3):\n",
        "            result = await dealing_messages(item['messages'])\n",
        "            if result is not None:\n",
        "                item[\"response\"] = result\n",
        "                return item\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    return None\n",
        "\n",
        "async def process(item, semaphore):\n",
        "    async with semaphore:\n",
        "        try:\n",
        "            output_folder = \"/content/output\"\n",
        "            if \"output_folder\" in item:\n",
        "                output_folder = item[\"output_folder\"]\n",
        "            if not os.path.exists(output_folder):\n",
        "                os.makedirs(output_folder)\n",
        "\n",
        "            file_path = os.path.join(output_folder, f\"{item['id']}.txt\")\n",
        "\n",
        "            if os.path.exists(file_path):\n",
        "                return\n",
        "\n",
        "            it = await getTranslation(item)\n",
        "            if it is None:\n",
        "                raise Exception(item['id'])\n",
        "\n",
        "            with open(file_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(it, f, ensure_ascii=False)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing entry: {e}\")"
      ],
      "metadata": {
        "id": "vHXrYc0DVgxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/output"
      ],
      "metadata": {
        "id": "czTeEW4HaWhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(input_datas[0]['text']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jLw0EnAoMhn",
        "outputId": "18401286-99ea-4dbd-b25c-6d656e3546d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def main(datas):\n",
        "\n",
        "    output_folder = \"/content/output\"\n",
        "\n",
        "    process_data = []\n",
        "\n",
        "    for data in datas:\n",
        "        id = data['id']\n",
        "        process_data.append({\n",
        "            \"id\": id,\n",
        "            \"messages\": data2messages(data),\n",
        "            \"output_folder\": output_folder\n",
        "        })\n",
        "\n",
        "    tasks = []\n",
        "\n",
        "    semaphore = asyncio.Semaphore(concurrency_limit)\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # # print(f\"Already processed {len(exist_list)} items...\")\n",
        "\n",
        "    # id = set()\n",
        "\n",
        "    for item in process_data:\n",
        "        file_path = os.path.join(output_folder, f\"{item['id']}.txt\")\n",
        "\n",
        "        if os.path.exists(file_path):\n",
        "            continue\n",
        "\n",
        "        tasks.append(asyncio.create_task(process(item, semaphore)))\n",
        "\n",
        "    async for task in tqdm(tasks, total=len(tasks), desc=\"Processing items\"):\n",
        "        await task\n",
        "        time.sleep(delay)\n",
        "\n"
      ],
      "metadata": {
        "id": "lApSic3YTC8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/output"
      ],
      "metadata": {
        "id": "jBVnBE-br_WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/CardBuild/dialogue_extract/0122english_*"
      ],
      "metadata": {
        "id": "7g0GkOlib_Hs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aa251fa-1fd2-48eb-8c41-401cca848651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CardBuild/dialogue_extract/0122english_0_to_10.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(input_datas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgvbVsn6ApRw",
        "outputId": "761ff137-67c9-418e-91bf-89efae48a784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_datas[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DxM1zTTZZYB",
        "outputId": "ca8ae17c-f8a7-4ef5-8548-0c8e5b695241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '0_second', 'text': 'Cory Doctorow wrote Little Brother in a white-hot fury over the course of eight weeks. The book was trying to get out of his head, leading to sleep deprivation and missed meals. The author\\'s father was one of the few \\'counterculture\\' people who thought computers were a good thing in the 1960s. The author\\'s fascination with activist causes grew as he saw how communications tools were being used to bring information and revolution to authoritarian states. However, 17 years later, computers are being used to spy, control, and restrict freedoms. The author expresses concern about the dangers of technology and the loss of privacy and freedom. The book is meant to be part of the conversation about what an information society means and encourages taking action for freedom and privacy.\\nI wrote Little Brother in a white-hot fury between May 7, 2007 and July 2, 2007: exactly eight weeks from the day I thought it up to the day I finished it (Alice, to whom this book is dedicated, had to put up with me clacking out the final chapter at 5AM in our hotel in Rome, where we were celebrating our anniversary). I\\'d always dreamed of having a book just materialize, fully formed, and come pouring out of my fingertips, no sweat and fuss -- but it wasn\\'t nearly as much fun as I\\'d thought it would be. There were days when I wrote 10,000 words, hunching over my keyboard in airports, on subways, in taxis -- anywhere I could type. The book was trying to get out of my head, no matter what, and I missed so much sleep and so many meals that friends started to ask if I was unwell.\\nWhen my dad was a young university student in the 1960s, he was one of the few \"counterculture\" people who thought computers were a good thing. For most young people, computers represented the de-humanization of society. University students were reduced to numbers on a punchcard, each bearing the legend \"DO NOT BEND, SPINDLE, FOLD OR MUTILATE,\" prompting some of the students to wear pins that said, \"I AM A STUDENT: DO NOT BEND, SPINDLE, FOLD OR MUTILATE ME.\" Computers were seen as a means to increase the ability of the authorities to regiment people and bend them to their will.\\nWhen I was a 17, the world seemed like it was just going to get more free. The Berlin Wall was about to come down. Computers -- which had been geeky and weird a few years before -- were everywhere, and the modem I\\'d used to connect to local bulletin board systems was now connecting me to the entire world through the Internet and commercial online services like GEnie. My lifelong fascination with activist causes went into overdrive as I saw how the main difficulty in activism -- organizing -- was getting easier by leaps and bounds (I still remember the first time I switched from mailing out a newsletter with hand-written addresses to using a database with mail-merge). In the Soviet Union, communications tools were being used to bring information -- and revolution -- to the farthest-flung corners of the largest authoritarian state the Earth had ever seen.\\nBut 17 years later, things are very different. The computers I love are being co-opted, used to spy on us, control us, snitch on us. The National Security Agency has illegally wiretapped the entire USA and gotten away with it. Car rental companies and mass transit and traffic authorities are watching where we go, sending us automated tickets, finking us out to busybodies, cops and bad guys who gain illicit access to their databases. The Transport Security Administration maintains a \"no-fly\" list of people who\\'d never been convicted of any crime, but who are nevertheless considered too dangerous to fly. The list\\'s contents are secret. The rule that makes it enforceable is secret. The criteria for being added to the list are secret. It has four-year-olds on it. And US senators. And decorated veterans -- actual war heroes.\\nThe 17 year olds I know understand to a nicety just how dangerous a computer can be. The authoritarian nightmare of the 1960s has come home for them. The seductive little boxes on their desks and in their pockets watch their every move, corral them in, systematically depriving them of those new freedoms I had enjoyed and made such good use of in my young adulthood.\\nWhat\\'s more, kids were clearly being used as guinea-pigs for a new kind of technological state that all of us were on our way to, a world where taking a picture was either piracy (in a movie theater or museum or even a Starbucks), or terrorism (in a public place), but where we could be photographed, tracked and logged hundreds of times a day by every tin-pot dictator, cop, bureaucrat and shop-keeper. A world where any measure, including torture, could be justified just by waving your hands and shouting \"Terrorism! 9/11! Terrorism!\" until all dissent fell silent.\\nWe don\\'t have to go down that road.\\nIf you love freedom, if you think the human condition is dignified by privacy, by the right to be left alone, by the right to explore your weird ideas provided you don\\'t hurt others, then you have common cause with the kids whose web-browsers and cell phones are being used to lock them up and follow them around.\\nIf you believe that the answer to bad speech is more speech -- not censorship -- then you have a dog in the fight.\\nIf you believe in a society of laws, a land where our rulers have to tell us the rules, and have to follow them too, then you\\'re part of the same struggle that kids fight when they argue for the right to live under the same Bill of Rights that adults have.\\nThis book is meant to be part of the conversation about what an information society means: does it mean total control, or unheard-of liberty? It\\'s not just a noun, it\\'s a verb, it\\'s something you do. DO SOMETHING\\n', 'n_quote': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datas = input_datas"
      ],
      "metadata": {
        "id": "BnL8OOyXZe7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_id = 0\n",
        "end_id = 10\n",
        "\n",
        "current_tasks = input_datas[start_id:end_id]\n",
        "\n",
        "await main(current_tasks)\n",
        "\n",
        "temp_output_folder = \"/content/output\"\n",
        "\n",
        "for id in range(start_id, end_id):\n",
        "    id_str = input_datas[id][\"id\"]\n",
        "    file_path = os.path.join(temp_output_folder, f\"{id_str}.txt\")\n",
        "    if os.path.exists(file_path):\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            try:\n",
        "                data = json.load(f)\n",
        "                response = data[\"response\"]\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        if response is not None:\n",
        "            datas[id][\"response\"] = response\n",
        "    # break\n",
        "\n",
        "final_save_name = \"/content/drive/MyDrive/CardBuild/exp0122/first/0123_eng_2nd_\" + str(start_id) + \"_to_\" + str(end_id) + \".txt\"\n",
        "\n",
        "with open(final_save_name, 'w', encoding='utf-8') as f:\n",
        "    for id in range(start_id, end_id):\n",
        "        json.dump(datas[id], f, ensure_ascii=False)\n",
        "        f.write('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uDvRq6TUCQP",
        "outputId": "0ef8931f-a72f-46d8-df30-fd43fd2ce316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datas = input_datas"
      ],
      "metadata": {
        "id": "VwbjpArQrlGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "super_start = 10\n",
        "super_end = len(datas)\n",
        "\n",
        "n_bag = 40\n",
        "\n",
        "# 计算每个子区间的长度\n",
        "interval_length = (super_end - super_start) // n_bag\n",
        "\n",
        "# 生成元组列表\n",
        "se_tuples_list = [(super_start + i * interval_length, super_start + (i + 1) * interval_length) for i in range(n_bag - 1)]\n",
        "\n",
        "# 添加最后一个元组，确保最后一个end等于super_end\n",
        "se_tuples_list.append((se_tuples_list[-1][1], super_end))\n",
        "\n",
        "# 打印生成的元组列表\n",
        "print(se_tuples_list[0:2])\n",
        "print(se_tuples_list[-2:])\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "random.shuffle(se_tuples_list)\n",
        "\n",
        "print(se_tuples_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bVbVGwudXu4",
        "outputId": "40347d04-63da-4a7b-83f0-f6f9ff67ad94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(10, 404), (404, 798)]\n",
            "[(14982, 15376), (15376, 15804)]\n",
            "(6314, 6708)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "for start_id, end_id in se_tuples_list:\n",
        "    current_tasks = datas[start_id:end_id]\n",
        "\n",
        "    await main(current_tasks)\n",
        "    await main(current_tasks)\n",
        "\n",
        "    temp_output_folder = \"/content/output\"\n",
        "\n",
        "    for id in range(start_id, end_id):\n",
        "        id_str = input_datas[id][\"id\"]\n",
        "        file_path = os.path.join(temp_output_folder, f\"{id_str}.txt\")\n",
        "        if os.path.exists(file_path):\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                try:\n",
        "                    data = json.load(f)\n",
        "                    response = data[\"response\"]\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            if response is not None:\n",
        "                datas[id][\"response\"] = response\n",
        "        # break\n",
        "\n",
        "    final_save_name = \"/content/drive/MyDrive/CardBuild/exp0122/first/0123_eng_2nd_\" + str(start_id) + \"_to_\" + str(end_id) + \".txt\"\n",
        "\n",
        "    with open(final_save_name, 'w', encoding='utf-8') as f:\n",
        "        for id in range(start_id, end_id):\n",
        "            json.dump(datas[id], f, ensure_ascii=False)\n",
        "            f.write('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2QVvvRjdkn4",
        "outputId": "d8eda4cc-72a1-446d-c478-9c010fe7c062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing items: 100%|██████████| 394/394 [10:22<00:00,  1.58s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:13<00:00,  1.40s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:30<00:00,  1.45s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:46<00:00,  1.49s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:06<00:00,  1.39s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [08:47<00:00,  1.34s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:36<00:00,  1.46s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:18<00:00,  1.42s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:04<00:00,  1.38s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:31<00:00,  1.45s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:31<00:00,  1.45s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [10:06<00:00,  1.54s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [08:44<00:00,  1.33s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [10:15<00:00,  1.56s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [10:46<00:00,  1.64s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:40<00:00,  1.47s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:45<00:00,  1.49s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [10:01<00:00,  1.53s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [10:27<00:00,  1.59s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [10:22<00:00,  1.58s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [13:25<00:00,  2.04s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [11:31<00:00,  1.76s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:39<00:00,  1.47s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:38<00:00,  1.47s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [11:17<00:00,  1.72s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [09:24<00:00,  1.43s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [18:14<00:00,  2.78s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [18:48<00:00,  2.86s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [10:19<00:00,  1.57s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [18:19<00:00,  2.79s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 428/428 [11:05<00:00,  1.55s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [10:09<00:00,  1.55s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [11:08<00:00,  1.70s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [10:39<00:00,  1.62s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [10:13<00:00,  1.56s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [19:03<00:00,  2.90s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [11:21<00:00,  1.73s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [10:38<00:00,  1.62s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [10:04<00:00,  1.53s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n",
            "Processing items: 100%|██████████| 394/394 [10:07<00:00,  1.54s/it]\n",
            "Processing items: 0it [00:00, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H7fnHrAritFt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}