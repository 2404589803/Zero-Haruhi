{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Collecting hf-transfer\r\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/a1/a9/9ba1c6d974555246fbdfc7268005152bce6d9283333560e7916bd3642a7a/hf_transfer-0.1.5.tar.gz (21 kB)\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Preparing metadata (pyproject.toml) ... \u001B[?25lerror\r\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[31m×\u001B[0m \u001B[32mPreparing metadata \u001B[0m\u001B[1;32m(\u001B[0m\u001B[32mpyproject.toml\u001B[0m\u001B[1;32m)\u001B[0m did not run successfully.\r\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\r\n",
      "  \u001B[31m╰─>\u001B[0m \u001B[31m[6 lines of output]\u001B[0m\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m Cargo, the Rust package manager, is not installed or is not on PATH.\r\n",
      "  \u001B[31m   \u001B[0m This package requires Rust and Cargo to compile extensions. Install it through\r\n",
      "  \u001B[31m   \u001B[0m the system's package manager or via https://rustup.rs/\r\n",
      "  \u001B[31m   \u001B[0m \r\n",
      "  \u001B[31m   \u001B[0m Checking for Rust toolchain....\r\n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\r\n",
      "  \r\n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001B[1;31merror\u001B[0m: \u001B[1mmetadata-generation-failed\u001B[0m\r\n",
      "\r\n",
      "\u001B[31m×\u001B[0m Encountered error while generating package metadata.\r\n",
      "\u001B[31m╰─>\u001B[0m See above for output.\r\n",
      "\r\n",
      "\u001B[1;35mnote\u001B[0m: This is an issue with the package mentioned above, not pip.\r\n",
      "\u001B[1;36mhint\u001B[0m: See above for details.\r\n",
      "\u001B[?25h"
     ]
    }
   ],
   "source": [
    "!pip install hf-transfer huggingface_hub"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-15T08:28:31.655508Z",
     "start_time": "2024-02-15T08:28:28.625798Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6911bv9PzmGK"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers torch sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oGX_qerzmGN"
   },
   "source": [
    "载入ChatHaruhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BP__SdrMzmGN",
    "outputId": "c25607be-604a-4885-dce6-3a945e0f371b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'Zero-Haruhi'...\n",
      "remote: Enumerating objects: 440, done.\u001B[K\n",
      "remote: Counting objects: 100% (38/38), done.\u001B[K\n",
      "remote: Compressing objects: 100% (27/27), done.\u001B[K\n",
      "remote: Total 440 (delta 22), reused 18 (delta 11), pack-reused 402\u001B[K\n",
      "Receiving objects: 100% (440/440), 2.97 MiB | 16.08 MiB/s, done.\n",
      "Resolving deltas: 100% (294/294), done.\n",
      "/content/Zero-Haruhi\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "!rm -rf /content/Zero-Haruhi\n",
    "!git clone https://github.com/LC1332/Zero-Haruhi\n",
    "%cd /content/Zero-Haruhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTR1PM4hzmGO",
    "outputId": "f5d41f97-e416-40e8-f577-97117b71bd30",
    "ExecuteTime": {
     "end_time": "2024-02-15T08:32:06.337414Z",
     "start_time": "2024-02-15T08:31:54.617644Z"
    }
   },
   "outputs": [],
   "source": [
    "from ChatHaruhi import ChatHaruhi\n",
    "from ChatHaruhi.responese_GLM_local import get_response\n",
    "\n",
    "chatbot = ChatHaruhi(role_name=\"凉宫春日\", llm=get_response,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_rags: [{'n': 5, 'max_token': 1000, 'query': '老师: 同学请自我介绍一下', 'lid': 8}] rest_limit = 1505\n",
      "Using device:  mps\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7fa19d6c8ed4e28923c5a3e286e74cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model-00005-of-00007.safetensors:   0%|          | 0.00/1.97G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b73f395dd5443bbb5931e3dbcb71408"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = chatbot.chat(user=\"\", text=\"老师: 同学请自我介绍一下\")\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-15T08:32:13.299234Z"
    }
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KiBTGsONzmGO",
    "outputId": "3719260a-1294-4fe9-80b1-d0648878ac1b"
   },
   "outputs": [],
   "source": [
    "response = chatbot.chat(user=\"\", text=\"听说你初中时候谈了很多男朋友\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
