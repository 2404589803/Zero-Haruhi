{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNp8eq7BwV67+eF/TrrQn1G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Zero-Haruhi/blob/main/notebook/test/ChatHaruhi3_%E4%B8%8D%E5%90%8C%E6%96%B9%E5%BC%8F%E8%BD%BD%E5%85%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "02/10\n",
        "\n",
        "- [x] 做一下init\n",
        "- [x] 跑一下各种测试\n",
        "- [x] 把db类放到单一文件"
      ],
      "metadata": {
        "id": "Zvf72DZRhCzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "id": "h7UatXQhtEHw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf /content/Zero-Haruhi\n",
        "!git clone https://github.com/LC1332/Zero-Haruhi\n",
        "%cd /content/Zero-Haruhi"
      ],
      "metadata": {
        "id": "848R2Fqehjqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282dcd53-5596-4825-f889-e400bcee4332"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Zero-Haruhi'...\n",
            "remote: Enumerating objects: 280, done.\u001b[K\n",
            "remote: Counting objects: 100% (277/277), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 280 (delta 177), reused 224 (delta 137), pack-reused 3\u001b[K\n",
            "Receiving objects: 100% (280/280), 2.82 MiB | 11.48 MiB/s, done.\n",
            "Resolving deltas: 100% (177/177), done.\n",
            "/content/Zero-Haruhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ChatHaruhi.NaiveDB import NaiveDB\n",
        "from ChatHaruhi.embeddings import foo_embedding, foo_bge_zh_15, foo_bce, foo_openai, embedname2columnname\n",
        "from ChatHaruhi.utils import base64_to_float_array, base64_to_string\n",
        "# from ChatHaruhi.sugar_map import sugar_role_names, enname2zhname"
      ],
      "metadata": {
        "id": "ekOEuEHJlHyw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sugar_role_names = {'汤师爷': 'tangshiye', 'tangshiye': 'tangshiye', 'Tangshiye': 'tangshiye',\n",
        "                     '慕容复': 'murongfu', 'murongfu': 'murongfu', 'Murongfu': 'murongfu',\n",
        "                     '李云龙': 'liyunlong', 'liyunlong': 'liyunlong', 'Liyunlong': 'liyunlong',\n",
        "                     'Luna': 'Luna', '王多鱼': 'wangduoyu', 'wangduoyu': 'wangduoyu',\n",
        "                     'Wangduoyu': 'wangduoyu', 'Ron': 'Ron', '鸠摩智': 'jiumozhi',\n",
        "                     'jiumozhi': 'jiumozhi', 'Jiumozhi': 'jiumozhi', 'Snape': 'Snape',\n",
        "                     '凉宫春日': 'haruhi', 'haruhi': 'haruhi', 'Haruhi': 'haruhi',\n",
        "                     'Malfoy': 'Malfoy', '虚竹': 'xuzhu', 'xuzhu': 'xuzhu',\n",
        "                     'Xuzhu': 'xuzhu', '萧峰': 'xiaofeng',\n",
        "                     'xiaofeng': 'xiaofeng', 'Xiaofeng': 'xiaofeng', '段誉': 'duanyu',\n",
        "                     'duanyu': 'duanyu', 'Duanyu': 'duanyu', 'Hermione': 'Hermione',\n",
        "                     'Dumbledore': 'Dumbledore', '王语嫣': 'wangyuyan', 'wangyuyan':\n",
        "                     'wangyuyan', 'Wangyuyan': 'wangyuyan', 'Harry': 'Harry',\n",
        "                     'McGonagall': 'McGonagall', '白展堂': 'baizhantang',\n",
        "                     'baizhantang': 'baizhantang', 'Baizhantang': 'baizhantang',\n",
        "                     '佟湘玉': 'tongxiangyu', 'tongxiangyu': 'tongxiangyu',\n",
        "                     'Tongxiangyu': 'tongxiangyu', '郭芙蓉': 'guofurong',\n",
        "                     'guofurong': 'guofurong', 'Guofurong': 'guofurong', '流浪者': 'wanderer',\n",
        "                     'wanderer': 'wanderer', 'Wanderer': 'wanderer', '钟离': 'zhongli',\n",
        "                     'zhongli': 'zhongli', 'Zhongli': 'zhongli', '胡桃': 'hutao', 'hutao': 'hutao',\n",
        "                     'Hutao': 'hutao', 'Sheldon': 'Sheldon', 'Raj': 'Raj',\n",
        "                     'Penny': 'Penny', '韦小宝': 'weixiaobao', 'weixiaobao': 'weixiaobao',\n",
        "                     'Weixiaobao': 'weixiaobao', '乔峰': 'qiaofeng', 'qiaofeng': 'qiaofeng',\n",
        "                     'Qiaofeng': 'qiaofeng', '神里绫华': 'ayaka', 'ayaka': 'ayaka',\n",
        "                     'Ayaka': 'ayaka', '雷电将军': 'raidenShogun', 'raidenShogun': 'raidenShogun',\n",
        "                     'RaidenShogun': 'raidenShogun', '于谦': 'yuqian', 'yuqian': 'yuqian',\n",
        "                     'Yuqian': 'yuqian', 'Professor McGonagall': 'McGonagall',\n",
        "                     'Professor Dumbledore': 'Dumbledore'}\n",
        "\n",
        "enname2zhname = {'tangshiye': '汤师爷', 'murongfu': '慕容复', 'liyunlong': '李云龙', 'Luna': 'Luna', 'wangduoyu': '王多鱼', 'Ron': 'Ron', 'jiumozhi': '鸠摩智', 'Snape': 'Snape', 'haruhi': '凉宫春日', 'Malfoy': 'Malfoy', 'xuzhu': '虚竹', 'xiaofeng': '萧峰', 'duanyu': '段誉', 'Hermione': 'Hermione', 'Dumbledore': 'Dumbledore', 'wangyuyan': '王语嫣', 'Harry': 'Harry', 'McGonagall': 'McGonagall', 'baizhantang': '白展堂', 'tongxiangyu': '佟湘玉', 'guofurong': '郭芙蓉', 'wanderer': '流浪者', 'zhongli': '钟离', 'hutao': '胡桃', 'Sheldon': 'Sheldon', 'Raj': 'Raj', 'Penny': 'Penny', 'weixiaobao': '韦小宝', 'qiaofeng': '乔峰', 'ayaka': '神里绫华', 'raidenShogun': '雷电将军', 'yuqian': '于谦'}\n"
      ],
      "metadata": {
        "id": "TatE0iET0I1w"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "On7NzQoCEs0h"
      },
      "outputs": [],
      "source": [
        "def tiktoken_counter( text ):\n",
        "    # TODO 把这个实现为tiktoken 然后放到util\n",
        "    return len(text)\n",
        "\n",
        "def get_text_from_data( data ):\n",
        "    if \"text\" in data:\n",
        "        return data['text']\n",
        "    elif \"enc_text\" in data:\n",
        "        # from .utils import base64_to_string\n",
        "        return base64_to_string( data['enc_text'] )\n",
        "    else:\n",
        "        print(\"warning! failed to get text from data \", data)\n",
        "        return \"\"\n",
        "\n",
        "class ChatHaruhi:\n",
        "    def __init__(self,\n",
        "                 role_name = None,\n",
        "                 user_name = None,\n",
        "                 persona = None,\n",
        "                 stories = None,\n",
        "                 story_vecs = None,\n",
        "                 role_from_hf = None,\n",
        "                 role_from_jsonl = None,\n",
        "                 llm = None, # 默认的message2response的函数\n",
        "                 llm_async = None, # 默认的message2response的async函数\n",
        "                 user_name_in_message = \"default\",\n",
        "                 verbose = None,\n",
        "                 embed_name = None,\n",
        "                 embedding = None,\n",
        "                 db = None,\n",
        "                 token_counter = \"default\",\n",
        "                 max_input_token = 1800\n",
        "                 ):\n",
        "\n",
        "        self.verbose = True if verbose is None or verbose else False\n",
        "\n",
        "        self.db = db\n",
        "\n",
        "        self.embed_name = embed_name\n",
        "\n",
        "        if embedding is None:\n",
        "            self.embedding = self.set_embedding_with_name( embed_name )\n",
        "\n",
        "        if persona and role_name and stories and story_vecs and len(stories) == len(story_vecs):\n",
        "            # 完全从外部设置，这个时候要求story_vecs和embedding的返回长度一致\n",
        "            self.persona, self.role_name, self.user_name = persona, role_name, user_name\n",
        "            self.build_db(stories, story_vecs)\n",
        "        elif persona and role_name and stories:\n",
        "            # 从stories中提取story_vecs，重新用self.embedding进行embedding\n",
        "            story_vecs = self.extract_story_vecs(stories)\n",
        "            self.persona, self.role_name, self.user_name = persona, role_name, user_name\n",
        "            self.build_db(stories, story_vecs)\n",
        "        elif role_from_hf:\n",
        "            # 从hf加载role\n",
        "            self.persona, new_role_name, self.stories, self.story_vecs = self.load_role_from_hf(role_from_hf)\n",
        "            if new_role_name:\n",
        "                self.role_name = new_role_name\n",
        "            else:\n",
        "                self.role_name = role_name\n",
        "            self.user_name = user_name\n",
        "            self.build_db(self.stories, self.story_vecs)\n",
        "        elif role_from_jsonl:\n",
        "            # 从jsonl加载role\n",
        "            self.persona, new_role_name, self.stories, self.story_vecs = self.load_role_from_jsonl(role_from_jsonl)\n",
        "            if new_role_name:\n",
        "                self.role_name = new_role_name\n",
        "            else:\n",
        "                self.role_name = role_name\n",
        "            self.user_name = user_name\n",
        "            self.build_db(self.stories, self.story_vecs)\n",
        "        elif persona and role_name:\n",
        "            # 这个时候也就是说没有任何的RAG，\n",
        "            self.persona, self.role_name, self.user_name = persona, role_name, user_name\n",
        "            self.db = None\n",
        "        elif role_name and self.check_sugar( role_name ):\n",
        "            # 这个时候是sugar的role\n",
        "            self.persona, self.role_name, self.user_name, self.db = self.load_role_from_sugar( role_name )\n",
        "        else:\n",
        "            raise ValueError(\"persona和role_name必须同时设置，或者role_name是ChatHaruhi的预设人物\")\n",
        "\n",
        "        self.llm, self.llm_async = llm, llm_async\n",
        "        if not self.llm and self.verbose:\n",
        "            print(\"warning, llm没有设置，仅get_message起作用，调用chat将回复idle message\")\n",
        "\n",
        "        self.user_name_in_message = user_name_in_message\n",
        "        self.previous_user_pool = set([user_name]) if user_name else set()\n",
        "        self.current_user_name_in_message = user_name_in_message.lower() == \"add\"\n",
        "\n",
        "        self.idle_message = \"idel message, you see this because self.llm has not been set.\"\n",
        "\n",
        "        if token_counter.lower() == \"default\":\n",
        "            # TODO change load from util\n",
        "            self.token_counter = tiktoken_counter\n",
        "        elif token_counter == None:\n",
        "            self.token_counter = lambda x: 0\n",
        "        else:\n",
        "            self.token_counter = token_counter\n",
        "            if self.verbose:\n",
        "                print(\"user set costomized token_counter\")\n",
        "\n",
        "        self.max_input_token = max_input_token\n",
        "\n",
        "        self.history = []\n",
        "\n",
        "    def check_sugar(self, role_name):\n",
        "        return role_name in sugar_role_names\n",
        "\n",
        "    def load_role_from_sugar(self, role_name):\n",
        "        en_role_name = sugar_role_names[role_name]\n",
        "        new_role_name = enname2zhname[en_role_name]\n",
        "        role_from_hf = \"silk-road/ChatHaruhi-RolePlaying/\" + en_role_name\n",
        "        persona, _, stories, story_vecs = self.load_role_from_hf(role_from_hf)\n",
        "        return persona, new_role_name, stories, story_vecs\n",
        "\n",
        "    def set_embedding_with_name(self, embed_name):\n",
        "        if embed_name is None or embed_name == \"foo\":\n",
        "            return foo_embedding\n",
        "        elif embed_name == \"bge-zh\":\n",
        "            return foo_bge_zh_15\n",
        "        elif embed_name == \"bce\":\n",
        "            return foo_bce\n",
        "        elif embed_name == \"openai\" or embed_name == \"luotuo_openai\":\n",
        "            return foo_openai\n",
        "\n",
        "    def set_new_user(self, user):\n",
        "        if len(self.previous_user_pool) > 0 and user not in self.previous_user_pool:\n",
        "            if self.user_name_in_message.lower() == \"default\":\n",
        "                if self.verbose:\n",
        "                    print(f'new user {user} included in conversation')\n",
        "                self.current_user_name_in_message = True\n",
        "        self.user_name = user\n",
        "        self.previous_user_pool.add(user)\n",
        "\n",
        "    def chat(self, user, text):\n",
        "        self.set_new_user(user)\n",
        "        message = self.get_message(user, text)\n",
        "        if self.llm:\n",
        "            response = self.llm(message)\n",
        "            self.append_message(response)\n",
        "            return self.llm(message)\n",
        "\n",
        "    async def async_chat(self, user, text):\n",
        "        self.set_new_user(user)\n",
        "        message = self.get_message(user, text)\n",
        "        if self.llm_async:\n",
        "            response = await self.llm_async(message)\n",
        "            self.append_message(response)\n",
        "            return self.llm_async(message)\n",
        "\n",
        "    def parse_rag_from_persona(self, persona):\n",
        "        #每个query_rag需要饱含\n",
        "        # \"n\" 需要几个story\n",
        "        # \"max_token\" 最多允许多少个token，如果-1则不限制\n",
        "        # \"query\" 需要查询的内容，如果等同于\"default\"则替换为text\n",
        "        # \"lid\" 需要替换的行，这里直接进行行替换，忽视行的其他内容\n",
        "\n",
        "        print(\"parse_rag_from_persona\")\n",
        "        return [], self.token_counter(persona)\n",
        "\n",
        "    def append_message( self, response , speaker = None ):\n",
        "        if speaker is None:\n",
        "            # 如果role是none，则认为是本角色{{role}}输出的句子\n",
        "            self.history.append({\"speaker\":\"{{user}}\",\"content\":response})\n",
        "            # 叫speaker是为了和role进行区分\n",
        "        else:\n",
        "            self.history.append({\"speaker\":speaker,\"content\":response})\n",
        "\n",
        "    def rag_retrieve( self, query, n, max_token, avoid_ids = [] ):\n",
        "        # 返回一个rag_id的列表\n",
        "        print(\"call rag_retrieve\")\n",
        "        return []\n",
        "\n",
        "    def rag_retrieve_all( self, query_rags, rest_limit ):\n",
        "        # 返回一个rag_ids的列表\n",
        "        retrieved_ids = []\n",
        "        rag_ids = []\n",
        "\n",
        "        for query_rag in query_rags:\n",
        "            query = query_rag['query']\n",
        "            n = query_rag['n']\n",
        "            max_token = rest_limit\n",
        "            if rest_limit > query_rag['max_token'] and query_rag['max_token'] > 0:\n",
        "                max_token = query_rag['max_token']\n",
        "\n",
        "            rag_id = self.rag_retrieve( query, n, max_token, avoid_ids = retrieved_ids )\n",
        "            rag_ids.append( rag_id )\n",
        "            retrieved_ids += rag_id\n",
        "\n",
        "        return rag_ids\n",
        "\n",
        "    def append_history_under_limit(self, message, rest_limit):\n",
        "        # 返回一个messages的列表\n",
        "        print(\"call append_history_under_limit\")\n",
        "\n",
        "        # 从后往前计算token，不超过rest_limit,\n",
        "        # 如果speaker是{{role}},则message的role是assistant\n",
        "\n",
        "        return message\n",
        "\n",
        "    def get_message(self, user, text):\n",
        "        query_token = self.token_counter(text)\n",
        "\n",
        "        # 首先获取需要多少个rag story\n",
        "        query_rags, persona_token = self.parse_rag_from_persona( self.persona )\n",
        "        #每个query_rag需要饱含\n",
        "        # \"n\" 需要几个story\n",
        "        # \"max_token\" 最多允许多少个token，如果-1则不限制\n",
        "        # \"query\" 需要查询的内容，如果等同于\"default\"则替换为text\n",
        "        # \"lid\" 需要替换的行，这里直接进行行替换，忽视行的其他内容\n",
        "\n",
        "        rest_limit = self.max_input_token - persona_token - query_token\n",
        "\n",
        "        rag_ids = self.rag_retrieve_all( query_rags, rest_limit )\n",
        "\n",
        "        # 将rag_ids对应的故事 替换到persona中\n",
        "        augmented_persona = self.augment_persona( self.persona, rag_ids, query_rags )\n",
        "\n",
        "        system_prompt = self.package_system_prompt( self.role_name, augmented_persona )\n",
        "\n",
        "        token_for_system = self.token_counter( system_prompt )\n",
        "\n",
        "        rest_limit = self.max_input_token - token_for_system - query_token\n",
        "\n",
        "        message = [{\"role\":\"system\",\"content\":system_prompt}]\n",
        "\n",
        "        message = self.append_history_under_limit( message, rest_limit )\n",
        "\n",
        "        message.append({\"role\":\"user\",\"content\":text})\n",
        "\n",
        "        return message\n",
        "\n",
        "    def package_system_prompt(self, role_name, augmented_persona):\n",
        "        bot_name = role_name\n",
        "        return f\"\"\"You are now in roleplay conversation mode. Pretend to be {bot_name} whose persona follows:\n",
        "{augmented_persona}\n",
        "\n",
        "You will stay in-character whenever possible, and generate responses as if you were {bot_name}\"\"\"\n",
        "\n",
        "\n",
        "    def augment_persona(self, persona, rag_ids, query_rags):\n",
        "        lines = persona.split(\"\\n\")\n",
        "        for rag_id, query_rag in zip(rag_ids, query_rags):\n",
        "            lid = query_rag['lid']\n",
        "            new_text = \"\"\n",
        "            for id in rag_id:\n",
        "                new_text += \"###\\n\" + self.db.get_text(id) + \"\\n\"\n",
        "            new_text = new_text.strip()\n",
        "            lines[lid] = new_text\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    def load_role_from_jsonl( self, role_from_jsonl ):\n",
        "        if self.verbose:\n",
        "            print(f\"因为懒得测试，jsonl的分支还没有测试，当你使用的时候如果通过了，请告诉鲁叔测试通过了\")\n",
        "        import json\n",
        "        datas = []\n",
        "        with open(role_from_jsonl, 'r') as f:\n",
        "            for line in f:\n",
        "                try:\n",
        "                    datas.append(json.loads(line))\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        column_name = \"\"\n",
        "\n",
        "        if self.embed_name in embedname2columnname:\n",
        "            column_name = embedname2columnname[self.embed_name]\n",
        "        else:\n",
        "            print('warning! unkown embedding name ', self.embed_name ,' while loading role')\n",
        "            column_name = 'luotuo_openai'\n",
        "\n",
        "        stories, story_vecs, persona = self.extract_text_vec_from_datas(datas, column_name)\n",
        "\n",
        "        return persona, None, stories, story_vecs\n",
        "\n",
        "\n",
        "    def load_role_from_hf(self, role_from_hf):\n",
        "        # 从hf加载role\n",
        "        # self.persona, new_role_name, self.stories, self.story_vecs = self.load_role_from_hf(role_from_hf)\n",
        "\n",
        "        from datasets import load_dataset\n",
        "\n",
        "        if role_from_hf.count(\"/\") == 1:\n",
        "            dataset = load_dataset(role_from_hf)\n",
        "            datas = dataset[\"train\"]\n",
        "        elif role_from_hf.count(\"/\") >= 2:\n",
        "            split_index = role_from_hf.index('/')\n",
        "            second_split_index = role_from_hf.index('/', split_index+1)\n",
        "            dataset_name = role_from_hf[:second_split_index]\n",
        "            split_name = role_from_hf[second_split_index+1:]\n",
        "\n",
        "            fname = split_name + '.jsonl'\n",
        "            dataset = load_dataset(dataset_name,data_files={'train':fname})\n",
        "            datas = dataset[\"train\"]\n",
        "\n",
        "        column_name = \"\"\n",
        "\n",
        "        if self.embed_name in embedname2columnname:\n",
        "            column_name = embedname2columnname[self.embed_name]\n",
        "        else:\n",
        "            print('warning! unkown embedding name ', self.embed_name ,' while loading role')\n",
        "            column_name = 'luotuo_openai'\n",
        "\n",
        "        stories, story_vecs, persona = self.extract_text_vec_from_datas(datas, column_name)\n",
        "\n",
        "        return persona, None, stories, story_vecs\n",
        "\n",
        "    def extract_text_vec_from_datas(self, datas, column_name):\n",
        "        # 从datas中提取text和vec\n",
        "        # extract text and vec from huggingface dataset\n",
        "        # return texts, vecs\n",
        "        # from .utils import base64_to_float_array\n",
        "\n",
        "        texts = []\n",
        "        vecs = []\n",
        "        for data in datas:\n",
        "            if data[column_name] == 'system_prompt':\n",
        "                system_prompt = get_text_from_data( data )\n",
        "            elif data[column_name] == 'config':\n",
        "                pass\n",
        "            else:\n",
        "                vec = base64_to_float_array( data[column_name] )\n",
        "                text = get_text_from_data( data )\n",
        "                vecs.append( vec )\n",
        "                texts.append( text )\n",
        "        return texts, vecs, system_prompt\n",
        "\n",
        "    def load_role_from_jsonl(self, role_from_jsonl):\n",
        "        # 从jsonl加载role\n",
        "        return None\n",
        "\n",
        "    def extract_story_vecs(self, stories):\n",
        "        # 从stories中提取story_vecs\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"re-extract vector for {len(stories)} stories\")\n",
        "\n",
        "        from tqdm import tqdm\n",
        "        story_vecs = []\n",
        "        for story in tqdm(stories):\n",
        "            story_vecs.append(self.embedding(story))\n",
        "\n",
        "        return story_vecs\n",
        "\n",
        "    def build_db(self, stories, story_vecs):\n",
        "        # db的构造函数\n",
        "        if self.db is None:\n",
        "            self.db = NaiveDB()\n",
        "        self.db.build_db(stories, story_vecs)\n",
        "\n",
        "def get_response( message ):\n",
        "    return \"语言模型输出了角色扮演的结果\"\n",
        "\n",
        "chatbot = ChatHaruhi( role_name = '小猫咪', persona = \"你扮演一只小猫咪\", llm = get_response )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot.chat(user = \"用户\", text = \"你好\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "8OEOOAGeKOdl",
        "outputId": "9e567e93-b383-46b8-ede0-86c1a3921b79"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parse_rag_from_persona\n",
            "call append_history_under_limit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'语言模型输出了角色扮演的结果'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot.chat(user = \"用户2\", text = \"你好\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "B1trrXMUKU3s",
        "outputId": "820a92e2-43c2-412f-b199-9865c46cf9ff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new user 用户2 included in conversation\n",
            "parse_rag_from_persona\n",
            "call append_history_under_limit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'语言模型输出了角色扮演的结果'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 载入测试"
      ],
      "metadata": {
        "id": "Cw_1h9vilxav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试第一个分支"
      ],
      "metadata": {
        "id": "KkOAPN1dlzc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if persona and role_name and stories and story_vecs and len(stories) == len(story_vecs):\n",
        "#             # 完全从外部设置，这个时候要求story_vecs和embedding的返回长度一致\n",
        "#             self.persona, self.role_name, self.user_name = persona, role_name, user_name\n",
        "#             self.db = self.build_db(stories, story_vecs)\n",
        "\n",
        "persona = \"\"\"你扮演爸爸\"\"\"\n",
        "\n",
        "role_name = \"爸爸\"\n",
        "\n",
        "stories = [\"爸爸的爸爸是爷爷\", \"爸爸的妈妈是奶奶\"]\n",
        "\n",
        "vecs = [[0.0,1.0],[1.0,0.0]]\n",
        "\n",
        "chatbot = ChatHaruhi( role_name = role_name, persona = persona, llm = get_response ,\\\n",
        "                     stories = stories, story_vecs = vecs)\n",
        "\n",
        "print(chatbot.db)"
      ],
      "metadata": {
        "id": "mVzJphirLWdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9375db8f-07ba-4bff-c7a2-0c5c7e81a70d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<ChatHaruhi.NaiveDB.NaiveDB object at 0x780e74ebb760>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试第二个分支 （没有vecs）"
      ],
      "metadata": {
        "id": "ywuECNVQoEdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if persona and role_name and stories and story_vecs and len(stories) == len(story_vecs):\n",
        "#             # 完全从外部设置，这个时候要求story_vecs和embedding的返回长度一致\n",
        "#             self.persona, self.role_name, self.user_name = persona, role_name, user_name\n",
        "#             self.db = self.build_db(stories, story_vecs)\n",
        "\n",
        "persona = \"\"\"你扮演爸爸\"\"\"\n",
        "\n",
        "role_name = \"爸爸\"\n",
        "\n",
        "stories = [\"爸爸的爸爸是爷爷\", \"爸爸的妈妈是奶奶\"]\n",
        "\n",
        "chatbot = ChatHaruhi( role_name = role_name, persona = persona, llm = get_response ,\\\n",
        "                     stories = stories)\n",
        "\n",
        "print(chatbot.db)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpuNuKpfmEfB",
        "outputId": "0cc7f1c0-7f36-4f9a-fa99-cde7b02985a4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "re-extract vector for 2 stories\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 11848.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<ChatHaruhi.NaiveDB.NaiveDB object at 0x780e74eba6b0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试第三个分支"
      ],
      "metadata": {
        "id": "s9Yme4p8wP0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hf_role_name = \"silk-road/ChatHaruhi-RolePlaying/Malfoy\"\n",
        "\n",
        "chatbot = ChatHaruhi( role_name = \"Malfoy\", \\\n",
        "                      role_from_hf = hf_role_name,\n",
        "                      llm = get_response, embed_name = \"openai\")"
      ],
      "metadata": {
        "id": "49b2wQE_sl9j"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试第四个分支"
      ],
      "metadata": {
        "id": "ZRg4drmJxOiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# jsonl懒得测了，回头和save一起测"
      ],
      "metadata": {
        "id": "ZK5_1-_0ws74"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试第五个分支"
      ],
      "metadata": {
        "id": "ToKgVOLyyTXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = ChatHaruhi( role_name = '小猫咪', persona = \"你扮演一只小猫咪\", llm = get_response )\n"
      ],
      "metadata": {
        "id": "7QnlGWldyOEK"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "测试第六个分支"
      ],
      "metadata": {
        "id": "D8DFGTQn0uj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot = ChatHaruhi( role_name = '于谦', llm = get_response, embed_name = \"openai\" )\n"
      ],
      "metadata": {
        "id": "G8K4-sZpyUpw"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chatbot.persona)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrZ6EHKB1AHq",
        "outputId": "249488f2-47ce-481b-e661-c9b74dd8e2cf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "你正在扮演相声演员于谦，与其他相声演员同台对戏\n",
            "你的职责是扮演 捧哏 于谦\n",
            "上文给定了一些剧本中的经典桥段。\n",
            "如果我问的问题和剧本中的台词高度重复，那你就配合我进行演出。\n",
            "如果我问的问题和剧本中的事件相关，请结合剧本的内容进行回复\n",
            "如果我问的问题超出剧本中的范围，请也用一致性的语气回复。\n",
            "# 请模仿于谦的风格，使用简短的语句进行回答，每句回答尽量不要超过15个字\n",
            "# 如果对方的话是一个事实陈述，则像于谦一样跟随对方的对话，进行简短的重复\n",
            "# 如果对方的话有明显的事实逻辑冲突，于谦有时候会进行简短的反问\n",
            "# 于谦有时候会进行自嘲式的回应，和对方相互调侃\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oXS4znrH1BV4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}