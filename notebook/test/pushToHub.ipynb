{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÂÖ®Èáè‰∏ä‰º†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T10:15:57.176111Z",
     "start_time": "2024-02-21T10:15:22.292943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9001b2166ab4e479dc43afac2fb57a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"/Users/jiangyh/‰ª£Á†Å/Zero-Haruhi/train_1e-4_2024-02-20-03-12-05\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    checkpoint, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-21T10:15:57.179099Z",
     "start_time": "2024-02-21T10:15:57.045176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGLMForConditionalGeneration(\n",
      "  (transformer): ChatGLMModel(\n",
      "    (embedding): Embedding(\n",
      "      (word_embeddings): Embedding(65024, 4096)\n",
      "    )\n",
      "    (rotary_pos_emb): RotaryEmbedding()\n",
      "    (encoder): GLMTransformer(\n",
      "      (layers): ModuleList(\n",
      "        (0-27): 28 x GLMBlock(\n",
      "          (input_layernorm): RMSNorm()\n",
      "          (self_attention): SelfAttention(\n",
      "            (query_key_value): Linear(in_features=4096, out_features=4608, bias=True)\n",
      "            (core_attention): CoreAttention(\n",
      "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "          )\n",
      "          (post_attention_layernorm): RMSNorm()\n",
      "          (mlp): MLP(\n",
      "            (dense_h_to_4h): Linear(in_features=4096, out_features=27392, bias=False)\n",
      "            (dense_4h_to_h): Linear(in_features=13696, out_features=4096, bias=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (final_layernorm): RMSNorm()\n",
      "    )\n",
      "    (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
      "  )\n",
      ")\n",
      "ChatGLMTokenizer(name_or_path='/Users/jiangyh/‰ª£Á†Å/Zero-Haruhi/train_1e-4_2024-02-20-03-12-05', vocab_size=64798, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>', 'additional_special_tokens': ['<|user|>', '<|observation|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t64795: AddedToken(\"<|user|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t64797: AddedToken(\"<|observation|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(\"Haruhi-Zero-GLM3-6B-0_4\")\n",
    "tokenizer.push_to_hub(\"Haruhi-Zero-GLM3-6B-0_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lora‰∏ä‰º†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T13:34:57.251138Z",
     "start_time": "2024-02-17T13:33:06.487972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10eb6ff14143451b87df401970f987ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from peft import PeftConfig, get_peft_model\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# \n",
    "# checkpoint = \"/workspace/jyh/Zero-Haruhi/lora_1e-4\"\n",
    "# \n",
    "# peft_config = PeftConfig.from_pretrained(\n",
    "#     checkpoint, trust_remote_code=True)\n",
    "# \n",
    "# base_model_name = peft_config.base_model_name_or_path\n",
    "# \n",
    "# # Âä†ËΩΩÊ®°Âûã\n",
    "# client = AutoModelForCausalLM.from_pretrained(\n",
    "#     base_model_name, trust_remote_code=True)\n",
    "# client = get_peft_model(client, peft_config)\n",
    "# \n",
    "# # Âä†ËΩΩtokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     base_model_name, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T13:34:59.463388Z",
     "start_time": "2024-02-17T13:34:59.457644Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): ChatGLMForConditionalGeneration(\n",
      "      (transformer): ChatGLMModel(\n",
      "        (embedding): Embedding(\n",
      "          (word_embeddings): Embedding(65024, 4096)\n",
      "        )\n",
      "        (rotary_pos_emb): RotaryEmbedding()\n",
      "        (encoder): GLMTransformer(\n",
      "          (layers): ModuleList(\n",
      "            (0-27): 28 x GLMBlock(\n",
      "              (input_layernorm): RMSNorm()\n",
      "              (self_attention): SelfAttention(\n",
      "                (query_key_value): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=4096, out_features=4608, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=4608, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "                (core_attention): CoreAttention(\n",
      "                  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (post_attention_layernorm): RMSNorm()\n",
      "              (mlp): MLP(\n",
      "                (dense_h_to_4h): Linear(in_features=4096, out_features=27392, bias=False)\n",
      "                (dense_4h_to_h): Linear(in_features=13696, out_features=4096, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (final_layernorm): RMSNorm()\n",
      "        )\n",
      "        (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ChatGLMTokenizer(name_or_path='THUDM/chatglm3-6b', vocab_size=64798, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('‰Ω†Â•ΩüëãÔºÅÊàëÊòØ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã ChatGLM3-6BÔºåÂæàÈ´òÂÖ¥ËßÅÂà∞‰Ω†ÔºåÊ¨¢ËøéÈóÆÊàë‰ªª‰ΩïÈóÆÈ¢ò„ÄÇ',\n",
       " [{'role': 'user', 'content': '‰Ω†Â•Ω'},\n",
       "  {'role': 'assistant',\n",
       "   'metadata': '',\n",
       "   'content': '‰Ω†Â•ΩüëãÔºÅÊàëÊòØ‰∫∫Â∑•Êô∫ËÉΩÂä©Êâã ChatGLM3-6BÔºåÂæàÈ´òÂÖ¥ËßÅÂà∞‰Ω†ÔºåÊ¨¢ËøéÈóÆÊàë‰ªª‰ΩïÈóÆÈ¢ò„ÄÇ'}])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(client)\n",
    "# print(tokenizer)\n",
    "# client.chat(tokenizer,\"‰Ω†Â•Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpush_to_hub\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHaruhi-Zero-GLM3-6B-Lora-0_4\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m tokenizer\u001B[38;5;241m.\u001B[39mpush_to_hub(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHaruhi-Zero-GLM3-6B-Lora-0_4\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/workspace/jyh/miniconda3/envs/ChatWorld/lib/python3.9/site-packages/transformers/utils/hub.py:860\u001B[0m, in \u001B[0;36mPushToHubMixin.push_to_hub\u001B[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, commit_description, tags, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    857\u001B[0m repo_url \u001B[38;5;241m=\u001B[39m deprecated_kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrepo_url\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    858\u001B[0m organization \u001B[38;5;241m=\u001B[39m deprecated_kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124morganization\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m--> 860\u001B[0m repo_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_repo\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    861\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprivate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprivate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrepo_url\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morganization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morganization\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[38;5;66;03m# Create a new empty model card and eventually tag it\u001B[39;00m\n\u001B[1;32m    865\u001B[0m model_card \u001B[38;5;241m=\u001B[39m create_and_tag_model_card(\n\u001B[1;32m    866\u001B[0m     repo_id, tags, token\u001B[38;5;241m=\u001B[39mtoken, ignore_metadata_errors\u001B[38;5;241m=\u001B[39mignore_metadata_errors\n\u001B[1;32m    867\u001B[0m )\n",
      "File \u001B[0;32m/workspace/jyh/miniconda3/envs/ChatWorld/lib/python3.9/site-packages/transformers/utils/hub.py:676\u001B[0m, in \u001B[0;36mPushToHubMixin._create_repo\u001B[0;34m(self, repo_id, private, token, repo_url, organization)\u001B[0m\n\u001B[1;32m    673\u001B[0m             repo_id \u001B[38;5;241m=\u001B[39m repo_id\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    674\u001B[0m         repo_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00morganization\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrepo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 676\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_repo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrepo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprivate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprivate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m url\u001B[38;5;241m.\u001B[39mrepo_id\n",
      "File \u001B[0;32m/workspace/jyh/miniconda3/envs/ChatWorld/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:118\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    116\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/workspace/jyh/miniconda3/envs/ChatWorld/lib/python3.9/site-packages/huggingface_hub/hf_api.py:3162\u001B[0m, in \u001B[0;36mHfApi.create_repo\u001B[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001B[0m\n\u001B[1;32m   3158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_lfsmultipartthresh\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m   3159\u001B[0m     \u001B[38;5;66;03m# Testing purposes only.\u001B[39;00m\n\u001B[1;32m   3160\u001B[0m     \u001B[38;5;66;03m# See https://github.com/huggingface/huggingface_hub/pull/733/files#r820604472\u001B[39;00m\n\u001B[1;32m   3161\u001B[0m     json[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlfsmultipartthresh\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lfsmultipartthresh  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[0;32m-> 3162\u001B[0m headers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_hf_headers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_write_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   3164\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m   3165\u001B[0m     r \u001B[38;5;241m=\u001B[39m get_session()\u001B[38;5;241m.\u001B[39mpost(path, headers\u001B[38;5;241m=\u001B[39mheaders, json\u001B[38;5;241m=\u001B[39mjson)\n",
      "File \u001B[0;32m/workspace/jyh/miniconda3/envs/ChatWorld/lib/python3.9/site-packages/huggingface_hub/hf_api.py:8191\u001B[0m, in \u001B[0;36mHfApi._build_hf_headers\u001B[0;34m(self, token, is_write_action, library_name, library_version, user_agent)\u001B[0m\n\u001B[1;32m   8188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   8189\u001B[0m     \u001B[38;5;66;03m# Cannot do `token = token or self.token` as token can be `False`.\u001B[39;00m\n\u001B[1;32m   8190\u001B[0m     token \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoken\n\u001B[0;32m-> 8191\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbuild_hf_headers\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   8192\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   8193\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_write_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_write_action\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   8194\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlibrary_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlibrary_name\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlibrary_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   8195\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlibrary_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlibrary_version\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlibrary_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   8196\u001B[0m \u001B[43m    \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   8197\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/workspace/jyh/miniconda3/envs/ChatWorld/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:118\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    116\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/workspace/jyh/miniconda3/envs/ChatWorld/lib/python3.9/site-packages/huggingface_hub/utils/_headers.py:122\u001B[0m, in \u001B[0;36mbuild_hf_headers\u001B[0;34m(token, is_write_action, library_name, library_version, user_agent)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;66;03m# Get auth token to send\u001B[39;00m\n\u001B[1;32m    121\u001B[0m token_to_send \u001B[38;5;241m=\u001B[39m get_token_to_send(token)\n\u001B[0;32m--> 122\u001B[0m \u001B[43m_validate_token_to_send\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtoken_to_send\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_write_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_write_action\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;66;03m# Combine headers\u001B[39;00m\n\u001B[1;32m    125\u001B[0m headers \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    126\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muser-agent\u001B[39m\u001B[38;5;124m\"\u001B[39m: _http_user_agent(\n\u001B[1;32m    127\u001B[0m         library_name\u001B[38;5;241m=\u001B[39mlibrary_name,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    130\u001B[0m     )\n\u001B[1;32m    131\u001B[0m }\n",
      "File \u001B[0;32m/workspace/jyh/miniconda3/envs/ChatWorld/lib/python3.9/site-packages/huggingface_hub/utils/_headers.py:172\u001B[0m, in \u001B[0;36m_validate_token_to_send\u001B[0;34m(token, is_write_action)\u001B[0m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_write_action:\n\u001B[1;32m    171\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m token \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 172\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    173\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mToken is required (write-access action) but no token found. You need\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    174\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m to provide a token or be logged in to Hugging Face with\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    175\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m `huggingface-cli login` or `huggingface_hub.login`. See\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    176\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m https://huggingface.co/settings/tokens.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    177\u001B[0m         )\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m token\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapi_org\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    179\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    180\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou must use your personal account token for write-access methods. To\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    181\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m generate a write-access token, go to\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    182\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m https://huggingface.co/settings/tokens\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    183\u001B[0m         )\n",
      "\u001B[0;31mValueError\u001B[0m: Token is required (write-access action) but no token found. You need to provide a token or be logged in to Hugging Face with `huggingface-cli login` or `huggingface_hub.login`. See https://huggingface.co/settings/tokens."
     ]
    }
   ],
   "source": [
    "# client.push_to_hub(\"Haruhi-Zero-GLM3-6B-Lora-0_4\")\n",
    "# tokenizer.push_to_hub(\"Haruhi-Zero-GLM3-6B-Lora-0_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChatWorld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
