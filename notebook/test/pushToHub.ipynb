{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全量上传"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# checkpoint = \"/workspace/jyh/Zero-Haruhi/train_2024-02-16-17-51\"\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     checkpoint, trust_remote_code=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)\n",
    "# print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.push_to_hub(\"Haruhi-Zero-GLM3-6B-0_4\")\n",
    "# tokenizer.push_to_hub(\"Haruhi-Zero-GLM3-6B-0_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lora上传"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-17T13:34:57.251138Z",
     "start_time": "2024-02-17T13:33:06.487972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "964ae28b002f40d5aa7d250c9a02f350"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "checkpoint = \"/Users/jiangyh/代码/Zero-Haruhi/lora\"\n",
    "\n",
    "\n",
    "def _resolve_path(path) -> Path:\n",
    "    return Path(path).expanduser().resolve()\n",
    "\n",
    "\n",
    "def load_model_and_tokenizer(model_dir):\n",
    "    model_dir = _resolve_path(model_dir)\n",
    "    if (model_dir / 'adapter_config.json').exists():\n",
    "        model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "            model_dir, trust_remote_code=True\n",
    "        )\n",
    "        tokenizer_dir = model.peft_config['default'].base_model_name_or_path\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_dir, trust_remote_code=True\n",
    "        )\n",
    "        tokenizer_dir = model_dir\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        tokenizer_dir, trust_remote_code=True\n",
    "    )\n",
    "    return model.to(), tokenizer\n",
    "\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-17T13:34:59.463388Z",
     "start_time": "2024-02-17T13:34:59.457644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): ChatGLMForConditionalGeneration(\n",
      "      (transformer): ChatGLMModel(\n",
      "        (embedding): Embedding(\n",
      "          (word_embeddings): Embedding(65024, 4096)\n",
      "        )\n",
      "        (rotary_pos_emb): RotaryEmbedding()\n",
      "        (encoder): GLMTransformer(\n",
      "          (layers): ModuleList(\n",
      "            (0-27): 28 x GLMBlock(\n",
      "              (input_layernorm): RMSNorm()\n",
      "              (self_attention): SelfAttention(\n",
      "                (query_key_value): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=4096, out_features=4608, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Dropout(p=0.1, inplace=False)\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=4096, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=4608, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                )\n",
      "                (core_attention): CoreAttention(\n",
      "                  (attention_dropout): Dropout(p=0.0, inplace=False)\n",
      "                )\n",
      "                (dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "              )\n",
      "              (post_attention_layernorm): RMSNorm()\n",
      "              (mlp): MLP(\n",
      "                (dense_h_to_4h): Linear(in_features=4096, out_features=27392, bias=False)\n",
      "                (dense_4h_to_h): Linear(in_features=13696, out_features=4096, bias=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (final_layernorm): RMSNorm()\n",
      "        )\n",
      "        (output_layer): Linear(in_features=4096, out_features=65024, bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "ChatGLMTokenizer(name_or_path='THUDM/chatglm3-6b', vocab_size=64798, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.push_to_hub(\"Haruhi-Zero-GLM3-6B-Lora-0_4\")\n",
    "tokenizer.push_to_hub(\"Haruhi-Zero-GLM3-6B-Lora-0_4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChatWorld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
