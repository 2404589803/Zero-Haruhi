{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMpT0+P8V2hmDNTJFXJpG6W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Zero-Haruhi/blob/main/notebook/%E4%BD%BF%E7%94%A8ChatHaruhi54K%E7%94%9F%E6%88%90messages%E5%BD%A2%E5%BC%8F%E6%95%B0%E6%8D%AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ ] RoleLLM的数据\n",
        "- [ ] 其他中文的hf的一些数据\n",
        "- [ ] ChatHaruhi54K本身的数据"
      ],
      "metadata": {
        "id": "GglE46SYH83z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里我们假设输入数据已经组织成了hf格式\n",
        "\n",
        "可以有效载入到chatbot中"
      ],
      "metadata": {
        "id": "vPt6Zysa5H78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install openai tiktoken langchain datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6VrCMIb5T_j",
        "outputId": "5f928cfe-f9ce-40ec-b5e7-d0f9ee7ef8ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.3/222.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.4/802.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.9/218.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m577.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "组织数据"
      ],
      "metadata": {
        "id": "JNmjcFSeoNZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"silk-road/ChatHaruhi-54K-Role-Playing-Dialogue\")\n",
        "\n",
        "role2tuple = {}\n",
        "\n",
        "from tqdm import tqdm\n",
        "for data in tqdm( dataset['train'] ):\n",
        "    agent_role = data['agent_role']\n",
        "    if agent_role not in role2tuple:\n",
        "        role2tuple[agent_role] = []\n",
        "\n",
        "    user_role = data['user_role']\n",
        "    user_question = data['user_question']\n",
        "\n",
        "    query = user_role + \":\" + user_question + \"\"\n",
        "\n",
        "    agent_response = data['agent_response']\n",
        "\n",
        "    target = agent_role + \":\" + agent_response + \"\"\n",
        "\n",
        "    # role2tuple[agent_role].append((query, target))\n",
        "\n",
        "    messages = [\n",
        "        {\"role\":\"user\",\"content\":query,'user_role':user_role,'user_question':user_question},\n",
        "        {\"role\":\"assistent\",\"content\":target}\n",
        "    ]\n",
        "\n",
        "\n",
        "    more_dialogues = data['more_dialogues']\n",
        "\n",
        "    if len(more_dialogues) > 0:\n",
        "        n = len( more_dialogues )\n",
        "        for i in range(n):\n",
        "\n",
        "            sent = more_dialogues[i]\n",
        "\n",
        "            if sent.startswith(agent_role):\n",
        "                messages.append( {\"role\":\"assistent\", \"content\":sent} )\n",
        "            else:\n",
        "                messages.append( {\"role\":\"user\", \"content\":sent} )\n",
        "\n",
        "    role2tuple[agent_role].append(messages)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh9u8M18oR8G",
        "outputId": "7bf62115-98ec-4e60-ad09-612996123042"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 54726/54726 [00:04<00:00, 11434.39it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in role2tuple:\n",
        "    print(key, len(role2tuple[key]))"
      ],
      "metadata": {
        "id": "TY_GfQ8dHZ9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tuple数据会保留在role2tuple"
      ],
      "metadata": {
        "id": "HTBjIkY4od7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(role2tuple['Harry'][100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GVNjUkPofaQ",
        "outputId": "fa048b0b-9554-4f4c-fa20-2e898d850c8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'user', 'content': 'Ginny:「Did I hear right? You’ve been taking orders from something someone wrote in a book, Harry?」'}, {'role': 'assistent', 'content': '「It’s nothing. It’s not like, you know, Riddle’s diary. It’s just an old textbook someone’s scribbled on.」'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "训练的参数设定"
      ],
      "metadata": {
        "id": "tl7H3ltbFaEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf /content/Haruhi-2-Dev\n",
        "!git clone https://github.com/LC1332/Haruhi-2-Dev\n",
        "%cd /content/Haruhi-2-Dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udVfoKmi9Tme",
        "outputId": "20d17001-bef3-482f-a1d6-add0b58d728f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'Haruhi-2-Dev'...\n",
            "remote: Enumerating objects: 1046, done.\u001b[K\n",
            "remote: Counting objects: 100% (353/353), done.\u001b[K\n",
            "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
            "remote: Total 1046 (delta 244), reused 306 (delta 210), pack-reused 693\u001b[K\n",
            "Receiving objects: 100% (1046/1046), 106.35 MiB | 48.19 MiB/s, done.\n",
            "Resolving deltas: 100% (574/574), done.\n",
            "/content/Haruhi-2-Dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "role_name_Haruhiu = {'汤师爷': 'tangshiye', 'tangshiye': 'tangshiye', 'Tangshiye': 'tangshiye',\n",
        "                     '慕容复': 'murongfu', 'murongfu': 'murongfu', 'Murongfu': 'murongfu',\n",
        "                     '李云龙': 'liyunlong', 'liyunlong': 'liyunlong', 'Liyunlong': 'liyunlong',\n",
        "                     'Luna': 'Luna', '王多鱼': 'wangduoyu', 'wangduoyu': 'wangduoyu',\n",
        "                     'Wangduoyu': 'wangduoyu', 'Ron': 'Ron', '鸠摩智': 'jiumozhi',\n",
        "                     'jiumozhi': 'jiumozhi', 'Jiumozhi': 'jiumozhi', 'Snape': 'Snape',\n",
        "                     '凉宫春日': 'haruhi', 'haruhi': 'haruhi', 'Haruhi': 'haruhi',\n",
        "                     'Malfoy': 'Malfoy', '虚竹': 'xuzhu', 'xuzhu': 'xuzhu',\n",
        "                     'Xuzhu': 'xuzhu', '萧峰': 'xiaofeng',\n",
        "                     'xiaofeng': 'xiaofeng', 'Xiaofeng': 'xiaofeng', '段誉': 'duanyu',\n",
        "                     'duanyu': 'duanyu', 'Duanyu': 'duanyu', 'Hermione': 'Hermione',\n",
        "                     'Dumbledore': 'Dumbledore', '王语嫣': 'wangyuyan', 'wangyuyan':\n",
        "                     'wangyuyan', 'Wangyuyan': 'wangyuyan', 'Harry': 'Harry',\n",
        "                     'McGonagall': 'McGonagall', '白展堂': 'baizhantang',\n",
        "                     'baizhantang': 'baizhantang', 'Baizhantang': 'baizhantang',\n",
        "                     '佟湘玉': 'tongxiangyu', 'tongxiangyu': 'tongxiangyu',\n",
        "                     'Tongxiangyu': 'tongxiangyu', '郭芙蓉': 'guofurong',\n",
        "                     'guofurong': 'guofurong', 'Guofurong': 'guofurong', '流浪者': 'wanderer',\n",
        "                     'wanderer': 'wanderer', 'Wanderer': 'wanderer', '钟离': 'zhongli',\n",
        "                     'zhongli': 'zhongli', 'Zhongli': 'zhongli', '胡桃': 'hutao', 'hutao': 'hutao',\n",
        "                     'Hutao': 'hutao', 'Sheldon': 'Sheldon', 'Raj': 'Raj',\n",
        "                     'Penny': 'Penny', '韦小宝': 'weixiaobao', 'weixiaobao': 'weixiaobao',\n",
        "                     'Weixiaobao': 'weixiaobao', '乔峰': 'qiaofeng', 'qiaofeng': 'qiaofeng',\n",
        "                     'Qiaofeng': 'qiaofeng', '神里绫华': 'ayaka', 'ayaka': 'ayaka',\n",
        "                     'Ayaka': 'ayaka', '雷电将军': 'raidenShogun', 'raidenShogun': 'raidenShogun',\n",
        "                     'RaidenShogun': 'raidenShogun', '于谦': 'yuqian', 'yuqian': 'yuqian',\n",
        "                     'Yuqian': 'yuqian', 'Professor McGonagall': 'McGonagall',\n",
        "                     'Professor Dumbledore': 'Dumbledore'}"
      ],
      "metadata": {
        "id": "aB85YpyjHmie"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6vNMO1f_E55",
        "outputId": "f7c89657-8dbd-4722-d481-6c0b368db889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatHaruhi  data  LICENSE  notebook  Readme.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ChatHaruhi import ChatHaruhi\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "role_en2bots = {}\n",
        "\n",
        "for ai_role_en in tqdm( role_name_Haruhiu.values() ):\n",
        "    if ai_role_en in role_en2bots:\n",
        "        continue\n",
        "\n",
        "    role_en2bots[ai_role_en] = ChatHaruhi(role_name = ai_role_en, llm = 'foo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12Zncxr6HuiB",
        "outputId": "1fd902f4-6a95-4312-eb59-c34c8dba85af"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [00:42<00:00,  1.78it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "\n",
        "for role in role2tuple:\n",
        "    if role in role_name_Haruhiu:\n",
        "        en_name = role_name_Haruhiu[role]\n",
        "        if en_name in role_en2bots:\n",
        "            count+= len(role2tuple[role])\n",
        "\n",
        "print(count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmh2GaQcIDbz",
        "outputId": "d2fdcb0a-9141-45aa-8236-2c166e5fc468"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K_SEARCH = 3\n",
        "MAX_LEN_STORY = 1000 #这个是按照token算的\n",
        "MAX_LEN_HISTORY = 1200 # count with token\n",
        "source = \"Haruhi52K\""
      ],
      "metadata": {
        "id": "espjcXFPJMC6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lynZ4m35BGy",
        "outputId": "a3a002a6-99ef-4a76-dbab-52a34d26fca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2494/2494 [10:37<00:00,  3.91it/s]\n",
            "100%|██████████| 1924/1924 [04:33<00:00,  7.04it/s]\n",
            " 29%|██▉       | 351/1216 [00:44<01:37,  8.89it/s]"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "save_datas = []\n",
        "\n",
        "# for role_name in tqdm(role_from_roleLLM):\n",
        "\n",
        "for role_name_zh in role2tuple.keys():\n",
        "    if role_name_zh not in role_name_Haruhiu:\n",
        "        continue\n",
        "    role_name_en = role_name_Haruhiu[role_name_zh]\n",
        "\n",
        "    chatbot = role_en2bots[role_name_en]\n",
        "\n",
        "\n",
        "    chatbot.k_search = K_SEARCH\n",
        "    chatbot.max_len_story = MAX_LEN_STORY\n",
        "    chatbot.max_len_history = MAX_LEN_HISTORY\n",
        "\n",
        "    all_messages = role2tuple[role_name_zh]\n",
        "\n",
        "    for messages in tqdm(all_messages):\n",
        "        query = messages[0]['content']\n",
        "        user_role = messages[0]['user_role']\n",
        "        user_question = messages[0]['user_question'].strip(\" 「」\")\n",
        "        prompt_messages = chatbot.generate_messages(user_question, user_role )\n",
        "\n",
        "        conversations = []\n",
        "        system_prompt = \"\"\n",
        "        for msg in prompt_messages[:-1]:\n",
        "            role = msg[\"role\"]\n",
        "            content = msg[\"content\"]\n",
        "            if role == \"AI\":\n",
        "                conversations.append({\"from\":\"gpt\",\"value\":content})\n",
        "            elif role == \"System\":\n",
        "                if system_prompt == \"\":\n",
        "                    system_prompt = content\n",
        "            elif role == \"User\":\n",
        "                conversations.append({\"from\":\"human\",\"value\":content})\n",
        "\n",
        "        for msg in messages:\n",
        "            content = msg[\"content\"]\n",
        "            if msg[\"role\"] == \"user\":\n",
        "                conversations.append({\"from\":\"human\",\"value\":content})\n",
        "            else:\n",
        "                conversations.append({\"from\":\"gpt\",\"value\":content})\n",
        "\n",
        "\n",
        "        save_data = {\n",
        "            \"source\":source,\n",
        "            \"conversations\":conversations,\n",
        "            \"system\":system_prompt\n",
        "        }\n",
        "        save_datas.append(save_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bokybOvNNWtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import random\n",
        "def sample_and_save( save_datas, save_name ,sample_n=50, save_folder = \"/content/drive/MyDrive/CardBuild/HaruhiZero\"):\n",
        "    file_name = os.path.join( save_folder, save_name + \".jsonl\" )\n",
        "    with open( file_name, \"w\", encoding=\"utf-8\" ) as f:\n",
        "        for data in save_datas:\n",
        "            f.write( json.dumps( data, ensure_ascii=False ) + \"\\n\" )\n",
        "\n",
        "    sample_name = os.path.join( \"/content/\", save_name + \"_sample.jsonl\" )\n",
        "    with open( sample_name, \"w\", encoding=\"utf-8\" ) as f:\n",
        "        random_50 = random. sample( save_datas, sample_n )\n",
        "        for data in random_50:\n",
        "            f.write( json.dumps( data, ensure_ascii=False ) + \"\\n\" )"
      ],
      "metadata": {
        "id": "x1J02Ol8NfaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_and_save( save_datas, \"Haruhi52K\" , sample_n = 50)"
      ],
      "metadata": {
        "id": "53ojkk0dtmAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_data = save_datas[3]\n",
        "for msg in save_data[\"conversations\"]:\n",
        "    print(msg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTZuXEsfNCiM",
        "outputId": "97f22528-bd07-4ec7-cae6-b31650de5603"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'from': 'human', 'value': \"Classic scenes for the role are as follows:\\nTogether:「Not at all.」\\nRaj:「Papa, please don't start.」\\nDr. Koothrappali:「God, it's just a question, he's so sensitive.」\\nRaj:「Okay, that's my life, that's my friends, good to see you, say goodbye.」\\n###\\nDr. Koothrappali:「Bye bye.」\\nRaj:「I don't believe it.」\\n###\\nLeonard:「This isn't a substitution, it's a reduction.」\\nChen:「Okay, no reductions.」\\nLeonard:「Fine, bring us three orders of dumplings, that's twelve, we'll each have four.」\\nRaj:「That works.」\\n###\\n\"}\n",
            "{'from': 'human', 'value': \"Leonard:「Take it, Raj. It's more than I’ve ever gotten.」\"}\n",
            "{'from': 'gpt', 'value': \"Raj:「Oh, I couldn't.」\"}\n",
            "{'from': 'human', 'value': 'Leonard:「No, no, no, you should.」'}\n",
            "{'from': 'gpt', 'value': 'Raj:「Okay, I will.」'}\n",
            "{'from': 'human', 'value': \"Sheldon:「I'm sorry, are we taking turns talking now?」\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rFKUkulxMUr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U_nKXIs957Oe"
      }
    }
  ]
}